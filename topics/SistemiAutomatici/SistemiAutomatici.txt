Sistemi automatici
Libro di testo per gli Istituti Tecnici e Tecnologici

Controllo automatico

In scienza dell'automazione, il controllo automatico di un dato sistema
dinamico (di un motore, di un impianto industriale, di una funzione
biologica come il battito cardiaco) si prefigge di modificare il
comportamento del sistema da controllare, ovvero delle sue uscite,
attraverso la manipolazione delle grandezze d'ingresso. Ad esempio può
richiedersi che l'uscita rimanga costante ad un valore prefissato al
variare dell'ingresso (controllo semplice) oppure segua fedelmente la
dinamica dell'ingresso stesso (sistema di asservimento) a meno di
amplificazioni e ritardi.

Il controllo del sistema in esame viene affidato ad un altro sistema
costruito appositamente, detto sistema controllante o controllore, che
viene progettato dopo uno studio preliminare del sistema da controllare per
individuarne un modello matematico sufficientemente preciso servendosi
degli strumenti messi a punto dalla teoria dei sistemi. Il controllo
automatico di un sistema è possibile solo se il sistema stesso è
raggiungibile e osservabile, cioè se è possibile sia portarlo in un dato
stato interno agendo sui suoi ingressi sia risalire allo stato attuale del
sistema basandosi sulle sue uscite.

Esempio di sistema di controllo

Per esempio in un moderno motore a combustione interna il sistema riceve in
ingresso la posizione del pedale dell'acceleratore o un setpoint di
velocità ed alcuni dati ambientali e deve garantire determinate velocità e
coppia in uscita e la corretta composizione dei gas di scarico. Il sistema
controllante è tipicamente una centralina che elabora i dati di ingresso
quali velocità di rotazione, portata di alimentazione, presenza di ossigeno
allo scarico... e agisce su una serie di grandezze fisiche come posizione
della valvola a farfalla, istante e durata dell'iniezione di carburante,
istante di accensione, eventuale anticipo variabile della distribuzione,
eccetera.

Cenni storici

Il primo esempio di applicazione della teoria dei controlli è dato dal
Regolatore centrifugo sul quale James Clerk Maxwell affrontò uno studio di
analisi dinamica nel suo scritto del 1868 intitolato On Governors.¹

In seguito Edward John Routh, allievo di Maxwell, generalizzò le
conclusioni di Maxwell per la classe dei sistemi lineari.²
Indipendentemente da Routh, Adolf Hurwitz analizzò nel 1877 la stabilità
del sistema servendosi di equazioni differenziali. Il risultato di Routh e
Hurwitz è noto come teorema di Routh-Hurwitz.³ ⁴

Negli anni 1890 Aleksandr Michajlovič Ljapunov elabora le basi della teoria
della stabilità.

Negli anni 1930 Harry Nyquist elabora il criterio di stabilità di Nyquist
che permette di studiare la stabilità di un sistema in retroazione
unitaria.

Con la Seconda guerra mondiale la teoria dei controlli espanse il suo campo
di applicazione ai sistemi di puntamento, ai sistemi di guida, e
all'elettronica. Con la corsa allo spazio anche la guida dei veicoli
spaziali divenne oggetto di studio della teoria dei controlli.

Negli anni quaranta anche l'informatica diventa studio della teoria dei
controlli grazie agli studi sulla programmazione dinamica di Richard
Bellman. Sempre negli anni '40 nasce la cibernetica, una scienza
multidisciplinare che sfrutta i risultati della teoria dei controlli.

Negli anni cinquanta John R. Ragazzini contribuisce introducendo i concetti
di controllo digitale e la trasformata zeta. Altri campi di applicazione
della teoria dei controlli sono l'economia e l'ingegneria chimica.

Teoria dei controlli

La teoria dei controlli è quella branca della scienza ed ingegneria che
studia il comportamento di un sistema le cui grandezze siano soggette a
variazioni nel tempo. Questa scienza, che ha un vastissimo campo di
applicazione, è nata nell'ambito dell'elettronica industriale e
dell'automazione.

Il controllo può avvenire solo in un regime temporale. Spesso lo studio
matematico con modelli matematici nel dominio del tempo diventa molto
difficile, causa la necessità di risolvere equazioni differenziali. Quindi
attraverso delle trasformazioni, le trasformate di cui le più famose sono
quelle di Fourier e quelle di Laplace, si studia lo stesso sistema con
tecniche di tipo algebrico nel dominio della frequenza e una volta ottenuto
il risultato si antitrasforma per tornare nel dominio del tempo.

La rappresentazione grafica di un sistema o processo si attua mediante
'schemi a blocchi' oppure 'grafi di flusso' dove ogni singolo processo è
individuato da una 'trasferenza' dinamica.

Ingressi e uscite

Ogni sistema può avere uno o più ingressi e una o più uscite. Con il
termine SISO (acronimo di single input - single output) si intende un
sistema a singolo ingresso e a singola uscita, mentre con il termine MIMO
(acronimo di multi input - multi output) si intende un sistema a ingressi
multipli e a uscite multiple.

Ad ogni variazione delle variabili in ingresso segue una determinata
risposta del sistema, ovvero un certo comportamento di altre variabili
all'uscita. Le variazioni delle variabili in ingresso più comuni sono:
l'impulso di Dirac, il gradino, la rampa e la sinusoide).

-
Impulso di Dirac.
-
Variazione a gradino.
-
Variazione a rampa.
-
Variazione sinusoidale.

Le variabili in ingresso (o in entrata) si differenziano in:

- variabili manipolabili (o variabili di controllo o variabili di
  manipolazione): hanno la caratteristica di essere sempre misurabili
- disturbi (o sollecitazioni esterne): possono essere anche non misurabili
  e la loro presenza è indesiderata dal punto di vista del controllo.

Tra le variabili in uscita si hanno:

- variabili di prestazione: sono le variabili controllate, da non
  confondere con le variabili di controllo, e possono essere misurabili
  direttamente o indirettamente
- variabili intermedie: sono delle variabili fisiche misurabili che possono
  essere utilizzate per la misura indiretta delle variabili di prestazione.

La misura diretta delle variabili da controllare viene detta misura (o
misurazione) primaria, mentre la misura indiretta delle variabili da
controllare viene detta misura (o misurazione) secondaria. Esempi di
misurazione secondaria sono il controllo in cascata, il controllo
adattativo e il controllo inferenziale.

Controllo ad anello aperto

Un sistema automatico di controllo può funzionare essenzialmente in due
modi: come controllo ad anello aperto o come controllo in retroazione.

Il controllo ad anello aperto (o in avanti o predittivo o feedforward) si
basa su una elaborazione degli ingressi eseguita senza conoscere il valore
dell'uscita del sistema controllato, essendo note alcune proprietà del
sistema da controllare.

In questo caso è fondamentale avere un buon modello matematico che descriva
con buona precisione il comportamento del sistema. Tanto più il modello
matematico su cui si basa l'azione del controllo feedforward è esatto,
tanto più questo tipo di controllo è affidabile.

I motori elettrici della maggior parte dei ventilatori oggi in vendita sono
controllati mediante un sistema di asservimento di questo tipo.

Controllo ad anello chiuso (retroazione)

Il controllo ad anello chiuso (o retroazionato o all'indietro o feedback),
più complesso ma molto più flessibile del primo, può rendere stabile un
sistema che di per sé non lo è affatto.

In questo caso l'anello di controllo riporta all'ingresso del processo che
si vuole controllare o rendere stabile una funzione dell'uscita che va
sommata algebricamente al segnale già presente in ingresso.

Chiamando y_{ref} il segnale in ingresso al sistema prima dell'innesto
della retroazione detto anche segnale di riferimento, y_{out} il segnale in
uscita dal sistema da controllare, y_{fb} il segnale in uscita dal
controllore (che quindi dipende da y_{out} e dalla struttura dello stesso
controllore), si può distinguere il controllo in:

- retroazione positiva: al segnale y_{ref} viene sommato y_{fb}, e la somma
  viene inviata in ingresso al sistema;
- retroazione negativa: al segnale y_{ref} viene sottratto y_{fb}, in modo
  da avere in ingresso al sistema il cosiddetto segnale errore, e_f

Il segnale di riferimento viene chiamato così in quanto nei sistemi di
asservimento si vuole che l'uscita lo segua il più fedelmente possibile per
alcuni classi di segnali di riferimento. Per questo motivo la differenza
tra riferimento e uscita viene chiamata errore o errore di inseguimento

In generale la retroazione positiva porta a sistemi instabili, mentre la
retroazione negativa apre la strada a strategie di controllo molto efficaci
per il raggiungimento della stabilità del sistema e il miglioramento delle
prestazioni del sistema: velocità nel raggiungere il valore di uscita
desiderata, errore nullo nel caso di ingresso costante o di ingresso con
variazioni lineari nel tempo, eccetera...

Controllo in retroazione di sistemi L.T.I. e L.I.T.

Ogni blocco componente un sistema L.T.I. può essere rappresentato tramite
una funzione di trasferimento applicando al sottosistema che modella il
blocco stesso rispettivamente la trasformata di Laplace o la trasformata
Zeta, a seconda che si tratti di sistemi a tempo continuo o a tempo
discreto. Perciò il controllo LTI in retroazione è essenzialmente un
sistema di controllo formato:

- dalla cascata di controllore C(s) o C(z) e processo P(s) o P(z) il cui
  ingresso è l'errore E(s) o E(z) tra riferimento R(s) o R(z) e uscita del
  processo Y(s) o Y(z); le funzioni complesse in s o in z sono
  rispettivamente le trasformate di Laplace o Zeta dei sistemi che
  rappresentano i blocchi e le trasformate di Laplace o Zeta dei segnali in
  ingresso e in uscita ai blocchi stessi.
- dal processo P(s) o P(z) la cui uscita Y(s) o Y(z) è prelevata da un
  compensatore dinamico C(s) (o C(z) ottenuto come sintesi di un
  osservatore dello stato e di un controllo in retroazione dallo stato, per
  esempio il regolatore lineare quadratico, che genera l'ingresso di
  controllo U(s) o U(z) che si somma al riferimento R(s) o R(z).

Le posizioni nel piano complesso dei poli e degli zeri della funzione di
trasferimento determinano i modi di risposta e in particolare la stabilità
del sistema. Nei sistemi causali LTI, quali i sistemi fisici LTI, ovvero
nei sistemi LTI le cui uscite non dipendono dai valori futuri degli
ingressi, gli elementi della matrice di trasferimento sono frazionari ed
hanno un polinomio a denominatore di grado non inferiore al grado del
polinomio a numeratore. Se gli zeri dei denominatori, detti poli della
trasformata, appartengono al semipiano a parte reale positiva del piano
complesso il sistema è instabile e la risposta all'impulso yδ(t) tende
all'infinito al crescere di t. Se invece i poli della trasformata
appartengono al semipiano a parte reale negativa del piano complesso il
sistema è asintoticamente stabile e yδ(t) tende asintoticamente a 0 al
crescere di t. Infine se infine i poli della trasformata appartengono alla
retta verticale a parte reale nulla del piano complesso ed hanno
molteplicità singola, il sistema è semplicemente stabile e yδ(t) è
maggiorata in valore assoluto da un certo valore al crescere di t. Per
determinare come variano le posizioni dei poli e degli zeri al variare
della funzione di trasferimento del compensatore si usano particolari
grafici quali il diagramma di Bode, il diagramma di Nyquist e il luogo
delle radici.

Due proprietà fondamentali dei sistemi LTI sono la raggiungibilità e
l'osservabilità. Se queste due proprietà sono verificate allora per il
sistema di controllo, cioè il sistema ottenuto retroazionando il sistema
dinamico LTI con un controllore LTI, esiste sempre un controllore che rende
il sistema di controllo asintoticamente stabile.

Esistono differenti tipi di controllori. Le prime tecnologie di controllori
si basavano essenzialmente su circuiti analogici (reti correttrici)
appositamente creati per un dato problema. Attualmente vengono utilizzati
sistemi di controllo digitale che permettono di sfruttare le potenzialità
dei computer garantendo un minor costo e una maggiore versatilità.

Esempio: controllo della temperatura

Esempio classico di controllo in retroazione è il sistema di controllo di
temperatura di una stanza. Questo sistema di controllo a retroazione viene
anche chiamato regolatore poiché regola l'uscita di un sistema per
mantenerla il più possibile uguale all'ingresso. Si vuole mantenere la
temperatura di una stanza a 20 °C. Un termostato controlla la temperatura e
comanda l'afflusso di acqua ai caloriferi della stanza. In un sistema di
controllo il valore a cui si vuole mantenere la temperatura viene chiamato
set point. A seconda della temperatura letta dal sensore si apre o si
chiude l'afflusso dell'acqua al calorifero. La temperatura della stanza
oscillerà attorno ai 20 °C a seconda della dissipazione del calore, della
capacità dei caloriferi e delle condizioni a cui il regolatore apre o
chiude la valvola. Un tipo di regolazione in retroazione come questo è
chiamato regolazione on-off in quanto prevede come retroazione un semplice
comando acceso-spento. Un tipo di controllo del genere può essere usato per
la regolazione del riscaldamento di una stanza di un'abitazione dove
oscillazioni di 1 °C sono tollerate da chi dovrà utilizzare la stanza.

Soluzioni di controllo

Esistono diverse tecniche per sintetizzare controllori in anello chiuso tra
cui le soluzioni più note sono:

Controllo PID

Rappresenta una delle soluzioni di controllo più semplici, permette di
ottenere buone prestazioni con sistemi prevalentemente lineari, mentre
risulta deludente per sistemi con carattere fortemente non lineare (es.:
sistemi LTV⁵ ) o con caratteristiche particolari come la presenza di zeri
nel semipiano di destra o di poli nell'origine o sull'asse immaginario. La
semplicità delle tre azioni elementari che lo costituiscono ne rende
semplice l'implementazione sia con tecnologie pneumatiche sia con
tecnologie elettroniche. Per via della sua larga diffusione non è raro
trovarne implementazione anche in elettronica digitale dove le potenzialità
della CPU permetterebbero l'implementazione di algoritmi ben più complessi.

Controllo sliding mode

Può essere considerato come una estensione del controllo on/off utilizzato
per la regolazione della temperatura di caldaie e frigoriferi. Sfruttando
la teoria di stabilità secondo Lyapunov e la possibilità di applicare
segnali di controllo in alta frequenza, permette di ottenere controllori
semplici ed estremamente robusti. Il limite principale è rappresentato
dalla frequenza massima del segnale di controllo e dalla presenza di
oscillazioni sull'uscita, note come chatter. Tuttavia la teoria alla base
del controllo sliding mode permette di svilupparne varianti leggermente più
complesse, prive di chatter e allo stesso tempo robuste anche per sistemi
con caratterizzazioni fortemente non lineari.

Controllo adattativo

In questa categoria rientrano gli algoritmi di controllo con capacità di
adattarsi al sistema da controllare. Esistono diverse forme di adattabilità
che vanno dalla modifica dei parametri di controllo lungo opportune curve
(Gain scheduling) alla possibilità di cambiare completamente o parzialmente
la struttura del controllore. Rispetto alle soluzioni di controllo che non
prevedono una variabilità nei parametri o nella struttura, scontano un
maggiore peso computazionale che ne rende difficile l'implementazione su
hardware commerciale, ma offrono come contropartita migliori prestazioni e
una maggiore robustezza.

Controllo ottimo

Il controllo ottimo si prefigge di stabilizzare il sistema dinamico tramite
l'ottimizzazione di una funzione di costo J(x,u), dove per x si intende lo
stato del sistema e per u il controllo generato da un opportuno controllore
ottenuto a seguito della minimizzazione. Minimizzando la funzione di costo
J e manipolando opportuni parametri si riesce ad ottenere un controllore
che rende la dinamica del controllo grande e veloce o piccola e lenta.
Minimizzare J significa far tendere x a zero, ovvero stabilizzarlo, in
tempo finito o infinito e di conseguenza anche u che è un controllo in
retroazione dallo stato, quindi un'opportuna combinazione lineare delle
variabili di stato. Il controllo ottimo è efficace sotto ipotesi di
stabilizzabilità del sistema e di rivelabilità del sistema. Se il sistema è
rivelabile, cioè se lo stato x va stimato, è necessario un osservatore
anch'esso ottimo: il filtro di Kalman.

La teoria sviluppata per il controllo ottimo permette la sintesi di
controllori noto il modello ed esclusivamente per sistemi lineari.

Controllo robusto

È una soluzione di controllo che permette di imporre sia le prestazioni
nominali, sia le prestazioni robuste sotto ipotesi di incertezze
parametriche sul modello del sistema. Valido solo per sistemi lineari,
giunge alla definizione di una serie di vincoli che il controllore deve
garantire.  In tal senso non è una soluzione di controllo robusta per
natura (come il Controllo sliding mode), ma semplicemente un'imposizione di
vincoli su un controllore in retroazione di stato.

Nel caso lineare MIMO il sistema P₀, detto processo nominale, viene
controllato con un apposito compensatore K in retroazione dallo stato
stimato, quindi il sistema di controllo sarà costituito da un controllore
vero e proprio e da un osservatore dello stato. La matrice K viene
sintetizzata tramite appositi algoritmi di controllo robusto che, assegnati
i vincoli di prestazione, forniscono un compensatore ottimo tramite sintesi
LQR - LTR (anche detta LQG), tramite sintesi in H-infinito o tramite i
classici metodi della compensazione di sistemi SISO previa operazione di
disaccoppiamento del sistema.

Controllo deadbeat

Il controllo deadbeat è una tecnica nata per sistemi tempo-continuo e poi
estesa ai sistemi tempo-discreto. Consente di ottenere sistemi che
garantiscono delle ottime proprietà dinamiche ed errore a regime nullo in
funzione di un dato segnale in ingresso. È una tecnica sviluppata
essenzialmente per sistemi lineari. Il suo utilizzo per i sistemi non
lineari è ancora un problema aperto.

Schema riassuntivo di confronto

Di seguito vengono confrontate le diverse possibilità di controllo:

Strutture del controllore
  + Controllo feedback - Vantaggi: robustezza, controlla anche i disturbi
    non misurabili o imprevisti - Svantaggi: essendo in anello chiuso può
    introdurre instabilità nella risposta se tarato male, non agisce in
    tempo reale
  + Controllo feedforward - Vantaggi: agisce prima che il sistema risenta
    del disturbo, non introduce instabilità nella risposta - Svantaggi: il
    sistema deve scostarsi poco dal modello, è richiesta una buona
    conoscenza del sistema, il disturbo deve essere misurabile, non sono
    controllati i disturbi imprevisti o non misurabili
  + Controllo misto - Unisce i vantaggi delle singole soluzioni senza
    presentare svantaggi significativi.
  + Controllo in cascata - Vantaggi: Sforzo di taratura minore, maggiore
    robustezza ai disturbi
Tipi di controllore
  + Controllo PID - Vantaggi: Semplice e funzionale, implementabile in
    diverse tecnologie - Svantaggi: Prestazioni modeste con sistemi
    fortemente non lineari, come gli LTV.
  + Controllo adattativo - Vantaggi: Sforzo di taratura ridotto,
    prestazioni elevate anche al variare dei parametri per fenomeni di
    invecchiamento. - Svantaggi: Costo computazionale maggiore,
    implementazione possibile solo con dispositivi elettronici digitali.
  + Controllo Sliding Mode - Vantaggi: Basso costo computazionale, elevata
    robustezza - Svantaggi: Alcune soluzioni possono essere affette da
    'chatter'.
  + Controllo Ottimo - Vantaggi: Permette di sintetizzare un controllore
    basandosi su un indice di costo, valido anche per sistemi lineari MIMO
    - Svantaggi: Peso computazione delle operazioni di sintesi elevato,
    valido solo per sistemi lineari.
  + Controllo Robusto - Vantaggi: Robustezza a variazioni parametriche -
    Svantaggi: Valido solo per sistemi lineari

Applicazioni

Controllo dei processi

Note

[1] Maxwell, J.C., On Governors, in Proceedings of the Royal Society of
  London, vol. 16, 1867, pp. 270–283, DOI:10.1098/rspl.1867.0055. URL
  consultato il 14 aprile 2008.
[2] Routh, E.J., Fuller, A.T., Stability of motion, Taylor & Francis, 1975,
  ISBN.
[3] Routh, E.J., A Treatise on the Stability of a Given State of Motion,
  Particularly Steady Motion: Particularly Steady Motion, Macmillan and
  co., 1877, ISBN.
[4] Hurwitz, A., On The Conditions Under Which An Equation Has Only Roots
  With Negative Real Parts, in Selected Papers on Mathematical Trends in
  Control Theory, 1964.
[5] Con la sigla LTV si fa riferimento a sistemi Lineari con parametri
  Tempo Varianti

Bibliografia

- Katsuhiko Ogata. Modern Control Engineering. Prentice Hall, 2002.
- Paolo Bolzern, Riccardo Scattolini, Nicola Schiavoni. Fondamenti di
  controlli automatici. McGraw-Hill Companies, giugno 2008. ISBN
  978-88-386-6434-2.
- Eduardo D. Sontag (1990): Mathematical Control Theory, Springer, ISBN
  3-540-97366-4
- Alain Bensoussan (1992): Stochastic Control of Partially Observable
  Sysytems, Cambridge University Press, ISBN 0-521-35403-X
- Hector O. Fattorini (1999): Infinite dimensional optimization and Control
  theory, Cambridge University Press, ISBN 0-521-45125-6
- Jiongmin Yong, Xun Yu Zhou (1999): Stochastic Controls. Hamiltonian
  Systems and HJB Equations, Springer, ISBN 0-387-98723-1
- Christopher Kilian, Modern Control Technology, Thompson Delmar Learning,
  2005, ISBN 1-4018-5806-6.
- Vannevar Bush, Operational Circuit Analysis, John Wiley and Sons, Inc.,
  1929.
- Robert F. Stengel, Optimal Control and Estimation, Dover Publications,
  1994, ISBN 0-486-68200-5.
- Franklin et al., Feedback Control of Dynamic Systems, 4ª ed., New Jersey,
  Prentice Hall, 2002, ISBN 0-13-032393-4.
- Joseph L. Hellerstein, Dawn M. Tilbury, and Sujay Parekh, Feedback
  Control of Computing Systems, John Wiley and Sons, 2004, ISBN
  0-471-26637-X.
- Diederich Hinrichsen and Anthony J. Pritchard, Mathematical Systems
  Theory I - Modelling, State Space Analysis, Stability and Robustness,
  Springer, 2005, ISBN 978-3-540-44125-0.
- Andrei, Neculai, Modern Control Theory - A historical Perspective (PDF),
  2005.
- Eduardo Sontag, Mathematical Control Theory: Deterministic Finite
  Dimensional Systems. Second Edition, Springer, 1998, ISBN 0-387-98489-5.
- Giovanni Marro, Controlli automatici, 4a edizione, Zanichelli, 1997, ISBN
  88-08-00015-X.
- Gottardo Marco, Let's program a PLC !!!, seconda edizione (2.1) 14
  novembre 2012, italiano, ISBN 978-1-291-18932-2. editore online LULU.

Voci correlate

- Analisi dei sistemi dinamici
- Automazione
- Controllabilità
- Controllo in cascata
- Controllo industriale
- Controllo lineare quadratico gaussiano
- Controllo ottimo
- Controllo PID
- Controllo robusto
- Controllo vincolato
- Controllore (strumento)
- Diagramma di Bode
- Equilibrio (Teoria dei sistemi)
- H-infinito
- Loop transfer recovery
- Diagramma di Nyquist
- Regolatore lineare quadratico
- Sistema dinamico lineare stazionario
- Sistema dinamico
- Strumentazione di controllo
- SCADA
- Teoria dei sistemi
- Teoria del caos

Altri progetti

- Wikibooks contiene testi o manuali su controllo automatico
- Wikimedia Commons contiene immagini o altri file su controllo automatico

Collegamenti esterni

- Controllo automatico, in Thesaurus del Nuovo soggettario, BNCF, marzo
  2013.
- Analisi e simulazione dei sistemi dinamici. (PDF), dsi.unifi.it.
- People in control (tratto da: Control Systems Magazine, IEEE, volume 24,
  articolo 5, ottobre 2004 pagine 12-15).
- ISA, the International Society for Measurement and Control, isa.org.

Stabilità interna

In matematica, la stabilità interna o stabilità di Lyapunov di un sistema
dinamico è un modo per caratterizzare la stabilità delle traiettorie
compiute dal sistema nello spazio delle fasi in seguito ad una sua
perturbazione in prossimità di un punto di equilibrio. Un punto di
equilibrio è detto stabile (secondo Lyapunov) se ogni orbita del sistema
che parte sufficientemente vicina al punto di equilibrio rimane nelle
vicinanze del punto di equilibrio, ed è detto asintoticamente stabile se
l'orbita converge al punto al crescere infinito del tempo.

L'analisi della stabilità interna di un sistema dinamico è di grande
importanza nello studio dei fenomeni naturali, in cui ad una condizione di
equilibrio stabile corrisponde un minimo dell'energia posseduta dal
sistema, come conseguenza del fatto che esso tende spontaneamente a
minimizzarla. Il teorema di Lagrange-Dirichlet, che considera sistemi
olonomi soggetti a forze conservative e con vincoli perfetti (bilaterali)
indipendenti dal tempo, stabilisce in particolare che l'energia potenziale
ha un minimo relativo proprio quando il sistema assume una configurazione
di equilibrio meccanico stabile (secondo Lyapunov).

Punti di equilibrio

Si consideri un sistema dinamico:

\dot{x} = f(x) \qquad x \in \R ⁿ

dove f: \mathcal{D} \subset \R ^n →\R ⁿ è una funzione lipschitziana in x e
continua in t.

Sia x₀ un punto di equilibrio, cioè f(x_0)=0 . Allora:¹

- Il punto di equilibrio x₀ è detto stabile (secondo Lyapunov) se per ogni
  intorno U del punto x₀ esiste un intorno V \subset U tale che le orbite
  che partono da punti interni a V rimangono dentro U per tutti i tempi
  t>0.
  Esplicitamente, per ogni ϵ> 0 esiste δ= δ(ϵ) > 0 tale che, se \| x(0)-
  x_0 \| < δ, allora per ogni t \geq 0 si ha \| x(t)- x_0 \| < ϵ.
- Il punto di equilibrio x₀ è detto attrattivo se esiste un intorno U di x₀
  tale che per ogni orbita x(t) che parta da un punto interno ad U si ha:
  \lim _{t →+\infty } x(t)=x₀Il più grande intorno U per cui ciò avviene è
  chiamato bacino di attrazione del punto x₀.
- Il punto di equilibrio x₀ è detto asintoticamente stabile se è stabile e
  attrattivo. Ovvero, esiste δ> 0 tale che se \| x(0)- x_0 \| < δ allora
  \lim _{t →\infty } \| x(t)- x_0\| = 0.
- Un punto di equilibrio x₀ è detto esponenzialmente stabile se è
  asintoticamente stabile ed esistono α, β, δ>0 tali per cui, se \| x(0)-
  x_0 \| < δ, si ha:
\| x(t)- x_0\| \leq α\| x(0)- x_0\| e^{-βt} \qquad t \geq 0
- Un punto di equilibrio si dice instabile se non è stabile, ovvero se
  esiste un intorno U di x₀ tale che, comunque si scelga un intorno V di x₀
  contenuto in U, si può sempre trovare una posizione iniziale x \in V la
  cui orbita si allontana da x₀ abbastanza da uscire da U.

Da un punto di vista geometrico, l'insieme (invariante) dei punti che si
avvicinano a x₀ (la cui orbita converge a x₀ per t →\infty ) è detto
varietà stabile, mentre per "varietà instabile" ci si riferisce all'insieme
di quelli che si allontanano.

Attrattività e stabilità

Un punto di equilibrio stabile in generale non è attrattivo, e un punto di
equilibrio attrattivo non è necessariamente stabile. La proprietà di
stabilità è una proprietà locale, potendo essere osservata considerando
intorni arbitrariamente piccoli del punto di equilibrio, mentre la
proprietà di attrattività non lo è: anche se il bacino di attrazione è
molto piccolo, o contiene intorni arbitrariamente piccoli, per verificare
se un punto vi appartiene occorre seguire tutta la sua traiettoria che
potrebbe allontanarsi arbitrariamente da x₀.

Un esempio di sistema dinamico con un punto di equilibrio che è attrattivo
ma non stabile è quello definito sulla circonferenza da:

\dot{θ} =1-cos(θ)

Qui θ=0 è un punto di equilibrio e le soluzioni che partono da qualsiasi
altro punto della circonferenza vi convergono "dal basso" girando in senso
orario. Il punto è attrattivo ed il suo bacino di attrazione è l'intera
circonferenza, ma il punto ha un equilibrio instabile dal momento che tutte
le soluzioni che partono da punti "sopra" di esso (arbitrariamente vicini)
si allontanano uscendo da qualsiasi intorno prefissato.

Criteri di Lyapunov

I criteri di Lyapunov forniscono condizioni sufficienti per la stabilità in
prossimità di un punto di equilibrio, e sono estesi da un vasto numero di
risultati. Il primo criterio riconduce l'analisi del sistema a quella della
sua approssimazione lineare in un intorno del punto di equilibrio, il
secondo utilizza una particolare funzione scalare, la funzione di Lyapunov,
per "confinare" le soluzioni in una regione dello spazio delle fasi. Nello
studio dei sistemi meccanici, a tale funzione si fa solitamente
corrispondere l'energia potenziale del sistema.

Primo criterio di Lyapunov

Dato il sistema dinamico:

\dot x = f( x)

con x₀ un punto di equilibrio, ovvero:

f(x_0)= 0

la linearizzazione del sistema in un intorno di x₀ si ottiene considerando
la traiettoria perturbata:

x(t) = x_0 + δx(t)

e inserendola nell'equazione:

\dot x = δ\dot x = f(x_0 + δx(t) ) = f(x_0) + \frac{\partial f}{\partial
x^T} |_{x= x_0} δx + O(\| δx \| ²⁾

dove trascurando i termini di ordine superiore al primo si ha:

δ\dot x = A δx \qquad A = \frac{\partial f}{\partial x^T} |_{x= x₀}

Il criterio di Lyapunov stabilisce che:²

- se il punto di equilibrio δx = 0 del sistema linearizzato δ\dot x = A δx
  è asintoticamente stabile allora x₀ è un punto di equilibrio
  asintoticamente stabile del sistema non linearizzato
- se δx = 0 è instabile allora x₀ è un punto di equilibrio instabile del
  sistema non linearizzato
- se δx = 0 è stabile non si può dire nulla del sistema non linearizzato.

Secondo criterio di Lyapunov

Sia a(t, x) : \R \times B →\R una funzione continua tale che a(t , 0) = 0
per ogni t \in \R , con B \subset \R ⁿ un intorno di 0. Si dice che a(t, x)
è definita positiva in B se esiste una funzione continua b(x) : B →\R
definita positiva (cioè b(x)>0 per ogni x \in B \setminus {0 }) tale che
b(0) = 0 e:

a(t, x) > b(x) \qquad ∀x \in B

La definizione per una funzione delle variabili (t, x) definita negativa si
ottiene analogamente, rimpiazzando > con <.

Si dice che a(t, x) è semidefinita positiva in B se esiste una funzione
b(x) : B →\R semidefinita positiva (cioè b(x) \ge 0 per ogni x \in B ) tale
che b(0) = 0 e:

a(t, x) \ge b(x) \qquad ∀x \in B

Invertendo il verso della disuguaglianza si definisce analogamente una
funzione semidefinita negativa.

Dato un intorno D \subset \R ⁿ del punto di equilibrio x₀ per il sistema:

\dot x = f(t, x)

se esiste una funzione V : \R \times D →\R di classe C¹ definita positiva e
con derivata orbitale:

\dot V (t, x) = \frac{\partial }{\partial t} V(t, x) + \frac{\partial
}{\partial x₁} V(t, x) f_1(x) + …+ \frac{\partial }{\partial xₙ} V(t, x)
f_n(x)

semidefinita negativa, allora x₀ è stabile nel senso di Lyapunov.

Il punto di equilibrio x₀ è asintoticamente stabile nel senso di Lyapunov
se esiste inoltre una funzione W : D →\R definita positiva tale per cui:³

V(t,x) < W(x) \qquad ∀(t,x) \in \R \times D

La stabilità così definita è una condizione sufficiente ma non necessaria,
cioè un punto di equilibrio può essere stabile anche se non esistono
funzioni di Lyapunov definite in un suo intorno.

Sistemi lineari

Nelle scienze applicate, specialmente in elettronica e nella teoria del
controllo, è comune studiare la stabilità dei sistemi dinamici lineari.
Spesso vengono studiati nel dominio di Laplace s = σ+ i ω, ovvero si
analizza la loro risposta in frequenza, che per sistemi stazionari è data
dalla funzione di trasferimento. Un sistema lineare di n stati x \in \R ⁿ,
m input u \in \R ^m e q uscite y \in \R ^q viene descritto da un'equazione
del tipo:

\dot x(t) = A x(t)+B u(t)
y(t) = C x(t)+D u(t)

ed è detto stabile se tutti gli autovalori di A hanno parte reale
negativa.⁴

In particolare, è possibile mostrare che se l'ingresso è un'oscillazione
del tipo u= \bar u e^{st} , con \bar u \in \R ⁿ un vettore arbitrario, ed
il sistema è stabile, allora per un tempo che tende ad infinito l'uscita è
un'oscillazione della stessa frequenza della perturbazione in ingresso:

\lim _{t →\infty } y(t)= [D+C(sI-A)^{-1} B] \bar u e^{st}

dove il guadagno [D+C(sI-A)^{-1} B], con I la matrice identità, produce uno
sfasamento ed un'amplificazione dell'input (senza variarne la frequenza).

Esempio: l'oscillatore armonico

L'oscillatore armonico è un classico esempio utilizzato per chiarire i
concetti di stabilità. Il sistema è costituito da una molla che da un lato
è vincolata ad un piano e dall'altro è collegata ad una massa. Se si
suppone che nel sistema non ci sia attrito, dopo aver compresso (o
allungato) la molla, la massa inizierà ad oscillare per un tempo
indefinito, senza mai fermarsi. Se si provano ad immaginare le traiettorie
del sistema, queste oscilleranno intorno al punto di equilibrio: si tratta
di un sistema stabile, e le traiettorie non si allontanano mai
eccessivamente dal punto di equilibrio. Se si suppone che nel sistema sia
presente attrito, le oscillazioni saranno smorzate e dopo un po' di tempo
il sistema si arresterà nella posizione di riposo (di equilibrio). Dunque
le traiettorie inizialmente oscilleranno in un intorno del punto di
equilibrio, per poi arrestarsi nella posizione di equilibrio. Si tratta di
un sistema asintoticamente stabile, le traiettorie non si allontanano mai
eccessivamente e dopo un certo tempo convergono al punto di equilibrio,
arrestandosi in esso.

Note

[1] (EN) Clemson University - Lyapunov Stability I: Autonomous Systems
[2] (EN) Christopher J. Damaren - Lyapunov Stability
[3] (EN) Christopher Grant - Lyapunov's Direct Method
[4] (EN) Andrew Packard - Frequency Response for Linear Systems

Bibliografia

- (EN) A.M. Lyapunov, Stability of motion , Acad. Press (1966)
- (DE) O. Perron, Ueber Stabilität und asymptotisches Verhalten der
  Integrale von Differentialgleichungssystemen Math. Z. , 29 (1928) pp.
  129–160
- (EN) R.E. Bellman, Stability theory of differential equations , Dover,
  reprint (1969)
- (EN) Jean-Jacques E. Slotine and Weiping Li, Applied Nonlinear Control,
  Prentice Hall, NJ, 1991
- (EN) Parks P.C: "A. M. Lyapunov's stability theory - 100 years on", IMA
  Journal of Mathematical Control & Information 1992 9 275-303
- (EN) G. Teschl, Ordinary Differential Equations and Dynamical Systems,
  Providence, American Mathematical Society, 2012, ISBN 978-0-8218-8328-0.
- (EN) S. Wiggins, Introduction to Applied Nonlinear Dynamical Systems and
  Chaos, 2ª ed., New York, Springer Verlag, 2003, ISBN 0-387-00177-8.

Voci correlate

- Attrattore
- Ciclo limite
- Funzione di Lyapunov
- Insieme limite
- Punto di equilibrio
- Punto fisso
- Punto periodico
- Stabilità esterna
- Teorema di Lagrange-Dirichlet
- Teorema di LaSalle
- Teoria della stabilità
- Varietà centrale
- Varietà invariante
- Varietà stabile

Altri progetti

- Wikimedia Commons contiene immagini o altri file su Stabilità interna

Collegamenti esterni

- (EN) V.M. Millionshchikov, Lyapunov stability, in Encyclopaedia of
  Mathematics, Springer e European Mathematical Society, 2002.
- (EN) Yu.S. Bogdanov, Asymptotically-stable solution, in Encyclopaedia of
  Mathematics, Springer e European Mathematical Society, 2002.
- (EN) asymptotically stable, in PlanetMath.
- (EN) Dan Zelazo - Lyapunov Stability Theory (PDF), tx.technion.ac.il.

Dominio della frequenza

In matematica, ingegneria, fisica, statistica, e altri ambiti delle
scienze, l'analisi nel dominio della frequenza di una funzione del tempo (o
segnale) ne indica la descrizione in termini dell'insieme (spettro) delle
sue frequenze. Ad esempio, è una pratica diffusa nell'ambito delle
tecnologie audiovisive e nelle telecomunicazioni valutare quanto un segnale
elettrico o elettromagnetico sia compreso in bande di frequenze di
particolare interesse.

In tale formalismo un segnale è visto come una sovrapposizione di sinusoidi
complesse, ognuna rappresentante una certa frequenza e fase. Conoscendo
l'ampiezza e la fase di ogni frequenza costitutiva di un segnale è in linea
di principio possibile "ricostruire" il segnale di partenza in un certo
intervallo di tempo. In molte applicazioni pratiche, tuttavia,
l'informazione sulla fase viene trascurata e la rappresentazione in termini
di frequenze pure è detta spettro del segnale.

Il concetto di dominio della frequenza è stato inizialmente reso possibile
dall'introduzione della serie di Fourier da parte del matematico francese
Joseph Fourier, che ha dato inizio ad un settore della matematica noto come
analisi di Fourier. La rappresentazione in serie di Fourier, che si
utilizza per segnali periodici, viene estesa a segnali generici (con
opportune limitazioni matematiche) da diverse trasformate integrali, in
particolar modo la trasformata di Fourier e la trasformata di Laplace,
sebbene il dominio di quest'ultima trasformata non sia strettamente
frequenziale.

Dominio di Laplace

La trasformata di Laplace trasforma una funzione che ha per variabile
indipendente il tempo (o comunque un numero reale) in una funzione che ha
per variabile indipendente un numero complesso, la cui parte reale dipende
dall'inviluppo della funzione di partenza, mentre la parte immaginaria
rappresenta le pulsazioni, per cui, se si annulla la parte reale, la
trasformata di Laplace viene a coincidere con quella di Fourier ed il suo
dominio diventa a tutti gli effetti frequenziale

Altri domini correlati

Vi sono inoltre la trasformata zeta (per segnali discreti, usata
soprattutto nell'elaborazione numerica dei segnali), la trasformata wavelet
(elaborazione digitale delle immagini, compressione dei segnali) o la
trasformata di Mellin.

Applicazioni

Questi strumenti di analisi sono utilizzati nello studio dei circuiti
elettronici e dei sistemi di controllo.

La trattazione matematica della scomposizione in frequenza di una funzione
viene affrontata in generale dall'analisi armonica, ed ha una vasta
diffusione nelle scienze applicate.

Per visualizzare i segnali nel dominio della frequenza si usa uno strumento
chiamato analizzatore di spettro, mentre nel dominio del tempo si usa
l'oscilloscopio.

Bibliografia

- (EN) S.A. Broughton e K. Bryan, Discrete Fourier Analysis and Wavelets:
  Applications to Signal and Image Processing, New York, Wiley, 2008, p.
  72.
- (EN) B. Boashash, Note on the Use of the Wigner Distribution for Time
  Frequency Signal Analysis, in IEEE Transactions on Acoustics, Speech, and
  Signal Processing, vol. 36, nº 9, Sep 1988, pp. 1518–1521,
  DOI:10.1109/29.90380..
- (EN) B. Boashash, Estimating and Interpreting the Instantaneous Frequency
  of a Signal-Part I: Fundamentals, in Proceedings of the IEEE, vol. 80, nº
  4, aprile 1992, pp. 519–538, DOI:10.1109/5.135376..

Voci correlate

- Analisi armonica
- Analisi di Fourier
- Dominio del tempo
- Rappresentazione spettrale dei segnali
- Serie di Fourier
- Spettro di potenza
- Trasformata di Fourier
- Trasformata di Laplace

Altri progetti

- Wikimedia Commons contiene immagini o altri file su Dominio della
  frequenza

Diagramma di Bode

Un diagramma di Bode è una rappresentazione grafica della risposta in
frequenza di un sistema lineare stazionario (LTI) e che consiste in due
grafici che rappresentano rispettivamente l'ampiezza (o modulo) e la fase
della funzione complessa di risposta in frequenza. Ricordiamo che si parla
di risposta in frequenza quando la funzione di trasferimento di un sistema
lineare tempo invariante viene sollecitata da un ingresso di tipo
sinusoidale con pulsazione ω al variare di questa.

Il nome di questo tipo di rappresentazione è dovuta allo scienziato
statunitense Hendrik Wade Bode, pioniere nello studio della teoria dei
controlli e delle telecomunicazioni elettroniche.

Contrariamente alla rappresentazione polare, o diagramma di Nyquist, la
rappresentazione di modulo e fase della funzione di trasferimento non
avviene su di un solo piano cartesiano, ma in due distinti che hanno
entrambi in ascissa, come variabile indipendente, la frequenza o la
pulsazione e in ordinata appunto il modulo dell'ampiezza usualmente
espressa in decibel o il modulo della fase espressa in gradi o radianti.

I due diagrammi possono raramente essere modificati l'uno dall'altro
indipendentemente - se si modifica la risposta in modulo molto
probabilmente verrà modificata la risposta in fase e viceversa. Per sistemi
a fase minima è possibile risalire al diagramma della risposta della fase
dal diagramma della risposta del modulo tramite la Trasformata di Hilbert.

Il diagramma di Bode trova applicazione, ad esempio, nella teoria dei
controlli, nella teoria dei sistemi, nella progettazione di filtri e
amplificatori.

Diagramma di Bode

Scala logaritmica

Per facilitare lo studio su un elevato spettro di pulsazioni sia il
diagramma del modulo sia il diagramma della fase vengono rappresentati su
carta logaritmica o semilogaritmica divisa in decadi. La carta
semilogaritmica è caratterizzata dal fatto che la distanza che separa due
valori ωₐ e ω_b è proporzionale alla differenza tra i logaritmi
(solitamente in base 10) di ωₐ e ω_b. Fatte queste premesse, una possibile
rappresentazione dei valori della pulsazione sulla carta semilogaritmica
potrebbe essere

I vantaggi nell'uso di diagrammi logaritmici sono sostanzialmente la
possibilità di rappresentare col dovuto dettaglio grandezze che variano in
campi notevolmente estesi, la possibilità di semplificare i calcoli di
moltiplicazione che nel caso di logaritmi si riconducono semplicemente a
somme.

Diagramma del modulo

Nel diagramma del modulo si rappresenta, sulla carta semilogaritmica, la
pulsazione sull'asse delle ascisse, mentre su quello delle ordinate il
modulo espresso in decibel, cioè il modulo espresso secondo la formula
\left | {F(jω)} \right |_{dB} = 20\log _{10} \left ( {\left | {F(jω)}
\right |} \right )¹

Diagramma della fase

Nel diagramma della fase si rappresentano le ampiezze assunte
dall'argomento di F per diversi valori di ω. Anche in questo caso è utile
servirsi della carta semilogaritmica indicando sull'asse delle ascisse le
pulsazioni e sull'asse delle ordinate le ampiezze, solitamente espresse in
gradi sessagesimali.

Diagrammi asintotici

Per tracciare il diagramma reale di Bode, sia del modulo, sia della fase,
sono richiesti una quantità particolarmente elevata di calcoli, dovendo
valutare il modulo e la fase della funzione F per un ventaglio di valori
della pulsazione molto ampio, e questo, in assenza di un calcolatore
elettronico che esegue parecchi calcoli in breve tempo, può risultare molto
difficile o comunque dispendioso in termini di tempo. Per ovviare a questo
problema è prassi comune quella di disegnare i diagrammi di Bode a partire
dai diagrammi asintotici e approssimando il comportamento dei grafici reali
da questi ultimi.

Funzione di trasferimento in forma normale

La funzione di trasferimento di un sistema è una funzione frazionaria
sicuramente propria, nella quale compaiono a numeratore le uscite e a
denominatore gli ingressi. Per studiare con maggiore facilità una funzione
di trasferimento è utile riportarla in forma canonica o forma di Bode.
Questa particolare forma è costituita da una serie fattorizzata di monomi,
binomi e trinomi espressi nella variabile complessa di Laplace. Essa assume
la forma:

G(s) = \frac{μ}{{s^g }} ·\frac{{\prod \limits _{i = 1}^p {\left ( {1 + T_i
s} \right )} ·\prod \limits _{i = 1}^q {\left ( {\frac{{s² }}{{ω_{n_i }² }}
+ 2ξ_i \frac{s}{{ω_{n_i } }} + 1} \right )} }}{{\prod \limits _{i = 1}^m
{\left ( {1 + τ_i s} \right )} ·\prod \limits _{i = 1}^w {\left (
{\frac{{s² }}{{ω_{n_i }² }} + 2ζ_i \frac{s}{{ω_{n_i } }} + 1} \right )} }}

Il significato dei vari membri di questa funzione sono:

μ: Valore costante che esprime il guadagno della funzione di trasferimento.

s^g: Zeri o poli nell'origine, a seconda del valore assunto da g.

{\left ( {1 + T_i s} \right )}: Zero reale della funzione di trasferimento.

{\left ( {1 + τ_i s} \right )}: Polo reale della funzione di trasferimento.

{\left ( {\frac{{s² }}{{ωₙ² }} + 2ξ\frac{s}{{ωₙ }} + 1} \right )}: Coppia
di zeri complessi coniugati.

{\left ( {\frac{{s² }}{{ωₙ² }} + 2ζ\frac{s}{{ωₙ }} + 1} \right )}: Coppia
di poli complessi coniugati.

Effettuando la sostituzione s = jω si passa alla forma canonica, che
permette di studiare più facilmente l'andamento della funzione. Su scala
semilogaritmica (misurando l'ampiezza in dB), infatti, tutte le produttorie
si trasformano in sommatorie ed è possibile studiare separatamente ciascun
membro della funzione, che porta dei contributi differenti sia sul
diagramma del modulo, sia sul diagramma della fase. Il modulo di H(s),
infatti, sarà la somma algebrica dei moduli di tutti i fattori così come la
fase sarà la somma algebrica delle fasi di tutti i fattori.

La funzione di trasferimento dopo aver effettuato la sostituzione appare
nella forma:
H(jω) = k ·\frac{\prod _{i=1}^p (1 + T_ijω) \prod _{i=1}^q
(\frac{(jω)²}{ω²_{n_i}} + \frac{2ξ_i}{ω_{n_i}} jω+ 1)}{(jω)^g \prod
_{i=1}^μ(1 + τ_ijω) \prod _{i=1}^w (\frac{(jω)²}{ω²_{n_i}} +
\frac{2ζ_i}{ω_{n_i}} jω+ 1)}

Esempio

Domanda:
Viene data la funzione di trasferimento G(s) = \frac{{8s^2 \left ( {1 + s}
\right )\left ( {\frac{{s² }}{{100}} + 2 ·0,3\frac{s}{{10}} + 1} \right
)}}{{\left ( {1 + 0,2s} \right )² }} e si vuole trovare il guadagno, il
tipo, gli zeri o i poli nell'origine, gli zeri e i poli reali e gli zeri ed
i poli complessi coniugati.

Soluzione:
Per prima cosa conviene riscrivere la funzione in un'espressione che
"assomigli" di più a quella canonica scritta sopra quindiG(s) = \frac{{8s^2
\left ( {1 + s} \right )\left ( {\frac{{s² }}{{100}} + 2 ·0,3\frac{s}{{10}}
+ 1} \right )}}{{\left ( {1 + 0,2s} \right )² }} = \frac{8}{{s^{ - 2} }}
·\frac{{\left ( {1 + s} \right )\left ( {\frac{{s² }}{{100}} + 2
·0,3\frac{s}{{10}} + 1} \right )}}{{\left ( {1 + 0,2s} \right )\left ( {1 +
0,2s} \right )}}

Da cui si riconosce subito che il guadagno è μ= 8 e il tipo è g=-2 (cioè ci
sono due zeri nell'origine). Si vede poi lo zero reale s=-1 e il doppio
polo reale s=-5. Infine vi è la presenza di una coppia di zeri complessi
coniugati con pulsazione naturale ωₙ ₌ ₁₀ e smorzamento ξ= 0,3.

Guadagno di una funzione di trasferimento

Il grafico del guadagno di una funzione di trasferimento appare, molto
semplicemente, come una retta orizzontale di modulo 20\log _{10} \left |
μ\right |dB e un'altra di ampiezza \arg \left ( μ\right ).

Esempio

Si vuole tracciare il diagramma reale di Bode della funzione di
trasferimento G(s)=2

ModuloIl diagramma del modulo è una retta orizzontale di ordinata uguale a
20\log _{10} \left | 2 \right | \simeq 6 dB

FaseIl diagramma della fase è anch'esso una retta orizzontale di ordinata
uguale a \arg \left ( 2 \right ) = 0^\circ

I poli in zero: (jω)^m

I poli di una funzione di trasferimento si definiscono come le radici del
denominatore (e quindi dell'ingresso). Dal momento che stiamo studiando i
poli generati da (jω)^m, siamo nel caso di poli situati in 0 e con
molteplicità m. Per semplicità di studio, ci limitiamo ad analizzare il
caso m = 1, lasciando a dopo le considerazioni su una possibile
molteplicità m > 1.

I poli in zero influiscono sull'andamento della funzione di trasferimento
nel seguente modo:

Modulo:
\bigg |\frac{1}{(jω)^m} \bigg |_{dB}=20m\log _{10}{\bigg |\frac{1}{jω}
\bigg |}=-20m\log _{10}{|ω|}
Si tratta pertanto di una retta con pendenza -20 dB/decade (o 6 dB/ottava)
incidente l'asse delle ascisse in \frac{1}{|τ|}

Fase:
ϕ\bigg (\frac{1}{jω} \bigg ) = \arg \bigg (\frac{1}{jω} \bigg ) = -\arg
(jω) = -\frac{π}{2}

Nel caso (più generale) in cui m > 1 si può "aggirare" il problema pensando
che (jω)^m = jω·jω·…·jω. Pertanto, poiché il diagramma di Bode viene
rappresentato su scala semilogaritmica, si può pensare di sommare m
contributi di fattori monomi del tutto simili a quello preso ora in esame.

Questa tesi viene sostenuta dal fatto che, rieseguendo i conti di modulo e
fase svolti poco sopra mantenendo m \neq 0, si ottiene:

\bigg |\frac{1}{(jω)^m} \bigg |_{dB} = -m ·20log_{10}|ω|

ϕ\bigg (\frac{1}{(jω)^m} \bigg ) = -m\frac{π}{2}

Esempio

Si vuole tracciare il diagramma della funzione di trasferimento G(s) =
\frac{2}{s}

ModuloIn tal caso essendo s=jω e
G(jω)=\frac{2}{jω} , allora il modulo risulta:
|G(jω)|=|\frac{2}{jω} |=\frac{2}{|jω|} =\frac{2}{ω} con ω\in \mathbb{R}
^{+}
Pertanto:
|G(jω)|_{dB}=20\log _{10}{\frac{2}{ω} } e per ω→0^{+}⇒|G(jω)|_{dB}→+\infty
mentre per
ω→+\infty ⇒|G(jω)|_{db}→-\infty , inoltre per
ω=2 radianti al secondo |G(jω)|_{db}=0.
Come si può osservare dal diagramma, la pendenza è -1 sempre.

Fase

Poiché G(jω)=-j\frac{2}{ω} è immaginario puro e ω\in \mathbb{R} ^{+} è
sempre positivo, allora i numeri complessi, al variare di ω, sono sulla
semiretta immaginaria negativa e quindi la loro fase è -90 sempre.

Zeri reali (1 + j ωτ)

Gli zeri dei binomi posti a numeratore influiscono sull'andamento della
funzione di trasferimento in modo non lineare. Può essere però comodo, per
semplificare i conti, studiare un andamento approssimato del modulo e della
fase, tenendo conto in seguito dell'errore massimo che si può commettere
con questa semplificazione.

Modulo

|1+jωτ|_{dB}=20\log _{10}{|1+jωτ|}=20\log _{10}{√(1+ω^2τ²)}=10\log
_{10}{\left (1+ω^2τ^2\right )}=

ponendo poi ω_B=\frac{1}{τ}

=10\log _{10}{\left (1+\frac{ω²}{ω²_B} \right )}

Si possono verificare ora due casi:

|1+jωτ|_{dB}=\left {\begin{matrix} \sim 10\log _{10}{1}=0 &\mbox{se } ω\ll
ω_B \sim 10\log _{10}{ω^2τ^2}=20\log _{10}{ωτ} &\mbox{se } ω\gg
ω_B\end{matrix} \right .

Ciò significa che il diagramma di Bode approssimato per un termine binomio
posto a numeratore della funzione di trasferimento consiste di una spezzata
che ha valore 0 per tutte le ω<{1\over |τ|} e che cresce linearmente di 20
dB/decade (o 6 dB/ottava) per tutte le ω>{1\over |τ|}.

È naturale, ora, chiedersi quale sia l'errore massimo che si commette
effettuando questa approssimazione. L'errore massimo è commesso proprio nel
caso in cui ω=ω_B. Infatti:

se ω=ω_B⇒|1+jωτ|_{dB}=10\log _{10}{2} \cong 3dB

Siamo pertanto sicuri che, nell'approssimazione dell'andamento del modulo
di un termine binomio con una spezzata, non si commette un errore maggiore
di 3dB.

Fase

Esempio

Un filtro RC passabasso, per esempio, ha la seguente risposta in frequenza:

H(f) = \frac{1}{1+j2πf R C}

La frequenza di taglio indicata dal punto fc (in hertz) ha valore pari a

f_\mathrm{c} = {1 \over {2πRC}}

L'approssimazione asintotica del diagramma di Bode consiste di due linee:

- per frequenze minori di fc è una linea orizzontale a 0 dB,
- per frequenze maggiori di fc è una linea con una pendenza di −20 dB per
  decade.

Queste due linee si incontrano alla frequenza di taglio. Dal diagramma si
vede che per frequenze molto al disotto della frequenza di taglio il
circuito ha un'attenuazione di 0dB, cioè il filtro non modifica il modulo
del segnale. Frequenze al disopra della frequenza di taglio sono attenuate
in misura maggiore tanto più si sale in frequenza.

Esempio pratico di tracciamento del diagramma

Vediamo ora, in pratica, come si procede per tracciare un diagramma
asintotico di Bode da cui poi si può tracciare, con buona approssimazione,
quello reale. La spiegazione viene fatta seguendo un esempio pratico: si
vuole tracciare il diagramma asintotico di Bode del modulo e della fase
della funzione di trasferimento

G\left ( s \right ) = \frac{{10(1 - 0,05s)}}{{\left ( {1 + s} \right )\left
( {1 + 0,5s} \right )}} = \frac{{10}}{{s⁰ }} ·\frac{{\left ( {1 - 0,05s}
\right )}}{{\left ( {1 + s} \right )\left ( {1 + 0,5s} \right )}}

Per prima cosa mettiamo in evidenza tutte le informazioni che ci servono.

Guadagno statico μ

Si trova, molto semplicemente calcolando μ= G\left ( 0 \right ) e poi
trasformandolo in decibel con la formula \left | μ\right | = 20\log _{10}
μIn questo caso μ= 10 da cui \left | μ\right | = 20\log _{10} 10 = 20dB

Pendenza iniziale

Occorre guardare il tipo, ovvero l'esponente (solitamente si indica con la
lettera g) relativo al polo nell'origine. In questo caso s⁰ quindi il tipo
è zero. La pendenza iniziale è uguale a g=0.

Fase iniziale

La fase iniziale è uguale a \arg \left {μ\right }- g ·90^\circ = 0 - 0
·90^\circ = 0^\circ

Zeri e poli

Si individuano a questo punto gli zeri e i poli della funzione di
trasferimento:

{z}_{1} { = + 20}

{p}_{1} { = - 1}

{p}_{2} { = - 2}

I poli e gli zeri sono tutti reali (non complessi) e non nell'origine. Si
inseriscono questi valori in una tabella dove sono divisi i poli dagli zeri
e quelli a parte reale positiva da quelli a parte reale negativa da quelli
nell'origine.

Le caselle azzurre nella tabella evidenziano quali singolarità (poli o
zeri) fanno aumentare o diminuire di 90° il diagramma asintotico della
fase.

Pendenza finale

È data dal numero totale di zeri meno il numero totale di poli. Non è
necessaria per tracciare il diagramma del modulo ma consente di verificare
la correttezza dell'esercizio. In questo caso 1 – 2 = – 1.

Tracciamo ora i diagrammi asintotici di Bode sulla carta semilogaritmica.

Diagramma del modulo

Partiamo considerando una retta con pendenza iniziale 0 e che passa per il
punto iniziale 20dB (significa che nel punto di pulsazione 1 ha modulo
20dB).

In corrispondenza di ω=1 troviamo un polo, quindi la pendenza del diagramma
del modulo si abbassa di 20dB per decade. Lo stesso accade in ω=2, dove la
pendenza scende di altri 20 dB per decade fino a ω=20, dove troviamo uno
zero che aumenta la pendenza del diagramma di 20dB per decade.

Diagramma della fase

Possiamo ora tracciare il diagramma della fase. Sapendo che il diagramma ha
fase iniziale 0° traccio la prima parte del grafico asintotico.

In corrispondenza di ω=1 troviamo un polo a parte reale negativa che fa
abbassare il diagramma di 90° così come accade in ω=2 e, successivamente,
in ω=20 per via dello zero a parte reale positiva. I "+" e i "-" riportati
nelle caselle azzurre nella tabella servono proprio ad evidenziare quali
singolarità (poli o zeri) fanno aumentare o diminuire di 90° il diagramma
asintotico della fase.

Con lo zero si abbassa di ulteriori 90° in quanto questo è instabile,
avendo la parte reale positiva. Inoltre il comportamento della fase nei
diagrammi di Bode per i poli con parte reale positiva e gli zeri con parte
reale negativa è l'inverso di quello antecedentemente descritto.

Note

[1] Nella definizione di decibel c'è un fattore 10 e non 20. Si veda questo
  paragrafo.

Voci correlate

- Diagramma di Nyquist
- Luogo delle radici

Altri progetti

- Wikimedia Commons contiene immagini o altri file su Diagramma di Bode

Collegamenti esterni

- Bode Plot Applet - Mostra il grafico di modulo e fase dati i coefficienti
  della funzione di trasferimento

Diagramma di Nyquist

Nell'ambito della teoria dei sistemi, con diagramma di Nyquist (anche
chiamato Cole-Cole plot) si intende una particolare rappresentazione
grafica della funzione di trasferimento di un sistema dinamico lineare
stazionario. È un grafico utile nell'analisi dei sistemi di controllo
retroazionati, specificatamente in relazione alla verifica della stabilità.

La rappresentazione avviene su un grafico in coordinate polari in cui sono
disegnati la parte immaginaria e quella reale della funzione di
trasferimento al variare della pulsazione o frequenza angolare ω. Questo
diagramma utilizza un solo piano di riferimento, al contrario del diagramma
di Bode che rappresenta modulo e la fase della funzione ω in due distinti
piani cartesiani.

Il diagramma di Nyquist è uno dei metodi classici per valutare la stabilità
di un sistema lineare. Negli ultimi anni questi metodi sono integrati con
strumenti software per computer. Tuttavia restano un modo conveniente per
un ingegnere per avere un'idea intuitiva del comportamento di un sistema.

Stabilità di un sistema retroazionato

Si conviene che un sistema di controllo ad anello chiuso è stabile purché
qualsiasi eventuale oscillazione transitoria presente venga alla fine a
cessare ed il sistema raggiunga lo stato permanente di regime. Viceversa è
detto instabile se l'oscillazione transitoria non si esaurisce mai, ma
aumenta in ampiezza fino a distruggere il sistema stesso oppure a
raggiungere un limite conseguenza delle non linearità sistematiche.

Criterio di stabilità di Nyquist

L'attitudine del grafico di Nyquist alla valutazione della stabilità dei
sistemi retroazionati discende dal criterio di stabilità enunciato dallo
stesso Nyquist. Questo criterio permette di valutare la stabilità di un
sistema a retroazione dalla conoscenza del grafico polare della funzione di
trasferimento G(jω)H(jω) ad anello reattivo aperto (notazione in cui si
indica con j l'unità immaginaria), quando il segnale perturbatore sia di
tipo sinusoidale di frequenza variabile.

Costruzione del grafico

Generalmente per costruire tale grafico si interrompe l'anello di
retroazione del sistema considerato e si introduce un segnale a frequenza
variabile. Il rapporto tra l'ampiezza del segnale in uscita e l'ampiezza
del segnale in ingresso sia simboleggiato r, e la differenza di fase tra la
fase del segnale in uscita e la fase del segnale in ingresso sia
simboleggiata con θ. Il grafico che deriva dalla tracciatura in coordinate
polari di r in funzione di θ, per tutte le frequenze dell'intervallo da -∞
a ∞, costituisce il grafico di Nyquist.

La teoria a supporto di questo grafico polare di visualizzazione della
funzione armonica del sistema è basata sulla Mappa conforme. Se traccio una
curva chiusa, con un certo andamento e che non passi sui poli (le
singolarità), nel dominio, anche nel codominio troverò (grazie alla teoria
sopracitata) una curva chiusa.

Nella pratica si contano i giri attorno l'origine. Per convenzione il senso
antiorario è positivo per gli zeri e negativo per i poli.

  R = Z - P

Dove R è il numero di rotazioni nette positive in senso orario attorno al
nostro punto, Z è il numero degli zeri interni al percorso chiuso, P è il
numero dei poli. La scelta della curva chiusa nel dominio deve essere fatta
con astuzia, di solito include tutto il semipiano positivo incluso l'asse
immaginario. Questa curva viene chiamata Cammino di Nyquist.

Per analizzare la stabilità a ciclo chiuso di una funzione con il criterio
di Nyquist si disegna il diagramma in cinque comodi passaggi:

- Si traccia il Cammino di Nyquist in un piano di Gauss ove sono
  rappresentati Zeri e Poli
- Si osserva F(jω)
- Si crea una tabella calcolando Modulo, Fase, Parte Reale e Parte
  Immaginaria per i valori notevoli della frequenza w
- Si disegna il diagramma di Nyquist riportando i punti della tabella e
  unendoli
- Si analizza la stabilità e si svolgono le considerazioni finali (N = Z -
  P)

Valutazione della stabilità

Una volta tracciato il grafico polare occorre prendere in considerazione il
punto P sull'asse reale negativo di coordinate -1+j0. Sotto le ipotesi più
semplici il criterio di Nyquist stabilisce che il sistema in retroazione è
stabile se il numero di giri, compiuti in senso antiorario, che il
diagramma di Nyquist associato alla funzione di trasferimento compie
attorno al punto P di coordinate -1+j0 risulta uguale al numero di poli con
parte reale positiva della funzione di trasferimento stessa. Risulterà
instabile nel caso opposto.

Qualora abbia disegnato il diagramma di Nyquist e verificato la stabilità
per un sistema con guadagno K è inutile disegnarlo anche per K' = mK,
perché per verificare la stabilità con il nuovo guadagno basta considerare
al posto del punto -1+j0 il punto -1/m+j0.

Voci correlate

- Piano di Gauss
- Teoria dei sistemi
- Controlli automatici
- Diagramma di Bode

Altri progetti

- Wikimedia Commons contiene immagini o altri file su Diagramma di Nyquist

Criterio di Nyquist

In teoria dei sistemi il criterio di Nyquist determina la stabilità
asintotica di un sistema dinamico in retroazione.

Il criterio afferma che, dato un sistema di controllo in retroazione avente
funzione di trasferimento ad anello aperto G(jω)·H(jω), e se P è il numero
di poli di questa funzione a parte reale positiva, il sistema di controllo
è stabile se e solo se il diagramma di Nyquist della funzione d'anello
aperto compie esattamente P giri in senso antiorario attorno al punto
(-1,0).

Un caso particolare di questo criterio è il criterio di Bode, il quale
afferma che un sistema di controllo in retroazione, avente funzione
d'anello aperto stabile (P=0), è a sua volta stabile se e solo se il
diagramma di Nyquist della funzione d'anello aperto non compie giri attorno
al punto (-1,0).

Formulato nel 1932, discende direttamente dall'applicazione del criterio di
Mikhailov (metodo grafico per la determinazione della stabilità di
polinomi) ai denominatori della funzione d'anello, che a sua volta si basa
sul principio dell'argomento.

Voci correlate

- Diagramma di Nyquist
- Retroazione

Criterio di Routh-Hurwitz

In matematica, in particolare in algebra lineare, il criterio di
Routh-Hurwitz determina il numero di radici a parte reale positiva e
negativa di un polinomio a partire dai suoi coefficienti, migliorando il
criterio di Cartesio. Risulta utile per esempio per determinare la
stabilità di un sistema dinamico lineare e tempo-invariante a singolo
ingresso e singola uscita (SISO).

Derivazione

Il criterio è legato al teorema di Routh-Hurwitz: a-b=w(+\infty )-w(-\infty
), dove:

- a è il numero di radici a parte reale negativa della polinomiale f(z);
- b è il numero di radici a parte reale positiva della polinomiale f(z);
- w(x) è il numero di variazioni della successione di Sturm ottenuta da
  P₀₍ₓ₎ e P₁₍ₓ₎ (per successive iterazioni dell'algoritmo di Euclide) dove
  f(ix)=P₀₍ₓ₎₊iP₁₍ₓ₎ per un numero reale x.

Per il teorema fondamentale dell'algebra, ogni polinomiale di grado n deve
avere n radici complesse. Perciò, abbiamo la condizione che f sia un
polinomio stabile (Hurwitz) se e solo se a-b=n. Possiamo quindi sostituire
la condizione su a e b con una condizione sulla successione di Sturm, che
ci darà a sua volta una condizione sui coefficienti di f.

Descrizione

Sia dato il polinomio finito: p(x) = a_n x^n + a_{n-1} x^{n-1} + …+ a₀ ₌
₀nel quale si assuma aₙ > 0: si costruisce la matrice di Routh:

R (p) = \begin{bmatrix} a_n & a_{n-2} & a_{n-4} & a_{n-6} & … a_{n-1} &
a_{n-3}& a_{n-5} & … b_{n-1} & b_{n-2} & …& c_{n-2} & c_{n-3} & &
\end{bmatrix}

in cui gli elementi b_i e successivi sono legati ai coefficienti: ognuno
corrisponde al rapporto tra il determinante della matrice composta dagli
elementi delle due righe superiori, nella prima colonna e nella colonna
successiva a quella dell'elemento, ed il primo coefficiente (cambiato di
segno) della riga immediatamente sopra l'elemento che si sta calcolando:

b_{n-1} = \frac{ \begin{vmatrix} a_n & a_{n-2} a_{n-1} & a_{n-3}
\end{vmatrix} }{-a_{n-1}}
b_{n-2} = \frac{\begin{vmatrix} a_n & a_{n-4} a_{n-1} & a_{n-5}
\end{vmatrix} }{-a_{n-1}}
c_{n-2} = \frac{\begin{vmatrix} a_{n-1} & a_{n-3} b_{n-1} & b_{n-2}
\end{vmatrix} }{-b_{n-1}}
  c_{n-3} = \frac{\begin{vmatrix} a_{n-1} & a_{n-5} b_{n-1} & b_{n-3}
  \end{vmatrix} }{-b_{n-1}} ossia più in generalek_{i,j} =
  \frac{\begin{vmatrix} k_{i-2,1} & k_{i-2,j+1} k_{i-1,1} & k_{i-1,j+1}
  \end{vmatrix} }{-k_{i-1,1}}

La costruzione termina non appena rimane un'unica matrice quadrata a
determinante nullo, cioè due coefficienti consecutivi ad un solo valore
ciascuno. Infatti, dove non presenti, gli elementi delle matrici sono da
considerarsi nulli.

Ogni variazione (permanenza) del segno dei coefficienti della prima colonna
corrisponde ad una radice a parte reale positiva (negativa).

Presenza di zeri sulla prima colonna

Nel caso in cui un termine della prima colonna è nullo, esistono quattro
diversi metodi.

Primo metodo

Sostituendo allo 0 il simbolo ε a rappresentare un numero molto piccolo,
tendente a 0⁺ o a 0^-.

Se gli altri numeri della prima colonna sono tutti positivi allora ε→0⁺.

Se gli altri numeri della prima colonna sono tutti negativi allora ε→0^-.

Altrimenti si devono considerare entrambi i casi ε→0⁺ e ε→0^-.

Ad esempio:

R (x^5 + 2x^4 + 2x^3 + 4x^2 + 3x) = \begin{bmatrix} 1 & 2 & 3 2 & 4 & 0 0 &
3 & 0 \end{bmatrix}

diventa sostituendo lo 0 con ε→0⁺

R (x^5 + 2x^4 + 2x^3 + 4x^2 + 3x) = \begin{bmatrix} 1 & 2 & 3 2 & 4 & 0 ε&
3 & 0 \frac{4ε-6}{ε} & 0 & 0 3 & 0 & 0 \end{bmatrix}

si vede chiaramente che ε> 0 ma \frac{4ε-6}{ε} < 0

Tale metodo è a rigore giustificato solamente quando il polinomio non ha
zeri sull'asse immaginario; per questo motivo in alcuni casi può dar luogo
ad errori (come si può vedere analizzando R(x⁶ ⁺ x⁵ ⁺ ³x⁴ ⁺ ³x³ ⁺ ³x² ⁺ ²x
+1)).

Secondo metodo

Si può moltiplicare il polinomio dato per un binomio con zero negativo (si
aggiunge così uno zero negativo al polinomio, permettendo di analizzare i
segni degli altri zeri): essendo p(x) il polinomio originale, si passa a
studiare il polinomio p(x)·(x-c)

Ad esempio:

R(x^4 + 2x^3 + 3x^2 + 6x + 4) = \begin{bmatrix} 1 & 3 & 4 2 & 6 & 0 0 & 4 &
0 \end{bmatrix}

quindi possiamo aggiungere, per esempio, uno zero in -1:

p(x) ·(x + 1) = x⁵ ⁺ ³x⁴ ⁺ ⁵x³ ⁺ ⁹x² ⁺ ¹⁰x + 4
R(x^5 + 3x^4 + 5x^3 + 9x^2 + 10x + 4) = \begin{bmatrix} 1 & 5 & 10 3 & 9 &
4 2 & \frac{26}{3} & 0 -4 & 4 & 0 \frac{32}{3} & 0 & 0 4 & 0 & 0
\end{bmatrix}

Terzo metodo

È applicabile anche in presenza di più zeri consecutivi sulla stessa riga.
Consiste nel sostituire la riga in questione con la stringa di numeri
ottenuti sommando all'i-esimo elemento della riga l'elemento di posto i+j
nella stessa riga moltiplicato per (-1)^j, essendo j il numero dei primi
elementi nulli.

Ad esempio:

R (x^5 + 5x^3 + 10x + 4) = \begin{bmatrix} 1 & 5 & 10 0 & 0 & 4 0 & 0 & 0
\end{bmatrix}

Al posto del primo 0 si prende 4 (che è il primo elemento non nullo della
riga) e lo si moltiplica per (-1)² essendo 2 gli zeri consecutivi prima del
4.

R(x^5 + 5x^3 + 10x + 4) = \begin{bmatrix} 1 & 5 & 10 4 & 0 & 4 5 & 9 & 0
-\frac{36}{5} & 4 & 0 \frac{106}{9} & 0 & 0 4 & 0 & 0 \end{bmatrix}

Quarto metodo

Può accadere che tutti i termini di una riga siano nulli solo se la riga è
di ordine dispari; infatti le due righe precedenti devono essere
proporzionali e quindi devono avere lo stesso numero di elementi (si noti
che nel passare da una riga dispari ad una pari sottostante il numero di
elementi non cambia). In questa circostanza si può concludere che il
polinomio considerato è il prodotto di due polinomi: il primo avrà zeri che
hanno parte reale caratterizzata dalle variazioni di segno degli elementi
della prima colonna della tabella sinora costruita (gli zeri di p₁₍ₓ₎ a
parte reale positiva sono tanti quante le variazioni di segno che sono
apparse nella prima colonna della tabella costruita fino a quel momento);
il secondo polinomio p₂₍ₓ₎ (che si chiama equazione ausiliaria) è di grado
uguale all'indice della riga che precede la riga che si è annullata, ha
solo potenze di grado pari ed i suoi coefficienti sono nell'ordine da
quello di grado massimo a quello di grado 0, i coefficienti della riga che
precede quella che si è annullata.

Ad esempio:

R (x^5 + x^4 + 3x^3 + 3x^2 + x + 1) = \begin{bmatrix} 1 & 3 & 1 1 & 3 & 1 0
& 0 & 0 \end{bmatrix}
x⁵ ⁺ x⁴ ⁺ ³x³ ⁺ ³x² ⁺ x + 1 = p₁₍ₓ₎ ₚ₂₍ₓ₎

p₁₍ₓ₎ è di primo grado ed ha uno zero negativo, p₂₍ₓ₎ di grado 4 con
potenze solo di ordine pari:

p₂₍ₓ₎ ₌ ₓ⁴ ⁺ ³x² ⁺ ¹

Per p₂₍ₓ₎ possiamo calcolare gli zeri, ma nel caso il grado fosse troppo
alto potrebbero esserci difficoltà. Allora la costruzione della tabella può
riprendere in un altro modo. Si deriva p₂₍ₓ₎

p₂'(x) = 4x³ ⁺ ⁶x

e ai coefficienti della riga nulla (in questo caso la terza) si
sostituiscono questi nuovi coefficienti:

R (4x^3 + 6x) = \begin{bmatrix} 1 & 3 & 1 1 & 3 & 1 4 & 6 & 0 \frac{3}{2} &
1 & 0 \frac{10}{3} & 0 & 0 1 & 0 & 0 \end{bmatrix}

Si osservi che gli zeri del polinomio p₂₍ₓ₎, con potenze di grado solo
pari, hanno una doppia simmetria rispetto a ciascun asse del piano
complesso. Questo assicura che se non vi sono zeri a parte reale positiva
tutti si trovano sull'asse immaginario. Più precisamente la seconda parte
della tabella deve essere così interpretata: si contano solo le variazioni
di segno corrispondenti alle radici a parte reale positiva, che indichiamo
con np; siano nn = np le radici a parte reale negativa (data la doppia
simmetria detta anche simmetria quadrantale), se l'equazione ausiliaria è
di grado n, allora le rimanenti n - np -nn radici si trovano sull'asse
immaginario. Nel nostro esempio l'equazione ausiliaria è di grado 4, quindi
n = 4. Le variazioni sono np = 0, quindi ci sono nn=0 radici a parte reale
negativa e quindi 4 - 0 - 0 = 4 radici sull'asse immaginario.

Bibliografia

- A.Hurwitz, Math. Ann., Vol. 46, 1895, p. 273-284.

Voci correlate

- Criterio di Cartesio
- Matrice di Hurwitz
- Criterio di Jury

Collegamenti esterni

- Codice MatLab per il criterio di Routh, mathworks.com.

Controllore logico programmabile

Il Controllore a Logica Programmabile o Programmable Logic Controller (PLC)
è un controllore per industria specializzato in origine nella gestione o
controllo dei processi industriali.

Il PLC esegue un programma ed elabora i segnali digitali ed analogici
provenienti da sensori e diretti agli attuatori presenti in un impianto
industriale. Nel tempo, con la progressiva miniaturizzazione della
componentistica elettronica e la diminuzione dei costi, è entrato anche
nell'uso domestico; l'installazione di un PLC nel quadro elettrico di
un'abitazione, a valle degli interruttori magnetotermico e differenziale
(salvavita), permette la gestione automatica dei molteplici sistemi e
impianti installati nella casa: impianto di riscaldamento, antifurto,
irrigazione, LAN, luci, ecc.

Un PLC è un oggetto hardware componibile. La caratteristica principale è la
sua robustezza estrema; infatti normalmente il PLC è posto in quadri
elettrici in ambienti rumorosi, con molte interferenze elettriche, con
temperature elevate o con grande umidità. In certi casi il PLC è in
funzione 24 ore su 24, per 365 giorni all'anno, su impianti che non possono
fermarsi mai.

La struttura del PLC viene adattata in base al processo da automatizzare.
Durante la progettazione del sistema di controllo, vengono scelte le schede
adatte alle grandezze elettriche in gioco. Le varie schede vengono quindi
inserite sul BUS o rack del PLC.

Funzionamento¹

La prima azione che il PLC compie è la lettura degli ingressi del portale e
si intende tutti gli ingressi sia digitali sia analogici, on board o su bus
di campo (schede remote collegate al PLC o con una rete di comunicazione).
Dopo aver letto tutti gli ingressi, il loro stato viene memorizzato in una
memoria che è definita "Registro immagine degli ingressi". A questo punto
le istruzioni di comando vengono elaborate in sequenza dalla CPU e il
risultato viene memorizzato nel "Registro immagine delle uscite". Infine,
il contenuto dell'immagine delle uscite viene scritto sulle uscite fisiche
ovvero le uscite vengono attivate. Poiché l'elaborazione delle istruzioni
si ripete continuamente, si parla di elaborazione ciclica; il tempo che il
controllore impiega per una singola elaborazione viene detto tempo di ciclo
(solitamente da 10 a 100 millisecondi).

Struttura del PLC

Un PLC è composto da un alimentatore, dalla CPU che in certi casi può avere
interna o esterna una memoria di tipo RAM, ROM, EPROM o EEPROM, da un certo
numero di schede di ingressi digitali e uscite digitali, e nel caso in cui
sia necessario gestire grandezze analogiche, il PLC può ospitare delle
schede di ingresso o di uscita sia analogiche che digitali.

Se il PLC opera in rete con altri PLC, sono necessarie delle schede di
comunicazione adatte al protocollo di rete già implementato sugli altri
PLC.

Nel caso di operazioni di movimentazione, come nel campo della robotica, il
PLC ospita delle schede di controllo assi, cioè delle schede molto veloci e
sofisticate che permettono di gestire spostamenti e posizionamento.

Alimentatore

L'alimentatore è un apparato necessario per il funzionamento dei PLC. Esso
è utilizzato per fornire l'energia elettrica a tutte le schede del PLC.
Fornisce le tensioni a 5 V necessarie alle schede, le tensioni a + o - 12
V, le altre tensioni necessarie, sempre in corrente continua (cc.). Può
essere interno o esterno al PLC. Nella normalità dell'uso, in campo
industriale, l'alimentazione è a 24 V c.c. compatibile con la maggior parte
dei sensori in commercio.

CPU

La CPU è il cervello del PLC. La CPU è una scheda complessa basata su una
logica programmabile (Infineon sulle CPU Siemens S7) con funzionalità base
di memorizzazione e accesso ad I/O, nonché bootloader, e con una zona di
memoria a disposizione del programma utente, cioè del programma di
automazione.

La memoria utente è spesso esterna come ad esempio nel caso di memoria
EPROM. Il vantaggio di una memoria esterna è legata alla semplicità di
programmazione o di modifica dello stesso.
La CPU durante il funzionamento a regime, colloquia con tutte le schede
connesse sul BUS del PLC, trasferendo dati e comandi da e verso il mondo
esterno (input e output).

Una delle caratteristiche peculiari di molte CPU è la capacità di poter
gestire le modifiche del programma di gestione del processo durante il
normale funzionamento. Questa possibilità è estremamente utile nel caso di
impianti che devono essere sempre attivi, come ad esempio nel controllo di
processo e nella produzione industriale in serie.

All'interno della CPU ci sono varie parti, tra cui

- unità di gestione, ovvero informazioni di gestione del PLC stesso,
  impostate dal costruttore e trasparenti all'utente;
- archivio di temporizzatori e contatori funzionali all'operatività del
  PLC;
- memorie immagine del processo, cioè le informazioni in ingresso ed i
  comandi in uscita del processo;
- memoria utente, in cui vengono scritti i programmi che il PLC deve
  eseguire;
- interfaccia per il dispositivo di programmazione, che comunica con gli
  strumenti di programmazione;
- bus dati, comando, indirizzi per la veicolazione dei dati fra le varie
  parti e con l'esterno della CPU.

Schede di ingresso digitali

Le schede di ingresso digitali sono utilizzate per il controllo di
grandezze "digitali", cioè di tensioni a due valori (ad esempio 0 V o 24 V,
oppure 0 V 110 V). Ogni scheda può gestire da 4 a 32, o 64 ingressi
digitali differenti. I segnali dal campo vengono fatti arrivare con cavi
elettrici fino alla morsettiera della scheda ed ogni singolo canale è
opportunamente protetto da fusibili di adeguato valore.

Schede di uscita digitali

Le schede di uscita digitali sono utilizzate per i comandi di attuatori
digitali. Ad esempio un relè è un attuatore digitale, in quanto può avere
soltanto due stati stabili: diseccitato, o eccitato. Altro esempio di
attuatore è una valvola digitale a due stati: aperta, chiusa
(elettrovalvola). Anche nel caso di schede di uscita digitali, si possono
gestire da un minimo di 4 ad un massimo di 64 uscite digitali differenti.

Schede di ingresso analogiche

Questo tipo di schede di ingresso permettono il controllo di grandezze
elettriche il cui valore può variare entro un intervallo. Le grandezze in
gioco sono in tensione o in corrente. Ad esempio sono disponibili schede di
ingresso analogiche in corrente, con un intervallo variabile tra 4 mA e 20
mA. Molti produttori di PLC rendono disponibili schede con ingressi
analogici per sonde di temperatura sia Pt100 che termocoppie T, J, K, ecc.
Queste schede sono disponibili con varie risoluzioni (8-12-14-16 bit) e con
1 o più ingressi separati galvanicamente disponibili in morsettiera o sul
connettore frontale.

Schede di uscita analogiche

Le schede di uscita analogiche permettono di controllare degli attuatori
variabili. Possono essere in corrente o in tensione ed avere una
determinata risoluzione esprimibile in bit. Ad esempio è possibile
comandare un motore elettrico tramite un inverter variandone la velocità,
tramite la frequenza, da zero alla sua massima velocità. Oltre all'esempio
sopra citato servono per regolazioni di temperatura variando l'intervallo
di uscita, regolazioni di luce. Un esempio che può risultare molto chiaro è
quella dell'intensità luminosa di una serie di plafoniere. Tramite un
potenziometro noi aumenteremo o diminuiremo l'intensità luminosa. Ad ogni
aumento o diminuzione di luce corrisponde un equivalente segnale in
corrente o in tensione.

Schede di comunicazione

Il PLC durante il suo funzionamento può comunicare con computer, con altri
PLC oppure con altri dispositivi come le macchine CNC (i torni e/o le frese
a controllo numerico delle aziende).

La comunicazione con computer e altri dispositivi avviene tramite tipi di
connessione standard come:

- RS232
- RS422/RS485
- TCP/IP

La comunicazione con altri PLC avviene tramite protocolli standard, ad
esempio:

- Profibus
- Profinet
- DeviceNet
- Wi-Fi 802.11
- TCP/IP
- Modbus
- Modbus Plus
- Modbus TCP/IP
- Controlnet
- EGD
- UDP/IP
- CAN BUS

ecc.

Schede speciali

Qualunque PLC di livello medio alto, oltre le consuete schede di
ingresso/uscita, analogiche/digitali, ha a catalogo moduli dedicati a
particolari compiti di automazione. Il vantaggio nell'utilizzare tali
schede è quello di avere il controllo di un'operazione/evento
indipendentemente dal ciclo del PLC, relegando il PCM alla funzione di
controllo/parametrizzazione. L'offerta è veramente vasta e ogni produttore
propone a catalogo le più svariate soluzioni, fra cui si segnala:

Schede di conteggio veloce

Sono in grado di accogliere il segnale di un sensore di conteggio e
direzione (up/down ossia incremento/decremento) più un canale di
azzeramento, sia in single ended (ossia a livelli di tensione 0÷24 V) che
in differenziale (normalmente secondo lo standard RS-422); normalmente è
possibile programmarle in modo che scatenino un evento (per esempio alzando
un'uscita) al raggiungimento di un dato conteggio o se il conteggio è
compreso fra una finestra di valori. Su tali schede sono normalmente
disponibili un numero limitato di uscite programmabili.

Schede programmatori a camme

Compito di tali schede è emulare una o più camme meccaniche; accettano in
ingresso un segnale proveniente da un encoder ed è possibile, se la
posizione è entro determinate finestre, avviare un evento tramite un'uscita
digitale programmabile.

Schede PID (Proporzionale Integrale Derivativo)

Spesso nel campo industriale è necessario controllare una variabile del
processo (per esempio la potenza applicata su un elemento riscaldante),
rilevando una variabile da esso dipendente (per esempio la temperatura di
un ambiente). Se il processo è particolarmente critico è necessario
eseguire il controllo in modo accurato, tramite moduli dedicati.
In passato, prima dell'avvento dei controllori logici programmabili (PLC),
esistevano moduli hardware, in qualche caso realizzati con tecnologie
ibride meccaniche, pneumatiche, elettromeccaniche, in grado di svolgere la
regolazione sommando le tre azioni proporzionale, integrativa e derivativa,
ma al giorno d'oggi sono realizzati dalle stesse case produttrici dei PLC,
non solo come blocchetti aggiuntivi hardware, ma anche come blocchi
software a cui è sufficiente passare i corretti parametri.

Schede controllo assi

Si impiegano ove sia necessario controllare il movimento di un organo
meccanico tramite un motore, sia esso brushless che passo passo. Alcune
schede presentano un funzionamento particolarmente semplice permettendo di
fissare una quota di consegna che l'asse deve raggiungere e un ingresso per
il feedback di posizione, altre - particolarmente complesse - permettono
grandissima flessibilità e permettono di emulare diversi profili.
Richiedono generalmente un modulo di potenza esterno (amplificatore di
corrente) per il comando effettivo del motore.

Linguaggi di programmazione

Il PLC per ottemperare ai suoi compiti deve essere programmato. La
programmazione del PLC è effettuata normalmente con un PC sul quale un
software specializzato permette di creare programmi da scaricare nella
memoria della CPU del PLC.

Questi software di programmazione possono leggere il programma direttamente
dalla memoria della CPU, e visualizzare il programma sul PC. Normalmente il
programma viene scritto su PC, quindi scaricato sul PLC, e salvato sul PC
stesso, per ulteriori modifiche o per sicurezza.

La normativa IEC 1131-3 del 1993 ha standardizzato 5 linguaggi di
programmazione, di cui 3 grafici e 2 testuali.

La Normativa è stata successivamente aggiornata con l'uscita della "CEI EN
61131-3" detta anche "CEI 65-40" Prima Edizione: 1º giugno 1996.

Linguaggi grafici

- Ladder diagram (LD o KOP) detto Linguaggio a contatti - Era il linguaggio
  più usato fino a pochi anni fa, in quanto era la trasposizione
  informatica dei circuiti elettrici usati dagli elettrotecnici.
L'automazione industriale infatti era basata su sistemi a logica cablata,
  il PLC (controllore di logica programmabile) ha permesso di trasportare i
  concetti della logica cablata nel linguaggio Ladder. Il programmatore
  semplicemente utilizza simboli logici corrispondenti a segnali di
  ingresso e di uscita per implementare la logica non più cablando i relè,
  ma disegnando gli schemi elettrici nel software di programmazione.
- Sequential function chart (SFC) detto Diagramma funzionale sequenziale -
  Viene usato anche come strumento di specifica. Tale linguaggio permette
  di implementare facilmente una macchina (o automa) a stati finiti.
- Function Block Diagram (FBD o FUP) detto Diagramma a blocchi funzionali -
  Analogo ai diagrammi circuitali.

Linguaggi testuali

- Instruction List (IL o AWL) detto Lista di istruzioni - Linguaggio di
  basso livello, diffuso nelle maggior ditte di programmazione con plc,
  molto simile all'Assembly (linguaggio di basso livello). Può essere
  facilmente ricavato dal Ladder e permette una programmazione più
  strutturata rispetto a quest'ultimo, infatti molti lo preferiscono per
  questo fattore.
- Structured Text (ST) detto Testo strutturato - Linguaggio di alto livello
  simile al Pascal.

Il PLC rispetto ad altri sistemi di controllo

I PLC si adattano bene a una serie di compiti di automazione. Questi sono
in genere processi industriali nel settore manifatturiero, dove i costi di
sviluppo e manutenzione del sistema di automazione è elevato rispetto al
costo totale dell'automazione, e dove sono attese modifiche al sistema
durante la sua vita operativa. I PLC contengono dispositivi di input e
output compatibili con i dispositivi pilota ed i controlli industriali;
richiedono poca progettazione elettrica, ed il problema del progetto è
focalizzato sulla sequenza desiderata di operazioni. Le applicazioni PLC
sono tipicamente sistemi altamente personalizzati, per cui il costo di un
PLC preconfezionato è basso rispetto a quanto costerebbe il progetto di un
controllore su misura. Per contro, nel caso di prodotti di massa, sistemi
di controllo personalizzati risultano economici. Ciò è dovuto al minor
costo dei componenti, che possono essere scelti in modo ottimale al posto
di una soluzione "generica", e dove i costi di progetto non ricorrenti sono
distribuiti su migliaia o milioni di unità.

Per applicazioni in grandi numeri o nel caso di compiti di automazione
fissi e molto semplici, vengono utilizzate tecniche diverse. Per esempio,
una lavastoviglie casalinga potrebbe essere controllata da un
temporizzatore elettromeccanico a camme che costa pochissimo se prodotto in
grandi quantità.

Un progetto basato su microcontrollore sarebbe appropriato qualora vengano
prodotte centinaia o migliaia di unità e quindi il costo di sviluppo
(progettazione di alimentatori, hardware di ingresso/uscita e necessario
test e certificazione) possa essere ripartito su molte vendite, e dove
l'utente finale non necessiti di modificare il controllo. Un esempio è
costituito dalle applicazioni automotive; milioni di unità sono costruite
ogni anno, e molto pochi utenti finali alterano la programmazione di questi
controllori. Tuttavia, alcuni veicoli speciali quali autobus di linea
utilizzano economicamente i PLC invece di controlli progettati su misura,
perché i volumi sono bassi e il costo di sviluppo sarebbe antieconomico.²

Un controllo di processo molto complesso, come ad esempio quello utilizzato
in un impianto chimico, può richiedere algoritmi e prestazioni al di là
della capacità di PLC anche ad alte prestazioni. Controlli di precisione o
ad elevata velocità possono anche richiedere soluzioni personalizzate; ad
esempio comandi di volo degli aeromobili. Per applicazioni di controllo
molto esigenti, nelle quali può essere sostenuto l'elevato costo di
sviluppo e manutenzione, si possono utilizzare dei single-board computer
che utilizzino hardware semi-personalizzato o completamente proprietario. I
"Soft PLC" in esecuzione su computer desktop sono in grado di
interfacciarsi con l'hardware di I/O industriale eseguendo programmi su una
versione di sistemi operativi commerciali adattata per le esigenze di
controllo di processo.²

Note

[1] Marco Gottardo, lulu.com (ed), Let's Program a PLC (seconda edizione)
  (in Italiano), Lulu.com, 2012 ISBN 1291189327
[2] Gregory K. McMillan, Douglas M. Considine (ed), Process/Industrial
  Instruments and Controls Handbook Fifth Edition (in Inglese),
  McGraw-Hill, 1999 ISBN 0-07-012582-1 Section 3 Controllers

Voci correlate

- Controllo industriale

Altri progetti

- Wikimedia Commons contiene immagini o altri file su Controllore logico
  programmabile

Collegamenti esterni

- PLC Forum - Il forum di riferimento italiano su PLC ed automazione,
  plcforum.it.
- Automationforum - Portale per l'automazione industriale con risorse per
  il programmatore di applicazioni MES, SCADA, HMI, PLC bus di campo per
  l'industria., automationforum.it.
- Atipica micro PLC
- Automated Manufacturing Systems; PLCs, eod.gvsu.edu.
- PLC - Controllori a logica programmabile - Un corso sulla programmazione
  dei PLC
- Progetto di Soft PLC - Open source e Open hardware, theremino.com.

Strumentazione di controllo

La strumentazione di controllo o strumentazione di processo in un complesso
industriale può essere definita come l'insieme degli strumenti di
misurazione, regolazione, e controllo del processo industriale stesso, che
formano, nel loro insieme una catena di regolazione (detta anche loop di
regolazione).

Il termine "controllo", riferito ai controlli automatici dei processi è
utilizzato nell'ingegneria per fare riferimento ad un insieme di tecniche e
tecnologie utili all'automatizzazione degli impianti industriali.

I processi degli impianti chimici e petrolchimici richiedono infatti la
regolazione dei valori di parametri fisici e/o chimici per poter mantenere
in corretta efficienza gli impianti stessi, e produrre ciò che è stato
progettato. I parametri maggiormente interessati sono ad esempio pressione,
temperatura, portata, livello, ma anche altri come pH e peso.

La strumentazione di processo può essere pneumatica (in disuso) o
elettronica (analogica o digitale), a seconda della natura del segnale
(pneumatico o elettronico) impiegato per mettere in comunicazione gli
strumenti.

Catena di regolazione

La catena di regolazione è formata da diversi componenti, ciascuno con la
propria funzione specifica:

- Trasmettitori del valore del parametro da tenere sotto controllo
- Controllore
- Organo finale di regolazione (ad esempio valvola di regolazione con
  attuatore)

Altri componenti ausiliari possono essere:

- Trasduttori di segnale
- Generazione e trattamento aria compressa
  + Motore pneumatico (o compressore)
  + Tubazioni
  + Raccordi
  + Filtri
  + Lubrificatori
  + Riduttore di pressione

Trasmettitore

Il trasmettitore è uno strumento installato sull'impianto (in campo). Ha un
sensore che è in contatto fisico col processo e del quale misura il valore
istantaneo della grandezza interessata. Ad esempio può essere una
termocoppia per la misura della temperatura, oppure una molla Bourdon per
la misura della pressione.

I parametri che è necessario misurare possono essere molteplici secondo le
necessità di processo. I più comuni sono i trasmettitori di temperatura,
pressione, portata, livello ecc. Il segnale misurato da questo sensore
viene trasdotto in modo proporzionale, all'interno del trasmettitore, in un
altro segnale standardizzato che viene trasmesso alla sala controllo verso
il proprio strumento regolatore.

Se è un trasmettitore pneumatico invierà attraverso un tubicino di rame una
pressione di aria compresa nel campo fra 3 e 15 psi. Se è un trasmettitore
elettrico trasmetterà una corrente elettrica continua compresa tra 4 e 20
mA, ecc. I trasmettitori hanno un proprio campo di misura, ed il valore del
segnale trasmesso è proporzionale al valore misurato.

Strumenti regolatori

Gli strumenti regolatori sono in generale installati in una sala controllo
centralizzata, su appositi pannelli che li raggruppano assieme ad altri
componenti di verifica e controllo dell'impianto.
Il regolatore riceve il segnale dal proprio trasmettitore (che da ora in
poi chiameremo semplicemente "misura"), ne confronta il valore istantaneo
con un valore prefissato (set point) che la grandezza misurata deve
assumere, ed invia in campo un segnale ad un attuatore o organo finale di
regolazione.

Organo finale di regolazione

Un tipico organo finale di regolazione è costituito dalla valvola di
regolazione a comando pneumatico, la cui apertura influenza la portata di
una corrente fluida, e indirettamente il valore della grandezza misurata.

In questa maniera il valore della grandezza misurata viene costretto ad
avvicinarsi a quello fissato dal controllore (set point).

Descrizione di una valvola di regolazione

La valvola di regolazione ha un corpo inserito nel fluido di processo.
All'interno del corpo c'è un otturatore che compie un movimento relativo ad
una sede. Lo spostamento dell'otturatore varia l'area di passaggio del
fluido e quindi la sua portata.

Lo stelo è collegato meccanicamente all'esterno, e con tenuta stagna, al
servomotore, associato ad una membrana di gomma sulla quale è applicata la
pressione di comando. La membrana è contrastata da una molla che dà il
rapporto di proporzionalità tra valore di segnale di comando e posizione
dello stelo.

Le valvole possono essere normalmente aperte (NO) e normalmente chiuse
(NC). La parola "normalmente" indica senza aria di comando sulla membrana.
Così quelle NO chiudono quando ricevono aria di comando sulla membrana;
quella NC aprono quando ricevono l'aria di comando sulla membrana.

Così ad esempio, per una valvola con azione aria-chiude si avrà la
posizione di apertura per pressione di comando di 3 psi; si avrà valvola
tutta chiusa per pressione di 15 psi. Per valori intermedi si avranno
posizioni intermedie proporzionali (ad esempio 9 psi daranno una corsa al
50%).

Molte volte la pressione di comando non viene inviata direttamente al
servomotore pneumatico, per evitare ritardi nell'azionamento. Viene usato
invece un dispositivo pneumatico chiamato posizionatore montato sulla
valvola. Il segnale di comando entra nel posizionatore, e da questi esce
l'aria per comandare la valvola. Il posizionatore è collegato
meccanicamente allo stelo per misurarne la posizione ed obbligarlo ad
assumere il valore fissato dal segnale di comando.

Le valvole di regolazione sono generalmente a due vie (un ingresso ed una
uscita). Esistono però altri modelli come quelle a tre vie (due ingressi ed
una uscita). Queste sono usate per miscelare in modo continuo due fluidi,
come ad esempio funzionano i miscelatori dei lavandini nei bagni domestici.

Regolazione in cascata

In alcune tipologie di processo nei quali il controllo risulterebbe
difficile e poco stabile viene usata la "regolazione in cascata". Il loop
di controllo è in questo caso formato da cinque componenti invece dei
classici tre. Lo scopo finale è sempre quello di tenere costante e sotto
controllo un importante parametro di processo, agendo però sul valore di un
secondo parametro capace di influenzare il primo.

Il primo parametro viene misurato da un trasmettitore, che invia il suo
segnale al primo regolatore. L'uscita da questi va a pilotare il set point
di un secondo regolatore, la cui uscita comanda l'organo finale di
regolazione. Un secondo trasmettitore che misura il secondo parametro del
processo rappresenta il segnale di misura del secondo regolatore. pertanto
il primo regolatore non agisce direttamente sull'organo finale di
regolazione, ma va a comandare il valore che deve assumere il secondo
parametro.

Mentre il primo regolatore è dedicato a mantenere costante il valore del
primo parametro, il secondo regolatore è dedicato a mantenere coincidenti
il valore di set point (ricevuto dall'uscita del primo regolatore), col
valore della propria variabile misurata dal secondo trasmettitore.

La regolazione in cascata risulta particolarmente efficace perché il
secondo regolatore si occupa di tenere sotto controllo i disturbi e le
variazioni che il primo regolatore, dato il tipo di processo, non avrebbe
la capacità di gestire efficacemente.

Caratteristiche dei segnali pneumatici

Il segnale che intercorre tra i componenti di una strumentazione pneumatica
è costituito da una pressione di aria compresa fra 3 e 15 psi.

I segnali di pressione vengono trasmessi attraverso tubicini di rame avente
diametro esterno di 6 mm, e diametro interno di 4 mm, giuntati con raccordi
a compressione a tenuta stagna.

Gli strumenti pneumatici, per erogare questa pressione, vengono alimentati
da aria alla pressione di 20 psi (circa 1,4 kg/cm²) tramite un riduttore di
pressione individuale connesso alla rete generale di stabilimento di aria
compressa.

Gruppo generazione e trattamento aria compressa

Lo stabilimento ha una rete interna di aria compressa che alimenta tutta la
strumentazione pneumatica. L'aria viene aspirata dall'atmosfera e compressa
in un apposito serbatoio dopo essere stata filtrata e deumidificata.

Dal serbatoio si diramano quindi le tubazioni per alimentare tutte le
utenze. La pressione di tale rete è piuttosto alta e può variare, secondo
gli impianti, da 4 a 16 bar. Le varie apparecchiature pneumatiche hanno
bisogno di una pressione inferiore e costante, e a tale scopo vengono
utilizzati riduttori di pressione di gruppo o individuali.

A questo punto l'aria è alla pressione che vogliamo, essiccata e filtrata.
Alcune utenze possono richiedere anche l'inserimento di un lubrificatore,
necessario per l'azionamento di organi mobili come pistoni pneumatici.

Strumentazione elettronica analogica

La strumentazione di processo invia e riceve segnali elettrici o digitali
con valore proporzionale al valore della grandezza di misura o di comando.

Un tipico segnale elettrico standard analogico è in corrente continua
compresa tra 4 e 20 mA. Si parla in questo caso di zero vivo, nel senso che
un segnale di 0 mA è indice di un malfunzionamento delle apparecchiature.

Così per esempio un trasmettitore di pressione avente un campo di misura da
0 a 20 bar invierà una corrente di 4 mA quando la pressione misurata è
zero, invierà una corrente in uscita di 20 mA per pressione misurata di 20
bar e invierà valori intermedi di corrente direttamente proporzionali al
valore misurato (in questo esempio invierà una corrente di 12 mA quando la
pressione misurata è 10 bar (50% del suo campo di misura, corrisponde ad
una corrente in uscita di (20-4)/2+4 = 12 mA). Naturalmente in questi casi
anche i regolatori saranno compatibili con tale segnale da 4 a 20 mA sia in
ingresso che in uscita verso il campo.

La strumentazione elettronica si può usare negli impianti chimici e
petrolchimici quando essa è costruita con la tecnologia della sicurezza
intrinseca. L'energia di una possibile scintilla non è capace di innescare
l'accensione di miscele esplosive. Negli anni passati, quando non esisteva
ancora tale tecnologia, era stata sviluppata efficacemente la
strumentazione pneumatica. Pur non essendo estremamente precisa, aveva
l'indubbio vantaggio di poter operare in tutta sicurezza negli impianti
chimici e petrolchimici, dove il rischio di incendi ed esplosioni a causa
di scintille elettriche è sempre presente.

Oggigiorno, pur con la strumentazione elettronica, l'organo finale di
regolazione è sempre ad azionamento pneumatico. Il posizionatore riceve il
segnale di comando analogico da 4 a 20 mA e invia aria compressa modulata
alla testa della valvola.

Strumentazione digitale

Con lo sviluppo dei microprocessori e dei microcontrollori e della loro
diffusione, si è arrivati al controllo digitale, definito come analisi e
sintesi di un sistema di controllo in retroazione in cui è presente un
calcolatore digitale e quindi una componente a tempo discreto.

Note

Bibliografia

- (EN) George Stephanopoulos, Chemical Process Control: An Introduction to
  Theory and Practice, Prentice Hall PTR, 1983, ISBN 0-13-128629-3.
- (EN) William Luyben, Process Modeling, Simulation and Control for
  Chemical Engineers, McGraw-Hill Companies, 1989, ISBN 0-07-039159-9.
- (EN) AAVV, Ullmann's Encyclopedia of Industrial Chemistry, "Process
  Control Engineering", Wiley-VCH Verlag GmbH & Co. KGaA, 2002,
  DOI:10.1002/14356007.b06_317.

Voci correlate

- Apparecchiature chimiche
- Controllabilità
- Controllo automatico
- Masoneilan
- Piping & Instrumentation Diagram
- Pneumatica (scienza)
- Programmable logic controller
- Strumento di misura
- Strumento di misura analogico
- Strumento di misura digitale

Altri progetti

- Wikimedia Commons contiene immagini o altri file su Strumentazione di
  controllo

Pneumatica (scienza)

La pneumatica dal greco πνευματικός ("pneumatikos, proveniente dal vento")
è una branca della fisica e della tecnologia che studia il trasferimento di
forze mediante l'utilizzo di gas in pressione, molto spesso aria compressa.

Applicazioni

La pneumatica è una scienza che trova larga applicazione nel campo
dell'automazione industriale.

Dispositivi pneumatici sono usati in molte applicazioni industriali, in
cui, solitamente, sono in gioco forze minori di quelle per cui sono più
indicati dispositivi idraulici. I dispositivi pneumatici sono generalmente
meno costosi di quelli elettrici e sono progettati per utilizzare, come
sorgente di energia, aria opportunamente filtrata e depurata, mediante
opportuni attuatori convertono l'energia dell'aria compressa in energia per
azionare dispositivi meccanici mobili. Il tipo di movimento prodotto
dipende dal tipo di attuatore impiegato.

Azionamento delle valvole

Una singola linea alimenta più banchi pneumatici quindi è necessario
l'utilizzo delle valvole per ripartire l'aria compressa tra i vari
utilizzi. Le valvole sono suddivise, a seconda del tipo di comando, in:

- Valvole ad azionamento manuale;
- Valvole ad azionamento pneumatico;
- valvole ad azionamento elettrico.

Inoltre sono ancora suddivise in altri tipi

- valvola 3/2: è una valvola con 2 posizioni e 3 vie
- valvola 5/2: valvola con 2 posizioni e 5 vie
- valvola 5/3: valvola con 3 posizioni e 5 vie la posizione centrale chiusa
  da dei tappi

gli orifizi hanno il loro nome: 1-> pressione, 2 e 4-> mandate, 3 e 5->
scarichi.

L'azionamento manuale consiste in una leva che permette all'operatore di
scegliere la linea a cui indirizzare l'aria; l'azionamento pneumatico è
così chiamato perché la valvola è comandata a sua volta da una linea
pneumatica separata o collegata a quella che si vuole comandare;
l'azionamento elettrico si utilizza per collegare le valvole ad un comando
elettrico a bobina che è spesso collegato ad un PLC.

Voci correlate

- Motore ad aria compressa
- Pressione
- Strumentazione di controllo
- Valvola Presta

Altri progetti

- Wikimedia Commons contiene immagini o altri file su pneumatica

Collegamenti esterni

- Azionamenti a fluido (PDF), xmlservices.unisi.it.

Controllo PID

Il controllo Proporzionale-Integrale-Derivativo¹ (talvolta tradotto anche
con Proporzionale-Integrativo-Derivativo, dall'inglese
Proportional-Integral-Derivative), comunemente abbreviato come PID, è un
sistema in retroazione negativa ampiamente impiegato nei sistemi di
controllo. È il sistema di controllo in retroazione di gran lunga più
comune nell'industria, in particolare nella versione PI (senza azione
derivativa). Grazie a un input che determina il valore attuale, è in grado
di reagire a un eventuale errore positivo o negativo tendendo verso il
valore 0. La reazione all'errore può essere regolata e ciò rende questo
sistema molto versatile.² .

Fondamenti

Il controllore acquisisce in ingresso un valore da un processo e lo
confronta con un valore di riferimento. La differenza, il cosiddetto
segnale di errore, viene quindi usata per determinare il valore della
variabile di uscita del controllore, che è la variabile manipolabile del
processo.

Il PID regola l'uscita in base a:

- il valore del segnale di errore (azione proporzionale);
- i valori passati del segnale di errore (azione integrale);
- quanto velocemente il segnale di errore varia (azione derivativa).

I controllori PID sono relativamente semplici da comprendere, installare e
tarare, al confronto con più complessi algoritmi di controllo basati sulla
teoria del controllo ottimo e del controllo robusto. La taratura dei
parametri avviene di solito attraverso semplici regole empiriche, come i
metodi di Ziegler-Nichols, che risultano in controllori stabilizzanti di
buone prestazioni per la maggior parte dei processi. Molto spesso l'azione
derivativa viene rimossa, risultando nel comunissimo controllore PI.

Limitazioni

I controllori PID sono spesso sufficienti a controllare processi
industriali anche complessi, ma la loro semplicità risulta in una serie di
limiti che è bene tener presente:

- Non sono in grado di adattarsi a cambiamenti nei parametri del processo;
- Non sono stabili, a causa della presenza dell'azione integrale (vedi
  Windup);
- Alcune regole di taratura, come quelle di Ziegler-Nichols, reagiscono
  male in alcune condizioni;
- Sono intrinsecamente monovariabili, non possono quindi essere usati in
  sistemi inerentemente multivariabili, come per esempio le colonne di
  distillazione.

Azioni di controllo di un PID

Le tre azioni di un PID vengono calcolate separatamente e semplicemente
sommate algebricamente:

u = u_P + u_I + u_D

Azione proporzionale (P)

L'azione proporzionale è ottenuta moltiplicando il segnale d'errore "e" con
un'opportuna costante:

u_P = K_P e

È perfettamente possibile regolare un processo con un simile controllore,
che, in alcuni casi semplici, risulta anche in grado di stabilizzare
processi instabili. Tuttavia, non è possibile garantire che il segnale
d'errore "e" converga a zero: questo perché un'azione di controllo "u" è
possibile solo se "e" è diverso da zero.

Azione integrale (I)

L'azione integrale è proporzionale all'integrale nel tempo del segnale di
errore "e", moltiplicato per la costante {K_I}:

u_I = {K_I} ∫e(t) \mathrm{d} t

Questa definizione dell'azione integrale fa sì che il controllore abbia
memoria dei valori passati del segnale d'errore; in particolare, il valore
dell'azione integrale non è necessariamente nullo se è nullo il segnale
d'errore. Questa proprietà dà al PID la capacità di portare il processo
esattamente al punto di riferimento richiesto, dove la sola azione
proporzionale risulterebbe nulla. L'azione integrale è anche l'elemento
metastabile di un PID, perché un ingresso costante non convergerà a un
determinato valore. Il fenomeno del windup è dovuto alla presenza
dell'integratore.

Azione derivativa (D)

Per migliorare le prestazioni del controllore si può aggiungere l'azione
derivativa:

u_D = K_D \frac{\mathrm{d} e}{\mathrm{d} t}

L'idea è compensare rapidamente le variazioni del segnale di errore: se
vediamo che "e" sta aumentando, l'azione derivativa cerca di compensare
questa deviazione in ragione della sua velocità di cambiamento, senza
aspettare che l'errore diventi significativo (azione proporzionale) o che
persista per un certo tempo (azione integrale). L'azione derivativa è
spesso tralasciata nelle implementazioni dei PID perché li rende troppo
sensibili: un PID con azione derivativa, per esempio, subirebbe una brusca
variazione nel momento in cui il riferimento venisse cambiato quasi
istantaneamente da un valore a un altro, risultando in una derivata di "e"
tendente a infinito, o comunque molto elevata. Ciò sconsiglia
l'applicazione dell'azione derivativa in tutti i casi in cui l'attuatore
fisico non deve essere sottoposto a sforzi eccessivi.

Se ben tarata e se il processo è abbastanza "tollerante", comunque,
l'azione derivativa può dare un contributo determinante alle prestazioni
del controllore.

Approssimazione ingegneristica

Un problema particolare causato dalla presenza dell'azione derivativa è
l'impossibilità teorica di realizzare un "derivatore puro": sarebbe
necessario infatti misurare il valore del segnale di errore nel futuro. Per
questo si calcola invece una derivata ingegneristica, che approssima il
derivatore fino ad una certa frequenza. Ciò risulta nella formula
complessiva (nel dominio della frequenza):

K(s) = K \left (\frac{τ_I s + 1}{τ_I s} \right ) \left (\frac{τ_D s+1}{α
τ_D s+1} \right )

dove α è un valore adimensionale piccolo, tipicamente tra 0,05 e 0,2,
mentre le costanti di tempo {τ_I} e {τ_D} sono tali per cui:

K_I = \frac{K}{τ_I}

K_D = {K} { τ_D}

Regole di Ziegler-Nichols

Il metodo di Ziegler-Nichols, risalente al 1942, è tra i più usati ed è
apprezzato per la sua semplicità, per il fatto di non richiedere un modello
matematico del processo e per le prestazioni che riesce a produrre.

Si tratta di un algoritmo per trovare il cosiddetto "guadagno critico", dal
quale si deriveranno gli altri parametri del PID³ .

- Il processo viene fatto controllare da un controllore esclusivamente
  proporzionale (KI e KD vengono impostati a zero);
- Il guadagno K del controllore proporzionale viene gradualmente aumentato;
- Il guadagno critico Ku è il valore del guadagno per cui la variabile
  controllata presenta oscillazioni sostenute, cioè che non spariscono dopo
  un transitorio: questa è una misura dell'effetto dei ritardi e della
  dinamica del processo;
- Si registra il periodo critico Pu delle oscillazioni sostenute;
- Secondo la seguente tabella, si determinano le costanti per il
  controllore P, PI o PID.

Pseudocodice

Questa è una semplice implementazione pratica di un controllo PID,
attraverso semplificazioni ingegneristiche (dato che normalmente la
funzione da controllare se fosse conosciuta matematicamente non sarebbe
necessario controllarla dinamicamente). Questo pseudocodice somma tre
componenti per capire quanto manovrare l'output, in base all'errore
calcolato volta per volta.
La parte proporzionale è direttamente proporzionale all'errore.
La parte integrativa somma nel tempo gli errori volta per volta; questo
riporta nel lungo periodo la variabile di uscita sui binari corretti.
Purtroppo questo non impedisce un'oscillazione una volta raggiunto il
valore desiderato.
La parte derivativa limita le oscillazioni della variabile di output,
rendendo le variazioni di "actual position" più dolci.
Questo pseudocodice funziona di per sé, ma c'è da valutare ogni quanto
campionare e quindi eseguire questi calcoli, e soprattutto i valori delle 3
costanti K

 previous_error = 0
 integral = 0 
 start:
   error = setpoint - measured_value
   integral = integral + error*dt
   derivative = (error - previous_error)/dt
   output = Kp*error + Ki*integral + Kd*derivative
   previous_error = error
   wait(dt)
   goto start


Codice esempio per Micro GT (PIC 16F876 oriented)

Questo è il codice funzionante, presentato a scopo didattico, per il quale
non è previsto l'uso su applicazioni industriali o commerciali a nome
dell'autore. Chi ne volesse fare uso a questo scopo lo può fare sotto la
propria responsabilità. Il sorgente dovrà essere salvato in un file con
estensione .h e incluso nel proprio lavoro tramite la direttiva #include
"nome.h". Il linguaggio e la sintassi è standard. L'IDE software è MPLAB X
liberamente scaricabile dal sito di Microchip Technology.

/***********************************************
*                                              *
*   Codice scheda:                             *
*   calcola PID PIC16F877 - 16F876             *
*                                              *
*   Firmware version:1.0                       *
*   compilatore Hitech PL 9.7 or upper         *
*   autore: Marco Gottardo                     *
*   Data:25/02/2014                            *
*   MCU: PIC16F877A -16F876A                   *
*   Piattaforma hardware: Micro-GT IDE         *
*   Piattaforma software: MPLAB X 1.58         *
***********************************************/
/**************************************************************
* L'azione PID è definita come l'azione in correzione di      *
* un valore di ritorno dal campo ad un nodo sottrattivo       *
* dove tale valore è calcolato come l'integrazione del valore *
* del setpoint meno il valore in campo (detto errore) diviso  *
* una costante Ki, più la derivazione del medesimo segnale    *
* moltiplicato per la costante Kd, il tutto sommato al        *
* segnale moltiplicato una costante proporzionale Kd.         *
***************************************************************/
int errore(int setpoint){ //calcola la distanza attuale tra misura e setpoint
   int err;
   err = (setpoint - leggi_ad(0));
   return err;
}

float integrale(int grandezza){
   float calcolato;
   int a, b, n, s, i, dx, x, ki;
   n = 20; //preset suddivisione in rettangoli del dominio
   a = 0; //metodo della media mobile, trasla lo zero sul gruppo di campionamenti successivi
   b = 100; //ampiezza intervallo estremo superiore
   dx = abs((b - a) / n); //calcola il differenziale
   s = 0; //inizializza l'integrale a 0
   i = 0; //indice dei cicli di accumulo
   do {
      s = s + dx * leggi_ad(0);
      DelayMs(5);// x=x+dx;
      i++;
   } while (i <= n);
   calcolato = s;
   calcolato = ((1 / ki) * calcolato);
   return calcolato;
}

int derivata(int grandezza){
   int calcolato, calcolato_1, calcolato_2;
   char kd;  // costante proporzionale fissa 12 a priori
   calcolato_1 = leggi_ad(0);
   DelayMs(5);
   calcolato_2 = leggi_ad(0);
   calcolato = calcolato_2 - calcolato_1;
   calcolato = kd * calcolato;
   return calcolato;
}

int proporzionale(int grandezza){
   int calcolato;
   char kp;  // costante proporzionale fissa 12 a priori
   calcolato = kp * grandezza;
   return calcolato;
}

float micro_gt_PID(int grandezza){
   float pid;
   pid = (proporzionale(grandezza) + integrale(grandezza) + derivata(grandezza));
   return pid;
}


Codice esempio per implementare una classe di calcolo PID su java

Questo è il codice in java in formato di classe da implementare come un
oggetto e calcolare ogni azione del PID separatamente per poi sommarli;
presentato a scopo didattico, non è previsto l'uso su applicazioni
industriali o commerciali. Chi ne volesse fare uso a questo scopo lo può
fare sotto la propria responsabilità. Autore: Christian Gobbi.

/**
*
* @author Gobbi Christian
*/
public class PID {
    public float integrale(float tf,float ti,float ef,float ei,float ki){
       // integrale contiene tutti i valori calcolati dell'integrale
       // ti è il tempo iniziale, tf è il tempo finale
       // ei è l'errore iniziale, ef è l'errore finale
       // ki è il coefficiente integrativo del pid
       float integrale=0;
       float area=((ei+ef)*(tf-ti))/2 ;
       
       integrale=area*ki; //calcoliamo l'integrale sommando il triangolo e il quadrato moltiplicandolo per il coefficiente integrativo
        
       return integrale;
      
    }
    public float proporzionale (float e,float kp){
        float proporzionale=kp*e; //calcoliamo la proporzionale
        return proporzionale;
    }
    public float derivativa(float tf,float ti,float ef,float ei,float kd){ //derivativa da sviluppare
        float ritorno;
        float sen=Math.abs(ef-ei); //seno del triangolo
        float cos=Math.abs(tf-ti); //coseno del triangolo
        ritorno=kd*sen/cos; //derivata dei due punti è uguale alla inclinazione creatasi dalla retta creata virtualmente dai due punti
        return ritorno;
    }
}


Note

[1] Massimiliano Veronesi, "Regolazione PID". FrancoAngeli, 2007
[2] Karl Johan Åström, Richard M. Murray: "Feedback systems: an
  introduction for scientists and engineers", Princeton University Press,
  2008: "More than 95% of all industrial control problems are solved by PID
  control, although many of these controllers are actually
  proportional-integral (PI) controllers because derivative action is often
  not included".
[3] Ziegler, J.G and Nichols, N. B., Optimum settings for automatic
  controllers (PDF), Transactions of the ASME, vol. 64, 1942, pp. 759–768.

Bibliografia

- Karl Johan Åström, Tore Hägglund, PID controllers, 1995
- Gottardo Marco, ed. 2015, Esercizi di programmazione dei PLC
  S7-300,400,1200, con TIA Portal, WinCC per HMI, ISBN 9781326143312.
- Karl Johan Åström, Tore Hägglund, Advanced PID control, 2006.
- Bolzern, Scattolini, Schiavoni, Fondamenti di controlli automatici, Mc
  Graw-Hill, 2008.
- George Stephanopoulus Chemical Process Control, an introduction to theory
  and practice, Prentice Hall Internationaly, 1984.
- Marro, Controlli automatici, Zanichelli, 2004.
- Marco Gottardo, Let's Program a PLC!!!, edizione 2016, editore LULU,28
  luglio 2015,terza edizione, ISBN 9781326143312
- Seborg, Edgar, Mellichamp, Process Dynamics and Control, Wiley, 1989.
- Massimiliano Veronesi, Regolazione PID, FrancoAngeli, 2011 (III Ediz.).

Voci correlate

- Controlli automatici
- Controllore (strumento)
- Sistema dinamico
- Trasformata di Laplace
- Z-trasformata
- Sistemi dinamici lineari tempo invarianti
- Strumentazione di controllo
- Windup

Altri progetti

- Wikimedia Commons contiene immagini o altri file su Controllori PID

Robotica

La robotica è la disciplina dell'ingegneria che studia e sviluppa metodi
che permettano a un robot di eseguire dei compiti specifici riproducendo il
lavoro umano. Anche se la robotica è una branca dell'ingegneria, più
precisamente della meccatronica, in essa confluiscono approcci di molte
discipline sia di natura umanistica, come linguistica, sia scientifica:
biologia, fisiologia, psicologia, automazione, elettronica, fisica,
informatica, matematica e meccanica.

Origini del termine

La parola robotica proviene dal ceco robota, che ha il significato di
"lavoro pesante" o "lavoro forzato". Questo termine è stato introdotto
dallo scrittore ceco Karel Čapek, nel 1920 nel suo racconto R.U.R.
(Rossum's Universal Robots).¹ Il termine inglese derivato robotics, secondo
l'Oxford English Dictionary, compare per la prima volta in un racconto di
fantascienza dello scrittore Isaac Asimov intitolato Bugiardo! (Liar!,
1941). Sempre ad Asimov si deve anche l'invenzione delle famose Tre Leggi
della Robotica enunciate interamente nel racconto Circolo vizioso
(Runaround, 1942); entrambi i racconti fanno parte dell'antologia Io,
Robot.

Campi di utilizzo

La scienza robotica, proprio in virtù della sua natura interdisciplinare,
trova applicazioni in molteplici contesti; questo ha fatto sì che
nascessero varie sotto-discipline fra le quali raramente esiste una netta
linea di demarcazione.

- Arte robotica: riguarda robot utilizzati sia per creare nuove forme di
  espressione artistica, sia per imitare e riprodurre le forme artistiche
  già esistenti. Ne sono un esempio i robot progettati per dipingere o per
  suonare uno strumento musicale leggendo in tempo reale uno spartito.
- Domotica: ha come obiettivo l'automazione applicata all'ambiente
  domestico. Tra gli sviluppi a breve termine più interessanti ci sono le
  tecnologie di aiuto ai portatori di handicap mentali o fisici nella vita
  quotidiana in casa.
- Microrobotica: si occupa dello studio e della diffusione di piccoli robot
  a basso costo utilizzati per scopi educativi o ludici.
- Robotica biomedica: è un ramo della robotica molto vasto che comprende
  diversi tipi di robot; robot capaci di assistere il chirurgo durante le
  operazioni, radioterapia robotica, robot telecontrollati con tecnologie
  dette di telepresenza che permettono al chirurgo di operare a distanza.
  Rientrano nella categoria anche le sofisticate apparecchiature per
  analisi biologiche utilizzate nei laboratori.
- Robotica degli sciami.
- Robotica di intrattenimento: si occupa delle tecnologie utilizzate nei
  parchi tematici, nei musei o negli effetti speciali cinematografici per
  intrattenere ed educare grandi quantità di pubblico; un esempio di
  utilizzo sono gli audioanimatroni spesso utilizzati per riprodurre le
  fattezze di personaggi fantastici o di specie animali oggi estinte come i
  dinosauri.
- Robotica evoluzionistica: è una disciplina che, attraverso lo studio di
  algoritmi evolutivi, tenta di realizzare robot sempre più versatili in
  modo da rendere meno essenziale il supporto umano.
- Robotica industriale: si riferisce a macchine che sostituiscono l'uomo in
  operazioni ripetitive. Il campo industriale è sicuramente quello in cui i
  robot hanno trovato maggiore diffusione: il loro impiego nelle catene di
  montaggio ha permesso alle aziende di abbattere notevolmente i costi
  accelerando e migliorando la produzione. Fra i robot più utilizzati
  dall'industria vi è il braccio robotico o robot manipolatore, costruito a
  imitazione del braccio umano, ma spesso dotato di più gradi di libertà: è
  una macchina molto versatile che si presta a svariate mansioni tra cui
  verniciatura, saldatura o montaggio. Interessante notare come questo tipo
  di macchine sia spesso utilizzata per produrre altri robot simili
  rendendo le speculazioni fatte dalla fantascienza sulle macchine
  autoreplicanti un discorso molto più vicino alla nostra quotidianità.
- Robotica marina: si tratta di una branca in via di espansione per le
  numerose applicazioni di tipo industriale, principalmente legate al
  settore petrolifero, oppure scientifico, archeologico e militare.
- Robotica militare: si riferisce in genere a robot utilizzati a scopi
  ispettivi. Anche se la fantascienza è ricca di riferimenti a robot
  utilizzati in ambito militare, attualmente questi sono utilizzati più che
  altro con scopi di ricognizione e vigilanza. Un esempio di queste
  applicazioni è quello degli aerei privi di equipaggio detti droni. Questo
  tipo di veicoli è sì controllato a distanza da personale apposito, ma in
  caso di emergenza può anche compiere diversi compiti in totale autonomia
  permettendo la ricognizione di teatri di guerra pesantemente difesi senza
  mettere a repentaglio vite umane. Altro esempio di robotica militare sono
  i robot artificieri che sono in grado, grazie al numeroso set di
  strumenti di cui sono muniti, di compiere analisi su un ordigno esplosivo
  ed eventualmente neutralizzarlo a distanza riducendo drasticamente i
  rischi per gli artificieri.
- Robotica sociale: si propone di sviluppare tecnologie che rendano i robot
  sempre più capaci di interagire e comunicare con gli esseri umani in modo
  autonomo.
- Robotica spaziale: è relativa alle applicazioni e all'impiego di robot
  fuori dall'atmosfera terrestre. Nonostante ciò, questo settore della
  robotica ha avuto ricadure e risultati utili anche in campi che esulano
  dalla ricerca spaziale. Esempi di questi robot sono le sonde esplorative
  impiegate in diverse missioni sui pianeti del sistema solare o il famoso
  braccio manipolatore dello Space Shuttle o quello di sembianze umane
  destinato alla ISS che verrà utilizzato in sostituzione degli astronauti
  nelle attività extraveicolari.
- Robotica umanoide: si riferisce allo sviluppo e alla costruzione di robot
  con sembianze umane.
- Telerobotica.
- Competizioni robotiche: comprende tutte quelle applicazioni ludiche in
  cui dei robot vengono sviluppati e utilizzati per effettuare competizioni
  di qualunque tipo, per esempio giocare a calcio o effettuare una corsa
  automobilistica.
- Robotica di controllo ed ispezione nel campo aeronautico per la verifica
  manutentiva degli aeromobili.

Modellistica

La realizzazione di un qualsiasi compito da parte di un robot è subordinata
all'esecuzione di un movimento specifico che necessita di essere
pianificato. L'esecuzione corretta di tale movimento è affidata a un'unità
di controllo che invia un insieme opportuno di comandi sulla base del tipo
di moto desiderato. Un sistema robotico presenta una struttura meccanica
articolata ed è fondamentale schematizzarne il comportamento mediante un
modello matematico che individui i legami di causa-effetto tra gli organi
costituenti.

Analisi cinematica

L'analisi cinematica di un robot concerne la descrizione del suo moto
prescindendo dalle considerazioni sulle forze e i momenti che lo provocano.
Essa si divide in:

- Cinematica: si occupa del legame tra i parametri interni del robot (che
  nel caso di robot industriali sono variabili associate ai giunti) e la
  posa da esso assunta (cioè la sua posizione e il suo orientamento).
- Cinematica differenziale: definisce delle relazioni analoghe a quelle
  identificate dalla cinematica riferite alle velocità dei componenti del
  sistema.

L'individuazione di tali legami consente di formulare il problema
cinematico inverso che consiste nel ricavare i valori da attribuire ai
parametri interni del robot per inseguire una determinata specifica di
moto.

Analisi dinamica

Modellare la dinamica di un robot è indispensabile per progettarne il
sistema di controllo. Di fatto il moto di un sistema robotico è assicurato
da un sistema di attuazione che ha il compito di fornire la potenza
necessaria ai compiti da svolgere trasformandola da una forma all'altra in
base alle esigenze. Anche qui occorre distinguere tra dinamica e dinamica
inversa: la prima si occupa del calcolo delle accelerazioni dei componenti
del robot in funzione delle forze di attuazione ed è utile in simulazione,
la seconda ricerca metodi per determinare le forze di attuazione da dare
per ottenere le accelerazioni desiderate.

Pianificazione del sistema

Un problema cruciale risiede nella specifica dei movimenti da imporre al
robot per svolgere i compiti ad esso affidati. Compito della pianificazione
di traiettorie è quello di generare leggi orarie per le variabili
caratteristiche del sistema, partendo da una descrizione informale del tipo
di moto che si vuole ottenere. In particolare bisogna evitare le collisioni
con i possibili ostacoli presenti nell'ambiente di lavoro attraverso
strumenti di natura algoritmica quali i diagrammi di Voronoi o il metodo
dei potenziali artificiali.

Controllo

Le traiettorie generate nella fase di pianificazione costituiscono
l'ingresso di riferimento del sistema di controllo del robot. Quest'ultimo
è un sistema di estrema complessità, e ogni suo modello risulta inadeguato
a causa della presenza di numerosi effetti dinamici imprevisti, tra i quali
gli attriti e gli accoppiamenti tra i componenti. È dunque necessario
introdurre un certo numero di anelli di retroazione, senza i quali
risulterebbe impossibile garantire il soddisfacimento dei requisiti di
precisione desiderati. Affinché il robot possa monitorare istante per
istante di quanto il suo comportamento si scosti da quello pianificato,
deve essere dotato di sensori in grado di misurare grandezze quali
posizione, velocità, forze scambiate con l'ambiente.

Sensori

I sensori si dividono in due grandi categorie:

- Sensori propriocettivi: misurano variabili interne al robot come la
  velocità delle ruote o il livello di carica della batteria.
- Sensori esterocettivi: misurano variabili esterne come la distanza dagli
  ostacoli o la posizione degli oggetti sui quali svolgere un compito.

Encoder

Gli encoder sono sensori propriocettivi in grado di effettuare la
trasduzione della posizione angolare dei giunti del robot. Rivestono un
ruolo essenziale nell'ambito della robotica industriale. Ne esistono due
tipi.

- L'encoder assoluto è un disco di vetro ottico sul quale sono presenti
  delle tracce concentriche. Ciascuna traccia è caratterizzata da una
  sequenza di settori opachi e trasparenti. Sulla base dell'alternanza di
  tali settori, sfruttando un raggio di luce captato da un fototransistor,
  è possibile individuare univocamente una stringa di bit che esprime in
  forma digitale lo spostamento angolare dei giunti.
- L'encoder incrementale riporta due tracce i cui settori opachi e
  trasparenti sono in quadratura tra loro. Consente di ricavare, oltre alla
  variazione della posizione angolare, anche il verso della rotazione
  effettuata. Essendo un sensore incrementale, è necessario effettuare un
  azzeramento, solitamente raggiungendo una posizione nota all'accensione.

Distanza

Tra i sensori in grado di valutare la distanza degli oggetti nelle
vicinanze vi sono i SONAR che utilizzano impulsi acustici dei quali viene
misurato il tempo di volo sensore-ostacolo-sensore. Conoscendo la velocità
di propagazione del suono è possibile calcolare la distanza dall'ostacolo.
Nelle applicazioni di robotica sottomarina e negli ambienti con scarsa
visibilità sono spesso l'unica soluzione attuabile. Un'ulteriore
possibilità è costituita dal LASER, la cui efficacia è però limitata dal
minimo intervallo di tempo osservabile in quanto l'elevatissimo valore
della velocità della luce rende il tempo di volo generalmente
impercettibile.

Visione

Un altro strumento utile al robot per orientarsi nell'ambiente in cui opera
è la telecamera. Essa sfrutta l'intensità luminosa riflessa dagli oggetti
per ricostruirne l'aspetto. Conoscendo i parametri caratteristici della
lente è possibile risalire dalla rappresentazione dell'oggetto nel piano
immagine alle sue dimensioni reali e alla sua distanza. Spesso i robot
impiegano un sistema di telecamere multiplo che consente di valutare la
profondità dell'ambiente tramite la stereoscopia.

Attuazione

Sulla base dell'errore di inseguimento tra i riferimenti e i valori
misurati delle grandezze di interesse del robot, il controllore del sistema
deve effettuare un'azione correttiva volta a modificare i parametri
correnti del moto della struttura. A tale scopo occorrerà aumentare o
ridurre la potenza fornita ai motori che si occupano di convertire
l'energia ricevuta dalla fonte di alimentazione in energia meccanica. Ne
esistono vari tipi:

- Motore elettrico: sfrutta l'energia elettrica generata tramite un flusso
  magnetico variabile ed è tipicamente usato laddove servono grandi
  velocità e basse forze;
- Motore idraulico: strutta la variazione di volume dovuta a un fluido in
  pressione, usato nelle applicazioni in cui servono grandi forze e basse
  velocità;
- Motore pneumatico: utilizza l'energia pneumatica fornita da un
  compressore.

Architettura software

L'unità di controllo di un sistema robotico ha il compito di gestire le
operazioni che devono essere effettuate sulla base di un modello interno
del robot e dei dati forniti dai sensori. Per ottenere un'organizzazione
flessibile in grado di separare le attività ad alto livello da quelle più
elementari, è opportuno che l'architettura di controllo sia ripartita in
livelli gerarchici. In particolare, sul gradino più alto vi è la
decomposizione del compito da svolgere in attività ad un elevato grado di
astrazione, mentre alla base della piramide vi sono gli algoritmi che
determinano i segnali forniti ai motori. Ciascun livello invia il risultato
della propria computazione al livello sottostante, dal quale è
retroattivamente influenzato.

Programmazione

Vi sono tre approcci principali alla programmazione di un robot.

- Teaching-by-showing: il robot viene guidato lungo un percorso e apprende
  le posizioni raggiunte grazie ai sensori; in seguito, si limita a
  replicare quella sequenza di posizioni;
- Robot-oriented: vi è un linguaggio di programmazione ad alto livello con
  strutture dati complesse, variabili, routine;
- Object-oriented: come nel precedente, solo che il linguaggio è orientato
  agli oggetti.

Note

[1] Arduino, p. 562

Bibliografia

- Gianni Arduino, Renata Moggi, Educazione tecnica, 1ª ed., Lattes, 1990.
- Bruno Siciliano, Lorenzo Sciavicco, Luigi Villani, Giuseppe Oriolo,
  Robotica Modellistica, pianificazione e controllo, 3ª ed., McGrawHill,
  2008.
- (EN) Bruno Siciliano e Oussama Khatib (a cura di), Springer Handbook of
  Robotics, Springer-Verlag, 2008, ISBN 978-3-540-23957-4.

Voci correlate

- Androide
- Robot
- Air-Cobot
- Rotazioni rpy
- KUKA
- Convenzione di Denavit-Hartenberg

Altri progetti

- Wikizionario contiene il lemma di dizionario «robotica»
- Wikimedia Commons contiene immagini o altri file su robotica

Collegamenti esterni

- Robotica, in Thesaurus del Nuovo soggettario, BNCF, marzo 2013.

Automazione

Il termine automazione identifica la tecnologia che usa sistemi di
controllo (come circuiti logici o elaboratori) per gestire macchine e
processi, riducendo la necessità dell'intervento umano. Si realizza per
l'esecuzione di operazioni ripetitive o complesse, ma anche ove si richieda
sicurezza o certezza dell'azione o semplicemente per maggiore comodità.

A partire dalla rivoluzione industriale sono stati richiesti, agli
ingegneri e alle industrie degli enormi investimenti nell'automazione: la
macchina a vapore di James Watt prima, il motore a scoppio di Eugenio
Barsanti e Felice Matteucci e l'elettronica dopo, hanno permesso il
raggiungimento di notevoli progressi tecnologici.

Origine del termine

L'origine del termine "automazione" risale al 1952 ed è contesa tra John
Diebold e Del Harder. Il primo scrisse nel 1952 il primo dei suoi dodici
libri, dal titolo Automation: the Advent of the Automatic Factory, basato
su uno studio che l'autore aveva condotto quando frequentava l'Università
di Harvard: nel libro, Diebold presentava la sua visione dell'uso di
sistemi elettronici programmabili in campo economico. Harder,
vicepresidente del settore produzione della Ford, avrebbe invece utilizzato
il termine "automazione" per riferirsi a una nuova concezione di
movimentazione automatica nell'industria automobilistica.

Il termine, che inizialmente fu utilizzato in maniera non molto dissimile
rispetto al termine "meccanizzazione", ebbe un rapido successo negli anni
successivi: tale successo fu favorito in particolare dagli sviluppi
dell'ingegneria meccanica, dell'ingegneria elettrica e dell'ingegneria del
controllo dei processi lavorativi, dai contributi forniti dalla
modellistica matematica e dall'avvento dei computer e delle nuove
tecnologie.

Definizione

Butera (1990) analizza in modo sistematico le varie definizioni che nel
corso degli anni sono state conferite al termine "automazione" per poi
trarre la conclusione che per automazione si può intendere un fenomeno che
ha - insieme - natura tecnologica economica, organizzativa e sociale e ha
per oggetto la gestione e l'evoluzione di complessi sistemi
tecnico-organizzativi che realizzano processi produttivi di prodotti e/o
servizi.

Prima di arrivare a questa conclusione, Butera analizza la definizione del
termine "automazione" secondo quattro concezioni diverse: l'automazione
come tipo particolare di sviluppo tecnico, l'automazione come tecnologia,
l'automazione come forma d'integrazione della produzione e dell'impresa,
l'automazione come sistema socio-tecnico capace di autoregolazione e di
adattamento.

Automazione come sviluppo tecnico

Jaffe e Froomkin (1968) parlano dell'automazione come di un particolare
tipo di sviluppo tecnologico, che sarebbe caratterizzato da uno sviluppo
della meccanizzazione unito a una serie di invenzioni. Le componenti
dell'automazione, secondo Jaffe e Froomkin, sarebbero quindi tre, e cioè:

- il cambiamento tecnologico, che influisce sulla produzione del prodotto
  finale o sul controllo del processo che dà luogo alla produzione;
- le invenzioni, che sarebbero combinazioni di cambiamenti tecnologici
  considerati come nuovi dispositivi o nuove macchine;
- la meccanizzazione, che sarebbe ogni cambiamento che aumenta la quantità
  di produzione per ora di lavoro.

Automazione come tecnologia

Secondo Bright (1958), Crossman (1960, 1966) e diversi altri autori,
l'automazione invece è da identificarsi secondo la sostituzione di lavoro
umano: l'automazione quindi sarebbe una particolare tecnologia che permette
di sostituire, mediante il controllo automatico dei processi, funzioni che
dovrebbero appartenere all'uomo. Bright, nel suo studio, fornisce anche una
classificazione dei livelli di automazione costruito secondo il grado di
passaggio di funzioni tra uomo e macchina.

Sempre in base a tale concezione di automazione, molto efficace è la
definizione di Drucker (citato in Sultan e Prasow, 1964), secondo il quale
l'automazione sarebbe l'uso di macchine per guidare macchine. Secondo tale
modo di concepire l'automazione, le caratteristiche di quest'ultima
sarebbero quindi:

- incorporazione di lavoro indiretto nelle macchine: ciò significa che le
  macchine, oltre a occuparsi di produzione, possono anche occuparsi di
  controllo dei processi e di elaborazione di dati;
- incorporazione di capacità sensoria nelle macchine: secondo Rogers (1958)
  e Killingsworth (1963), le funzioni di controllo che le macchine assumono
  implicherebbero capacità sensorie simili a quelle umane.

Butera nota che una tale concezione di automazione avrebbe poco a che
vedere con le proprietà costruttive delle macchine stesse e che sarebbe
invece focalizzata sulle loro prestazioni: questo approccio quindi,
nonostante offra un notevole contributo alle analisi del progresso
tecnologico, sarebbe insoddisfacente per ciò che riguarda la descrizioni
dell'unità tecnico-organizzativa (officine, stabilimenti, aziende) e
l'analisi delle ragioni dello sviluppo tecnico.

Automazione come integrazione

La concezione di automazione come integrazione tra diverse macchine
nell'ambito di un unico sistema di controllo appartiene a Diebold e fu
formulata nel suo già citato lavoro del 1952. Secondo Diebold,
l'automazione dovrebbe presumere una logica di sistema integrato, basato né
su singole macchine, né su gruppi di macchine, ma sull'intero processo di
produzione. Sempre secondo Diebold, l'automazione non sarebbe semplicemente
una serie di nuove macchine, ma sarebbe piuttosto un diverso modo di
concepire e di realizzare i processi di produzione. La stessa tesi viene
ripresa da Pollock (1957), secondo il quale l'automazione sarebbe
l'integrazione di processi discontinui o parziali in un processo
coordinato, da Northrup (1958), che definisce l'automazione come produzione
automatica continua, e da Buckingham (1961), secondo il quale l'automazione
sarebbe una concezione della fabbricazione. Le caratteristiche rilevanti
dell'automazione come integrazione sarebbero:

- le macchine stesse
- l'integrazione tra i diversi strati della produzione
- l'integrazione tra fabbricazione e processi informativi gestionali
- la continuità della produzione
- l'integrazione tra le funzioni aziendali
- le forme di controllo economico e gestionale.

La concezione di automazione come integrazione è importante anche perché,
al contrario delle precedenti, permette di pensare all'automazione in un
contesto aziendale flessibile: secondo Azzarello e Wegner, i grandi
cambiamenti tecnologici resi possibili dai nuovi sistemi tecnici,
dall'integrazione dei processi e dalla nascita delle nuove tecnologie,
implicherebbero anche l'integrazione dei sistemi gestionali delle aziende e
lo sviluppo di processi di progettazione e di gestione in grado di superare
le tradizionali distinzioni tra funzioni e la divisione del lavoro nelle
fabbriche.

Automazione come sistema socio-tecnico

Secondo Naville (1963), l'automazione non sarebbe un concetto di natura
tecnica, ma sarebbe invece una organizzazione avanzata: questo perché ogni
tecnologia è un sistema di concetti e le realizzazioni tecniche sarebbero
effetti e risultati, piuttosto che cause. Questo tipo di concezione di
automazione si pone quindi in netto contrasto con il concetto di
automazione come tecnologia: se in base a quest'ultima concezione
l'automazione ridurrebbe sempre di più il lavoro umano, la concezione di
automazione come sistema socio-tecnico implicherebbe invece un sistema
tecnico, organizzativo e sociale di nuova organizzazione, flessibile e
capace di controllo. C'è da notare inoltre come una tale concezione
implichi anche le tre precedenti, perché il sistema sarebbe dotato di
singole macchine (automazione come sviluppo tecnico), capaci di sostituire
lavoro umano (automazione come tecnologia) e integrate in un unico sistema
di controllo (automazione come integrazione): in più, il sistema
rivelerebbe capacità di apprendimento, di evoluzione e di creazione. Il
sistema quindi diventerebbe anche autoreferenziale e allo stesso tempo
flessibile, capace di evolversi e di adattarsi all'ambiente.

Tipi di automazione

Laganà (1982) classifica i diversi tipi di automazione proponendo uno
schema che combina la dimensione della pervasività dei diversi sistemi con
la loro dimensione socio-organizzativa. La scala così composta si suddivide
in sette settori diversi, a loro volta classificati in due aree, una (1-3)
per le automazioni facenti parte di un sistema, l'altra (4-7) per i
dispositivi individuali:

In Anatomy of Automation (1962), Amber e Amber, definendo l'automazione
come la tecnologia necessaria per realizzare macchine in grado di
sostituire uno o più attributi dell'uomo nell'effettuare un lavoro,
propongono una classificazione basata sugli attributi sostituiti:¹

Il maggior sviluppo nel campo dell'automazione è avvenuto con l'avvento
dell'elettronica che ha consentito di passare dal livello 3 della meccanica
pura alle possibilità offerte dall'elettronica e dai controlli automatici
(meccatronica). Oggi l'automazione ha raggiunto il livello 5 con qualche
caso di livello 6.

Tali livelli di automazione sono realizzati mediante l'interazione tra la
meccanica pura (che provvede alla sostituzione degli attributi umani fino
al livello 3) e dispositivi elettronici quali:

- computer dedicati chiamati programmable logic controller (PLC) che con
  opportuni software permettono il movimento di attuatori o l'analisi dei
  dati generati da sensori
- sensori e trasduttori
- sistemi di visione artificiale
- microcontroller
- personal computer dotato di apposite schede di I/O, generalmente chiamato
  CN (controllo numerico)
- logica cablata (ormai rara, in quanto è l'antenata del PLC).

Con questi strumenti è possibile realizzare dei controlli automatici che
sono in grado di recepire il mondo reale e di reagire secondo gli algoritmi
che il programmatore ha implementato ad esempio in un PLC.

Per la modellizzazione di problemi d'automazione complessi (con
problematiche di condivisione risorse e parallelismo) vengono comunemente
usate le Reti di Petri, mentre per problemi più semplici (solo
parallelismo) si usa la semplificazione dei Sequence Function Diagram (SFC)
o (caso sequenziale) gli automi. Qualsiasi modello va poi tradotto in un
linguaggio implementabile al calcolatore, quale ad esempio il diffuso
Ladder Diagram, anche se si possono trovare in commercio PLC direttamente
programmabili in SFC.

Impatto sul lavoro

Con lo sviluppo dei sistemi di automazione negli anni '50 e '60, gli
studiosi iniziarono a interrogarsi sugli effetti che l'automazione avrebbe
avuto sull'occupazione, dal momento che molte aziende introducevano sistemi
di fabbricazione automatica proprio per ridurre la manodopera. Altri ancora
si interrogavano su quali sarebbero stati gli effetti sulla qualificazione
del lavoro, sulle competenze richieste, sulle condizioni di lavoro,
sull'organizzazione delle imprese.

Nella sua analisi, Butera (1990), elaborando gli studi condotti da coloro
che si sono occupati degli effetti dell'automazione sul lavoro, individua
quattro tesi, da lui chiamate pessimistica, ottimistica, evoluzionistica e
progettuale.

- Tesi pessimistica: secondo questo modo di vedere, l'automazione e le
  nuove tecnologie provocherebbero disoccupazione (Leontieff e Duchin,
  1984), "polarizzazione", cioè la differenza tra pochi lavoratori
  "superqualificati" e molti lavoratori dequalificati (Brandt,
  Papadimitriu) nonché il cosiddetto taylorismo tecnologico. Inoltre,
  sempre secondo la tesi pessimistica, aumenterebbero le differenze tra i
  lavori di pianificazione, controllo, ideazione e sviluppo e il lavoro di
  esecuzione. Da questa analisi deriverebbe quindi una diagnosi di una
  diminuzione dell'occupazione e di una dequalificazione del lavoro degli
  operai e degli impiegati.
- Tesi ottimistica: secondo questa tesi, l'automazione sarebbe una risorsa
  utile per liberare i lavoratori dai lavori faticosi, pericolosi o
  stupidi. L'automazione consentirebbe quindi di contrastare da una parte
  l'impoverimento e la banalizzazione del lavoro, e dall'altra l'esistenza
  di lavori pesanti, faticosi e rischiosi. Benché l'automazione, anche
  secondo questa tesi, riduca effettivamente la quantità della manodopera,
  essa stimolerebbe comunque il ciclo dell'espansione dando vita a nuovi
  prodotti, nuovi mercati, nuove imprese e nuove professioni, e quindi a
  occupazione sostitutiva (Lawrence, 1984). Al contrario della tesi
  precedente, la tesi ottimistica prevede un incremento della
  qualificazione dei lavoratori.
- Tesi evoluzionistica: questa tesi sostiene che i cambiamenti
  economico-sociali prodotti dall'automazione avverrebbero in modo
  progressivo, senza rivoluzioni (Rosenberg, Nelson e Winter). Secondo
  questa tesi coesisterebbero mestieri tradizionali e mestieri creati dalle
  nuove tecnologie. Per alcuni operai cambierebbe soltanto il modo di
  lavorare (meno fatica e più attenzione e responsabilità), altri si
  occuperebbero di lavori nuovi ma sempre in maniera tayloristica (per
  esempio, custodi di stabilimenti o addetti a fast food), altri ancora
  continuerebbero i mestieri tradizionali non automatizzabili.
- Tesi progettuale: secondo questa tesi non esisterebbe una automazione, ma
  esisterebbero varie automazioni, ognuna diversa a seconda e adattata in
  funzione della struttura e della storia dell'azienda, dello stabilimento
  o dell'ufficio in cui la nuova tecnologia verrebbe introdotta. Secondo la
  tesi progettuale non avrebbe senso parlare di effetti sociali
  dell'automazione, ma avrebbe più senso parlare di risultati di scelte
  operate dall'azienda all'interno di gamme di opzioni consentite dalle
  caratteristiche del sistema a cui la tecnologia andrebbe applicata.

Automazione nel mondo reale

Un particolare caso di automazione, nonché uno dei casi attualmente più
avanzati, è quello delle macchine utensili a controllo numerico, che
consentono la realizzazione di manufatti sostituendosi all'uomo nel fornire
energia, destrezza, diligenza, giudizio e valutazione (livello 5). La
massima estremizzazione dell'automazione manifatturiera è la fabbrica
automatica.

Un recente sviluppo della tecnologia è l'automazione applicata all'ambito
domestico, detta "domotica".

L'automazione applicata nei laboratori di ricerca e diagnosi si chiama
"automazione di laboratorio".

Note

[1] Amber

Bibliografia

- (EN) George H. Amber, Paul S. Amber, Anatomy of automation,
  Prentice-Hall, 1962.
- J. R. Bright, Automation and Management, Harvard University, Cambridge,
  1958.
- W. Buckingham, Automation: its impact on business and people, Harper &
  Row, New York, 1961.
- F. Butera, L'automazione e il futuro del lavoro operaio, Studi
  organizzativi, 2, 82.
- F. Butera, Il castello e la rete: impresa, organizzazione e professioni
  nell'Europa degli anni '90, Franco Angeli, Milano, 1990.
- P. Chiacchio, F. Basile, Tecnologie informatiche per l'automazione,
  Mc-Graw-Hill, 2006.
- E. R. Crossman, Automation and skill, Hmso, London, 1960.
- E. R. Crossman, Taxonomy of automation, Oecd, Parigi, 1966.
- J. Diebold, Automation: the advent of automated factory, Van Nostrand,
  New York, 1952.
- A. J. Jaffe, J. Froomkin, Technology and jobs-Automation in perspective,
  Frederick Praeger, New York, 1968.
- C. Killingsworth, Automation jobs and manpower in Nation's manpower
  revolution, USGPO, Washington DC, 1963.
- R.Z. Lawrence, The employment of new information technologies: an
  optimistic view, Brookings Institutions, 1984.
- W. Leontieff, F. Duchin, The impact of automation on employment,
  1963-2000, National Sciense Foundation, Washington, 1984.
- G.A. Magnani, G. Ferretti, P. Rocco, Tecnologie dei sistemi di controllo,
  McGraw-Hill, 2006.
- A. Martin, Dizionario di Automazione e Informatica Industriale,
  Editoriale Delfino, 2006.
- P. Naville, Vers l'automatism social?, Gallimard, Parigi, 1963.
- H.R. Northrup, Automation: effects on labour force, skills and employment
  in Annal proceedings of Industrial Relations Research Association,
  Washington, 1958.
- F. Pollock, Automation, Europaische Verlangsaltat, Francoforte sul Meno,
  1956.
- P.E. Sultan, P. Prasow, Automation: Some classification and measurement
  problems, Labour and Automation (Geneva, ILO), Bullettin n. 1, 1964.

Voci correlate

- Automa (informatica)
- Controllo automatico
- Ipnosi stradale
- Theremino System

Altri progetti

- Wikizionario contiene il lemma di dizionario «automazione»
- Wikimedia Commons contiene immagini o altri file su automazione

Collegamenti esterni

- Automazione, in Thesaurus del Nuovo soggettario, BNCF, marzo 2013.
- UCIMU - Sistemi per produrre (Unione Costruttori Italiani Macchine
  Utensili, robot ed automazione), ucimu.it.
- Polo formativo della meccanica, polomeccanica.net.
- Materiale didattico, atuttascuola.it.
- Open source software di automazione, openapc.com.
- Software e hardware Open-Source e Fai-da-te per l'automazione,
  theremino.com.

Automa (informatica)

In teoria dei sistemi dinamici, un automa è un sistema dinamico discreto
(nella scansione del tempo e nella descrizione del suo stato) e invariante
(il sistema si comporta alla stessa maniera indipendentemente dall'istante
di tempo in cui agisce).

Quando l'automa si trova in un dato stato, esso può accettare solo un
sottoinsieme dei simboli del suo alfabeto. L'evoluzione di un automa parte
da un particolare stato detto stato iniziale. Un sottoinsieme privilegiato
dei suoi stati è detto insieme degli stati finali o marcati.

In genere gli automi sono deterministici, ovvero dato uno stato ed un
simbolo in ingresso è possibile una sola transizione. Esistono comunque
anche automi non deterministici, o stocastici.

Automi e linguaggi

Gli automi sono spesso utilizzati per descrivere linguaggi formali in
informatica teorica, e per questo sono chiamati accettori o riconoscitori
di un linguaggio.

L'insieme dei possibili simboli che possono essere forniti ad un automa
costituisce il suo alfabeto.

Una sequenza di simboli (detto anche stringa o parola) appartiene al
linguaggio se essa viene accettata dal corrispondente automa, ovvero se
porta l'automa in uno stato valido, che sia lo stesso o un altro stato. Un
sottoinsieme del linguaggio riconosciuto, chiamato linguaggio marcato porta
l'automa dal suo stato iniziale ad uno stato finale o marcato.

A diverse classi di automi corrispondono diverse classi di linguaggi,
caratterizzate da diversi livelli di complessità.

Un automa può quindi generare più linguaggi (produzione di più sequenze).

Automi con blocchi

Esistono principalmente due tipi di blocchi: deadlock e livelock. Il primo
avviene quando si giunge in uno stato che non rientra fra gli stati finali
e ha Γ={Φ}, ovvero in cui non ci sono uscite. Un livelock si verifica
invece quando si giunge all'interno di un insieme di stati, nessuno dei
quali è uno stato finale, da cui non è più possibile uscire. La presenza di
questi blocchi si può individuare con algoritmi che operano sui riguardanti
i digrafi sottostanti.

Operazioni con automi

Esistono operazioni che si possono effettuare su un singolo automa o su più
automi. Tra le prime possiamo citare: l'accessibilità, la coaccessibilità,
il trim e il complemento. Tra le composizioni di automi si trova il
prodotto e la composizione in parallelo.

Classificazione degli automi

Elenchiamo una classificazione dei vari tipi di automi, elencati per
capacità crescente. Una sintesi è riportata nella tabella presente nella
pagina.

Automi a stati finiti

Gli automi a stati finiti sono dotati di un insieme finito di stati,
scandiscono una stringa di simboli in ingresso (simbolo per simbolo) in
maniera ordinata per decidere se essa appartenga o meno ad un linguaggio.

Formalmente tali automi sono delle quintuple, (Q, I, f, q0, F ), formate da
un alfabeto finito dei simboli in ingresso (I), un insieme finito di
stati(Q) tra cui si distingue uno stato iniziale (q0) ed un sottoinsieme di
stati, detti finali (F), ed una funzione di transizione(f). Tale funzione,
descritta mediante una tabella di transizione degli stati, o un
multidigrafo, è definita per coppie (stato corrente, simbolo scandito) e
stabilisce la transizione da compiere, ossia lo stato in cui si transita
leggendo il dato simbolo.

Il funzionamento dell'automa può essere così descritto:

- partendo dallo stato iniziale e dal primo simbolo della stringa in
  ingresso si decide in base alla funzione di transitare in un determinato
  stato (potrebbe anche essere lo stesso stato);
- finché esiste un altro simbolo nella stringa da scandire si opera alla
  stessa maniera fino ad esaurire la stringa in ingresso;
- la stringa si dirà accettata se si giunge in uno stato appartenente al
  sottoinsieme degli stati finali.

Tali automi sono in grado di riconoscere i linguaggi regolari.

Automi con output

Tale classe di automi a stati finiti può associare l'emissione di simboli
appartenenti ad un altro alfabeto detto di output. Questi automi vengono
chiamati macchine di Moore o di macchina di Mealy, a seconda che l'output
sia associato agli stati (caso più particolare), o alle transizioni fra
stati.

Automi a pila

Gli automi possono anche essere dotati di memoria supplementare (rispetto
ai soli stati) ad esempio nella forma di una pila (push down automata).
Tali automi sono in grado di riconoscere una classe più ampia di linguaggi
rispetto agli automi a stati finiti, come quella dei linguaggi liberi dal
contesto.

Lo stato degli automi a pila è costituita da una pila di simboli. Solo il
simbolo in cima alla pila in un dato momento è accessibile e può essere
letto.

Le transizioni negli automi a pila dipendono dal simbolo in ingresso e dal
simbolo in cima alla pila; una transizione può comportare il deposito di un
nuovo simbolo in cima alla pila e/o l'emissione di un simbolo in uscita.

Gli automi a pila sono un sovrainsieme di quelli a stati finiti.

Automi lineari limitati

Un automa lineare limitato (in inglese linear bounded automata, LBA) è una
particolare macchina di Turing non deterministica, nella quale la lunghezza
del nastro è funzione lineare della dimensione dell'input. Questi automi
sono in grado di accettare linguaggi dipendenti dal contesto generati da
grammatiche dipendenti dal contesto (o di Tipo-1 secondo la gerarchia di
Chomsky).

Macchine di Turing

Il massimo livello di complessità di un automa è raggiunto dalla macchina
di Turing, modello che generalizza gli automi a pila (e a fortiori gli
automi a stati finiti).

Un sottoassieme di macchine di Turing è costituito dalle Macchine che
terminano sempre, o decider nella terminologia inglese, che sono macchine
per le quali è sempre garantita la terminazione della computazione, per
qualunque input.

Automi non deterministici

Vengono studiati anche automi non deterministici, ovvero nei quali dato uno
stato dell'automa ed un simbolo in ingresso è possibile più di una
transizione. Questi hanno una utilità concettuale nella Teoria della
complessità algoritmica.

Bibliografia

- Hopcroft John E., Motwani, Rajeev; Ullman, Jeffrey D., Automi, linguaggi
  e calcolabilità, I ed. it., Addison Wesley, ISBN 88-7192-154-2.

Voci correlate

- Informatica
- Linguaggio formale
- Multidigrafo
- Automa a stati finiti
- Macchina sequenziale sincrona e asincrona
- Macchina astratta

Altri progetti

- Wikimedia Commons contiene immagini o altri file su Automa

Collegamenti esterni

- Automa, in Thesaurus del Nuovo soggettario, BNCF, marzo 2013.

Androide

L'androide è un essere artificiale, un robot, con sembianze umane, presente
soprattutto nell'immaginario fantascientifico. In taluni casi l'androide
può risultare indistinguibile dall'essere umano. Differisce dal cyborg, il
quale è costituito da parti biologiche oltre che artificiali.

Il termine deriva da ἀνδρός andrós, il genitivo del greco antico ανήρ anēr,
che significa «uomo», e il suffisso -οειδής -oidēs, da -ειδής -eidēs, usato
per significare «della specie; simile», da εἶδος eidos «aspetto». Il
termine è menzionato per la prima volta da Alberto Magno nel 1270¹ e fu
reso popolare dallo scrittore francese Villiers² nel suo romanzo del 1886
Eva futura; il termine «android» appariva comunque nei brevetti
statunitensi già nel 1863 in riferimento ad automi giocattolo in miniatura
con fattezze umane.³

Il corrispettivo femminile del termine androide è l'assai poco frequente
«ginoide», dal greco γυνή ghinē «donna».

Precursori nei miti e nelle leggende

L'idea di persone artificiali è rintracciabile fin dalle storie della
mitologia greca. Cadmo seppellì dei denti di drago che si trasformarono in
soldati; secondo il mito, re Pigmalione si innamorò di una statua che
rappresentava una donna ideale, Galatea; chiese allora ad Afrodite di
donare la vita alla statua, e sposò la donna.

Nella mitologia classica, il deforme dio del metallo Efesto (o Vulcano)
creò dei servi meccanici, che andavano dalle intelligenti damigelle dorate
a più utilitaristici tavoli a tre gambe che potevano spostarsi di loro
volontà.

La leggenda ebraica ci parla del Golem, una statua di argilla, animata
dalla magia cabalistica. Nell'estremo Nord canadese e nella Groenlandia
occidentale, le leggende inuit raccontano del Tupilaq, che può essere
creato da uno stregone per dare la caccia e uccidere un nemico. Usare un
Tupilaq per questo scopo può essere un'arma a doppio taglio, in quanto una
vittima abbastanza ferrata in stregoneria può fermare un Tupilaq e
«riprogrammarlo» per cercare e distruggere il suo creatore.

Il termine androide è menzionato per la prima volta nel 1270 dal filosofo,
teologo e scienziato Alberto Magno¹ , che lo usò per definire esseri
viventi creati dall'uomo per via alchemica. Una leggenda vuole Alberto
Magno costruttore di un vero e proprio androide di metallo, legno, cera,
vetro, cuoio, con il dono della parola, che avrebbe dovuto svolgere la
funzione di servitore presso il monastero domenicano di Colonia.

Nel XVI secolo i trattati di alchimia fornivano indicazioni per costruire
un essere artificiale: l'homunculus.

Storia

La prima vera tecnologia degli automi meccanici si può far risalire al
medioevo, quando si cominciano a costruire le prime figure mobili che
arricchivano i campanili e gli orologi delle chiese.

Il primo progetto documentato di un androide è firmato da Leonardo da Vinci
e risale al 1495 circa: appunti riscoperti negli anni cinquanta nel codice
Atlantico e in piccoli taccuini tascabili databili intorno al 1495-1497
mostrano disegni dettagliati per un cavaliere meccanico in armatura, che
era apparentemente in grado di alzarsi in piedi, agitare le braccia e
muovere testa e mascella. L'automa cavaliere di Leonardo era probabilmente
previsto per animare una delle feste alla corte sforzesca di Milano,
tuttavia non è dato sapere se fu realizzato o no.

La fine del XVIII secolo e il XIX secolo vede fiorire la moda degli automi
meccanici, concepiti soprattutto come sofisticati giocattoli, ma talvolta
assai perfezionati.

Il primo androide funzionante conosciuto venne creato nel 1738 da Jacques
de Vaucanson, che fabbricò un automa che suonava il flauto, così come
un'anatra meccanica che, secondo le testimonianze, mangiava e defecava.

Alla fine del Settecento a un inventore ungherese, il barone Wolfgang Von
Kempelen, fu attribuita l'ideazione di un automa in grado di giocare a
scacchi, Il Turco, poi rivelatosi (nel 1857) un elaborato imbroglio. Tra il
1770 e il 1773 due inventori, Pierre e Henri-Louis Jaquet-Droz, costruirono
tre sorprendenti automi: uno scrivano, un disegnatore e un musicista
(ancora funzionanti, si trovano nel Musée d'Art et d'Histoire di Neuchâtel
in Svizzera).

La moderna tecnologia della robotica vede attualmente la costruzione
soprattutto di macchine estremamente specializzate per uso industriale,
totalmente prive di aspetto umano, che risulterebbe d'intralcio e, secondo
alcuni, potrebbe comportare dei problemi a livello psicologico e sindacale.
La costruzione degli androidi rimane dunque, soprattutto, una curiosità per
tutto il XX secolo, anche se il successo commerciale dei cani robot, specie
in Giappone, ha permesso ad alcuni di supporne un ipotetico sviluppo
futuro.

Gli androidi nella letteratura

Una volta che la tecnologia avanzò al punto che la gente intravedeva delle
creature meccaniche come qualcosa più che dei giocattoli, la risposta
letteraria al concetto di essere artificiale rifletté le paure che gli
esseri umani avrebbero potuto essere rimpiazzati dalle loro stesse
creazioni intelligenti.

Nella letteratura il primo classico riferito alla creazione di un essere
umano artificiale è in genere considerato il romanzo Frankenstein (1818) di
Mary Wollstonecraft Shelley, che spesso è anche citato come la prima opera
di fantascienza. La creatura del dottor Frankenstein era assemblata con
parti di cadaveri, utilizzando per infonderle la vita una strumentazione
scientifica (non si tratta dunque di un automa meccanico, ma piuttosto di
quello che molti anni dopo sarebbe stato definito un cyborg).

Il racconto di E.T.A. Hoffmann L'uomo della sabbia (1815) narra l'amore tra
un uomo e una bambola meccanica; nel romanzo breve La storia filosofica dei
secoli futuri (1860) Ippolito Nievo indicò l'invenzione dei robot (da lui
chiamati «omuncoli», «uomini di seconda mano» o «esseri ausiliari») come
l'invenzione più notevole della storia dell'umanità, e in Steam Man of the
Prairies (1865) Edward S. Ellis espresse la fascinazione americana per
l'industrializzazione. Giunse un'ondata di storie su automi umanoidi, che
culminò nell'Uomo elettrico di Luis Senarens, nel 1885.

Il primo a utilizzare il termine androide in un romanzo fu però il francese
Mathias Villiers de l'Isle-Adam (1838-1889) nella sua opera più celebre,
Eva futura (L'Ève future, 1886),² ⁴ nel quale il protagonista è addirittura
Thomas Edison, il quale inventa una donna artificiale quasi perfetta.

Impossibile non citare il racconto dell'italiano Carlo Collodi del 1883, Le
avventure di Pinocchio, in cui un bambino di legno prende vita. La storia,
pur utilizzando elementi fiabeschi piuttosto che fantascientifici, contiene
i temi fondamentali dei successivi racconti sugli androidi.

Un precursore del moderno androide è da molti considerato il Golem, la
temibile creatura protagonista di una vecchia leggenda del ghetto ebraico
di Praga. In questo caso si tratta di una statua d'argilla che prende vita
grazie alla magia cabalistica e non alla tecnologia scientifica. Una
versione più moderna del Golem lo vede però costruito come una specie di
androide, nella novella di U.D. Horn (Der Rabby von Prag, 1842) e nel
libretto di F. Hebbel per il dramma musicale di Arthur Rubinstein Ein
Steinwurf (1858): il Golem viene qui rappresentato come un uomo-macchina di
legno con un meccanismo a orologeria dentro la testa. La leggenda del Golem
viene infine ripresa e resa famosa dal romanzo Il Golem (Der Golem) del
1915 dello scrittore e occultista praghese Gustav Meyrink.

Nel dramma R.U.R. (Rossum's Universal Robots) (1920) del ceco Karel Čapek
appaiono uomini artificiali completamente organici, utilizzati come forza
lavoro a basso costo. L'opera è famosa per avere introdotto il termine
robot, nonostante non si tratti di esseri meccanici ma di veri e propri
«uomini artificiali». La procedura di costruzione degli androidi di Rossum
comprende macchine per impastare e tini per il trattamento di protoplasma
chimico. Quando il dramma di Čapek introdusse il concetto di una catena di
montaggio operata da robot che costruivano altri robot, il tema prese delle
sfumature politiche e filosofiche, ulteriormente disseminate da film
classici come Metropolis (1927), il popolare Guerre stellari (1977), Blade
Runner (1982) e Terminator (1984).

Tra il 1940 e il 1941 Isaac Asimov, con la collaborazione dell'editore John
W. Campbell, elabora le tre leggi della robotica, divenute un punto fermo
della narrativa sui robot. Nel 1976 Asimov scrive L'uomo bicentenario, la
storia di un robot che vuole diventare umano a tal punto da fare ciò che
differenzia gli esseri umani dai robot: morire. Pur avendo inserito
numerosissimi robot antropomorfi nella sua sterminata produzione di
racconti e romanzi (il più famoso dei quali è R. Daneel Olivaw), Asimov
tuttavia non usa in genere il termine «androide», reso popolare solo negli
anni cinquanta quando apparve in alcuni racconti di Jack Williamson.

Uno degli autori di fantascienza che fanno maggior uso degli androidi è
stato Philip K. Dick il quale, scarsamente interessato agli aspetti
strettamente tecnico-scientifici, li utilizzava soprattutto come sostituti
robotici degli uomini e dunque inquietanti simboli,
rispecchiamento/rovescio dell'essere umano, definendoli spesso simulacri.
Dal romanzo di Dick Cacciatore di androidi è tratto il film Blade Runner,
che presenta un vivido ritratto di replicanti che aspirano a quella vita
umana loro ineluttabilmente negata.

Marvin l'androide paranoico è uno dei personaggi principali della Guida
galattica per gli autostoppisti, serie di fantascienza umoristica di
Douglas Adams.

Cinema e televisione

Il primo film con un immaginario automa nel ruolo principale fu The Master
Mystery del 1920,⁵ interpretato da Harry Houdini. Il secondo fu L'uomo
meccanico (1921), del comico francese André Deed, in cui per la prima volta
viene messo in scena uno scontro tra un robot buono e uno cattivo.

Esempi famosi di androidi nella cinematografia e nelle serie televisive:

- Il robot femmina del film Metropolis (1927) per la regia di Fritz Lang
- Il pistolero interpretato da Yul Brynner nel Mondo dei robot (Westworld,
  1973), iniziatore della rivolta dei robot contro gli umani del parco dei
  divertimenti Westworld.
- Il simpatico androide protocollare C-3PO (D-3BO) di Guerre stellari
  (1976)
- Il replicante Roy Batty, condannato a una breve esistenza e ribelle in
  Blade Runner (1982) di Ridley Scott, ispirato al romanzo Il cacciatore di
  androidi di Philip K. Dick
- L'androide killer protagonista di Terminator (1984) e dei tre seguiti,
  che però è più propriamente un cyborg
- La bambina robot Vicky protagonista della sit-com Super Vicky (1985)
- Il signor Dent, personaggio di Code Name: Eternity (1999), un androide
  che ha la facoltà di rigenerarsi, quando viene distrutto.
- Il bambino artificiale in AI - Intelligenza Artificiale (2001) di Steven
  Spielberg
- Il tenente comandante Data è un membro dell'equipaggio della nave
  stellare Enterprise nella serie televisiva Star Trek - The Next
  Generation e in alcuni film derivati dalla serie stessa.
- L'androide Ash in Alien di Ridley Scott.
- La serie televisiva svedese Real Humans (titolo in svedese: Äkta
  människor, 2012) descrive una realtà in cui gli androidi (denominati
  hubot) sono diffusi e utilizzati con varie funzioni, lavorative e
  domestiche. In particolare, la serie segue la storia di un gruppo di
  androidi che hanno acquistato una volontà libera e la capacità di
  autodeterminazione, e sono per questo ricercati e perseguitati dagli
  umani.
- Mike Wellington interpretato da Christopher Walken in La donna perfetta
  film del 2004 diretto da Frank Oz, tratto dal romanzo La fabbrica delle
  mogli di Ira Levin.
- Sonny interpretato da Alan Tukyk in Io, Robot film del 2004 diretto da
  Alex Proyas, tratto dal romanzo Io, Robot di Isaac Asimov.

Fumetti e animazione

Nei fumetti i robot e gli androidi appaiono di pari passo con i romanzi di
fantascienza. Uno dei primi ad essere protagonista è Astro Boy, personaggio
del manga scritto e illustrato del giapponese Osamu Tezuka nel 1952.

Passando al vasto campo dei supereroi, uno dei primi androidi è la Torcia
Umana originale, un personaggio degli anni quaranta facente parte
dell'universo Marvel Comics, la quale nei suoi fumetti ha sempre fatto uso
massiccio di esseri cibernetici. Fin dai primissimi numeri, ad esempio, i
Fantastici Quattro (1961) si trovano a combattere non solo con robot, ma
anche con gli incredibili androidi del Pensatore Pazzo; praticamente tutta
la loro storia è legata a doppio filo con questi esseri. Due altri
importanti androidi dell'universo Marvel sono Ultron e Visione. Tra i
personaggi della DC Comics, Superman nelle sue avventure ha incontrato
migliaia di robot più o meno antropomorfi, servendosene egli stesso: negli
anni cinquanta troviamo infatti già i primi super-robot da lui costruiti
per sostituirlo come sosia. Anche Batman negli anni cinquanta-sessanta si è
fatto talvolta sostituire da un sosia robot (perfino la sua spalla Robin).
Un altro androide della Marvel è Mister Macchina (il cui nome umano è Aaron
Stack), che per un breve periodo fu protagonista di una propria serie.

In un fumetto italiano pubblicato su Topolino dell'aprile 1974 («Zio
Paperone e il donatore straniero», testo di Jerry Siegel disegni di Luciano
Gatto), anche zio Paperone si fa sostituire da un robot sospettando di
correre dei rischi.

Nella serie di manga e anime Dragon Ball sono presenti molte generazioni di
potenti androidi sviluppati per la battaglia, che saranno a volte tra i
maggiori antagonisti del manga: l'Androide 8 prima malvagio e poi
personaggio positivo, citazione di Frankenstein, in Dragon Ball e gli
androidi 19, 20, 13, 14, 15, 16, 17, 18 in Dragon Ball Z (corrispondente
alla seconda parte del manga). Questi non sono semplicemente degli
androidi, ma veri e propri congegni di distruzione totale, inarrestabili
con mezzi normali: infatti essi verranno sconfitti dai personaggi più forti
della serie quali Goku, Vegeta, Gohan e Trunks.

Note

[1] Intelligence in the Making, Harvard University. URL consultato il 7
  gennaio 2007.
[2] Per Shelde, Androids, Humanoids, and Other Science Fiction Monsters:
  Science and Soul in Science Fiction Films, New York, New York University
  Press, 1993. ISBN 0-8147-7930-1
[3] U.S. Patent and Trademark Office, Patent# 40891, Toy Automation, Google
  Patents. URL consultato il 7 gennaio 2007.
[4] In alcune edizioni il termine è stato tradotto in italiano con
  «andreide».
[5] (EN) The Master Mystery, in Internet Movie Database, IMDb.com.

Bibliografia

Narrativa

- Philip K. Dick, I simulacri (The Simulacra, 1964)
- Philip K. Dick, Abramo Lincoln androide (A. Lincoln, Simulacrum, 1969)
- Philip K. Dick, Cacciatore di androidi (Do Androids Dream of Electric
  Sheep?, 1971)

Voci correlate

- Automa meccanico
- Robot
- Cyborg
Modelli di androidi prodotti
- ASIMO
- HRP-3 Promet Mk-II
- Robonauta
Nella letteratura
- Ginoide
- Mecha
- Ribellione della macchina
- Robot positronico

Altri progetti

- Wikiquote contiene citazioni di o su androide
- Wikizionario contiene il lemma di dizionario «androide»
- Wikimedia Commons contiene immagini o altri file su androide

Collegamenti esterni

- I robot a fumetti, comune.modena.it.
- Sito italiano dedicato agli androidi, androidi.com.

Automa meccanico

Un automa è una macchina in grado di operare in modo autonomo. Il termine è
talvolta usato per indicare un robot, più precisamente un robot autonomo,
ma più spesso descrive una macchina semovente non elettronica (come un
automa meccanico), specialmente quelle costruite per assomigliare ad esseri
umani o ad animali.Il termine automa deriva dal greco αὐτόματος, automatos,
"che agisce di propria volontà".

Nell'uso colloquiale, comportarsi come un "automa" significa agire in in
modo meccanico, senza pensare.

Automi nell'antichità

Gli automi nel mondo ellenistico erano concepiti come giocattoli, idoli
religiosi per impressionare i fedeli o strumenti per dimostrare basilari
principi scientifici, come quelli costruiti da Ctesibio, Filone di Bisanzio
(III secolo a.C.) ed Erone di Alessandria (I secolo). Quando gli scritti di
Erone su idraulica, pneumatica e meccanica, conservati a opera degli arabi
e dei bizantini, furono tradotti in latino nel Cinquecento e in italiano, i
lettori iniziarono a ricostruire le sue macchine, tra cui sifoni, un
idrante, un organo idraulico, l'eolipila e, appunto, gli automi, sulla cui
costruzione Erone aveva scritto uno dei suoi trattati di maggior successo,
Automata, in cui egli illustra teatrini automatici dotati di moto autonomo,
rettilineo o circolare, per tutta la durata dello spettacolo.

Si conosce l'esistenza di complessi dispositivi meccanici nella Grecia
antica, benché l'unico esemplare sopravvissuto sia la Macchina di
Anticitera (circa 150-100 a.C.), il più antico calcolatore meccanico
conosciuto. In origine si pensava provenisse da Rodi, dove sembra esistesse
una tradizione di ingegneria meccanica; l'isola era rinomata per i suoi
automi.

Vi sono inoltre esempi dal mito: Dedalo utilizzò l'argento vivo per
installare una voce nelle sue statue. Efesto creò automi per il suo
laboratorio: Talo, un uomo artificiale di bronzo e, secondo Esiodo, la
donna Pandora.

Nell'antica Cina un curioso resoconto sugli automi si trova nel testo del
Libro del Vuoto Perfetto (Liè Zĭ) scritto nel III secolo a.C. In esso vi è
una descrizione di un più antico incontro tra re Mu del regno di Zhou
(1023-957 a.C.) e un ingegnere meccanico chiamato Yan Shi, un 'artefice'.

Nell'VIII secolo l'alchimista islamico Giabir ibn Hayyan (Geber) inseriva
nel suo trattato Il libro delle pietre delle ricette per costruire
serpenti, scorpioni ed esseri umani artificiali che fossero soggetti al
controllo del loro creatore. Nell'827 il califfo al-Ma'mun aveva un albero
d'argento e oro nel suo palazzo a Baghdad, che aveva le caratteristiche di
una macchina automatica: c'erano uccelli di metallo che cantavano
automaticamente sui rami oscillanti di quest'albero costruito da inventori
e ingegneri islamici del tempo.² ³ Il califfo abbaside al-Muktadir
possedeva a sua volta un albero dorato nel suo palazzo di Baghdad nel 915,
con uccelli che battevano le ali e cantavano.² ⁴ Nel IX secolo i fratelli
Banū Mūsā inventarono un flautista automatico che sembra essere stato la
prima macchina programmabile, e che descrissero nel loro Libro dei
dispositivi ingegnosi.⁵ Alī Ibn Khalaf al-Murādī scrisse nell'XI secolo il
Libro dei segreti risultanti dai pensieri (in arabo: الأسرار في نتائج
الأفكار‎, Kitāb al-asrār fī natā'ij al-afkār), un trattato di ingegneria
meccanica interamente dedicato alla costruzione di complessi automi,⁶ in
cui descrive 31 automi (21 dei quali orologi).

Tra gli altri esempi notevoli di automi vi è la colomba di Archita,
menzionata da Aulo Gellio⁷ . Analoghi resoconti cinesi di automi volanti si
trovano negli scritti del V secolo del filosofo moista Mozi e del suo
contemporaneo Lu Ban, che costruì uccelli artificiali in legno (ma yuan)
che potevano effettivamente volare, secondo quanto riportato da Han Fei e
in altri testi.⁸

Automi dal XIII al XIX secolo

Ad Al-Jazari è attribuito il primo progetto documentato di automa
programmabile nel 1206, usato per una serie di automi umanoidi. Il suo
automa era una nave con quattro musicisti che galleggiava su un lago per
intrattenere gli ospiti alle feste di corte. Il suo meccanismo aveva una
batteria di percussioni programmabile con pistoncini (camme) che battevano
su piccole leve che operavano la percussione. Il suonatore di tamburi
poteva eseguire differenti ritmi e differenti partiture se i pistoncini
erano spostati.⁹ Secondo Charles B. Fowler, gli automi erano una "banda
musicale di robot" i quali potevano eseguire "più di cinquanta movimenti
facciali e del corpo durante ogni selezione musicale."¹⁰

Al-Jazari inventò anche un automa per il lavaggio delle mani, utilizzando
per la prima volta il meccanismo di scarico utilizzato oggi per il vaso
delle toilette. Si tratta di un automa con sembianze femminili con un
bacile riempito d'acqua. Quando l'utilizzatore preme la leva, l'acqua
scorre e l'automa riempie nuovamente il bacile.¹¹ La sua "fontana del
pavone" era un altro dispositivo più sofisticato per il lavaggio delle mani
fornito di automi umanoidi come servi che offrono sapone e asciugamani.
Mark E. Rosheim la descrive così:

Al-Jazari in tal modo sembra sia stato il primo inventore a mostrare un
interesse nel creare macchina di forma umana per scopi pratici come
manipolare l'ambiente per il comfort delle persone.¹³

Villard de Honnecourt, nel suo taccuino degli anni 1230, mostra progetti
per automi zoomorfi e un angelo che rivolge perpetuamente il volto al sole.

Un'aquila in legno costruita da Regiomontano (1436-1476) volò - come
riferito da Hakewill - dalla città di Konigsberg per incontrare
l'imperatore, salutarlo e tornare indietro. Regiomontano costruì inoltre
una mosca di ferro della quale egli stesso ebbe a dire che ad una festa si
fosse levata dalle sue mani, avesse volato in cerchio e fosse ritornata a
lui.¹⁴

Nella cattedrale di Strasburgo sono presenti tre automi chiamati
«rohraffes», posti nella parte inferiore dell'organo, che venivano attivati
durante la Pentecoste, e, forse, anche in altre solennità.

Lo scrittore cinese Xiao Xun scrisse che quando il fondatore della dinastia
Ming Hongwu (r. 1368–1398) stava distruggendo il palazzo di Khanbaliq che
apparteneva alla precedente dinastia Yuan, vi furono trovati - tra i molti
altri dispositivi meccanici - degli automi dell'aspetto di tigri.¹⁵

Leonardo da Vinci progettò un automa più complesso intorno al 1495: appunti
riscoperti solo negli anni cinquanta nel codice Atlantico e in piccoli
taccuini tascabili databili intorno al 1495-1497 mostrano disegni
dettagliati per un cavaliere meccanico in armatura, che era apparentemente
in grado di alzarsi in piedi, agitare le braccia e muovere testa e
mascella.

Il Rinascimento testimonia un considerevole ritorno d'interesse per gli
automi. I trattati di Erone di Alessandria vennero pubblicati e tradotti in
latino e italiano. Nel Settecento furono costruiti numerosi automi per
meccanismi ad orologeria, principalmente dagli artigiani delle libere città
imperiali dell'Europa centrale. Questi dispositivi meravigliosi trovarono
ospitalità nei "gabinetti delle curiosità" o Wunderkammer delle corti
principesche europee. Per le grotte dei giardini furono costruiti automi
idraulici e pneumatici, simili a quelli descritti da Erone.

In Cartesio si può riscontrare una nuova attitudine nei confronti degli
automi, quando egli suggerisce che i corpi degli animali sono nient'altro
che complesse macchine: le ossa, i muscoli e gli organi potrebbero essere
rimpiazzati da pulegge, pistoni e camme.

In tal modo il meccanicismo divenne lo standard al quale erano comparati la
Natura e l'organismo. La Francia settecentesca fu la patria di quegli
ingegnosi giocattoli meccanici che sarebbero divenuti dei prototipi per i
motori della rivoluzione industriale. Così nel 1649, quando Luigi XIV era
ancora un bambino, un artigiano di nome Camus progettò per lui un cocchio
in miniatura, e cavalli completi di fanti e una signora nella vettura;
tutte queste figure mostravano un movimento perfetto. Secondo P. Labat, il
generale de Gennes costruì, nel 1688, oltre a macchine per l'artiglieria e
la navigazione, un pavone che camminava e mangiava. il gesuita Athanasius
Kircher produsse diversi automi per mettere in scena spettacoli, tra cui
una statua che parlava .

Il primo automa del mondo costruito con successo è considerato Il suonatore
di flauto, inventato dal francese Jacques de Vaucanson nel 1737. Egli
costruì inoltre un'anatra meccanica, l'anatra digeritrice, che dava
l'illusione di nutrirsi e defecare, il che sembrava avvalorare le idee
cartesiane che gli animali non sono altro che macchine biologiche.

A partire dal 1770 una macchina per giocare a scacchi chiamata Il Turco,
creata da Wolfgang von Kempelen, fece il giro delle corti europee venendo
spacciata per automa. Solo molti anni dopo, nel 1857, si scoprì che in
realtà il Turco aveva un operatore all'interno: l'ingegnoso meccanismo
nascondeva un elaborato imbroglio.

Tra gli altri costruttori di automi del Settecento vi sono il prolifico
inventore francese Pierre Jaquet-Droz e il suo contemporaneo Henri
Maillardet. Tra il 1770 ed il 1773 Pierre Jaquet-Droz e il figlio
Henri-Louis costruirono tre sorprendenti automi: uno scrivano, un
disegnatore ed un musicista (ancora funzionanti, si trovano nel Musèe d'Art
et d'Histoire di Neuchâtel in Svizzera). Maillardet, un meccanico svizzero,
costruì un automa capace di disegnare quattro figure e scrivere tre poemi
(oggi conservato al museo scientifico del Franklin Institute di
Filadelfia). John Joseph Merlin, di origine belga, creò il meccanismo
dell'automa del Cigno d'argento (ora al Bowes Museum).¹⁶

Secondo il filosofo Michel Foucault, Federico II il Grande, re di Prussia
dal 1740 al 1786, era "ossessionato" dagli automi¹⁷ . Secondo Manuel de
Landa, "mise insieme le sue armate così come un meccanismo ben oliato i cui
componenti erano guerrieri simili a robot."

Il Giappone adottò gli automi durante il periodo Edo (1603 - 1867); erano
noti come Karakuri ningyō (からくり人形?).

Il famoso prestigiatore Jean Eugène Robert-Houdin (1805 - 1871) era
conosciuto per aver creato automi per i suoi spettacoli da palcoscenico.

Il periodo tra il 1860 e il 1910 è conosciuto come "l'età d'oro degli
automi". In quegli anni prosperavano a Parigi numerose piccole imprese
familiari di costruttori di automi. Dalle loro officine esportarono in
tutto il mondo migliaia di automi meccanici e uccelli meccanici che
cantavano. Sono questi automi francesi ad essere collezionati oggi e,
sebbene oggi rari e costosi, attraggono collezionisti da ogni parte del
mondo. I principali costruttori francesi furono Vichy, Roullet & Decamps,
Lambert, Phalibois, Renou e Bontems.

Automi contemporanei

Gli automi contemporanei continuano questa tradizione enfatizzando
l'aspetto artistico, piuttosto che la sofisticazione tecnologica. Gli
automi contemporanei sono rappresentati dalle opere del Cabaret Mechanical
Theatre nel Regno Unito e Dug North, Chomick+Meder¹⁸ e Thomas Kuntz¹⁹ negli
Stati Uniti.

Un'evoluzione dei giocattoli meccanizzati sviluppati nel corso del
Sette-Ottocento è rappresentata dagli automi costruiti in carta. Malgrado
la relativa semplicità del materiale, gli automi di carta sono
intrinsecamente oggetti con un alto grado di tecnologia, in cui i principi
della meccanica incontrano la creatività dell'arte.

Influenza nella cultura

- Martin Scorsese, nel film Hugo Cabret (2011), ricorre analogamente alla
  figura di un automa come espediente narrativo.
- Giuseppe Tornatore, nel film La migliore offerta (2013) introduce un
  automa come importante elemento della narrazione.
- Nell'avventura grafica Syberia (2002) la Fabbrica Voralberg è una piccola
  impresa da sempre specializzata nella fabbricazione di automi ad
  orologeria di altissima qualità, che ricorrono numerose volte nel corso
  della storia.

Note

[1] Needham, Volume 2, 53.
[2] Arslan Terzioglu (2007), The First Attempts of Flight, Automatic
  Machines, Submarines and Rocket Technology in Turkish History, in H. C.
  Guzel (ed.), The Turks, pp. 804-10
[3] Ismail b. Ali Ebu'l Feda history, Weltgeschichte, hrsg. von Fleischer
  and Reiske 1789-94, 1831.
[4] A. Marigny (1760). Histoire de Arabes. Parigi, Bd. 3, S.206.
[5] Teun Koetsier (2001). "On the prehistory of programmable machines:
  musical automata, looms, calculators", Mechanism and Machine theory 36,
  pp. 590-591.
[6] Technology in the service of progress: The examples of hydraulic
  technologies, Ahmed Djebbar, Arab-Muslim Civilization in the Mirror of
  Universal, (UNESCO, 2010), 292, 300.
[7] Aulo Gellio, Noctes Atticae L. 10.
[8] Needham, Volume 2, 54.
[9] A 13th Century Programmable Robot, University of Sheffield
[10] Charles B. Fowler, The Museum of Music: A History of Mechanical
  Instruments, in Music Educators Journal, vol. 54, nº 2, ottobre 1967, pp.
  45-49.
[11] Mark E. Rosheim, Robot Evolution: The Development of Anthrobotics,
  Wiley-IEEE, 1994, pp. 9-10, ISBN 0-471-02622-0.
[12] Mark E. Rosheim, Robot Evolution: The Development of Anthrobotics,
  Wiley-IEEE, 1994, pp. 9, ISBN 0-471-02622-0.
[13] Mark E. Rosheim, Robot Evolution: The Development of Anthrobotics,
  Wiley-IEEE, 1994, p. 36, ISBN 0-471-02622-0.
[14] voce da Cyclopaedia
[15] Needham, Volume 4, Part 2, 133 & 508.
[16] Bowes Museum: History of the Silver Swan
[17] Vedi Michel Foucault, Discipline and Punish, New York, Vintage Books,
  1979, p.136: "The classical age discovered the body as object and target
  of power... The great book of Man-the-Machine was written simultaneously
  on two registers: the anatomico-metaphysical register, of which Descartes
  wrote the first pages and which the physicians and philosophers
  continued, and the technico-political register, which was constituted by
  a whole set of regulations and by empirical and calculated methods
  relating to the army, the school and the hospital, for controlling or
  correcting the operations of the body. These two registers are quite
  distinct, since it was a question, on one hand, of submission and use
  and, on the other, of functioning and explanation: there was a useful
  body and an intelligible body... The celebrated automata [of the 18th
  century] were not only a way of illustrating an organism, they were also
  political puppets, small-scale models of power: Frederick, the meticulous
  king of small machines, well-trained regiments and long exercises, was
  obsessed with them."
[18] Chomick+Meder
[19] Thomas Kuntz

Bibliografia

Fonti originali della voce in lingua inglese qui tradotta
- Needham, Joseph (1986). Science and Civilization in China: Volume 2.
  England: Cambridge University Press.
- J. Douglas Bruce, 'Human Automata in Classical Tradition and Mediaeval
  Romance', Modern Philology, Vol. 10, No. 4 (Apr., 1913), pp. 511-526,
  links.jstor.org.
- M. B. Ogle, 'The Perilous Bridge and Human Automata', Modern Language
  Notes, Vol. 35, No. 3 (Mar., 1920), pp. 129-136, links.jstor.org.
Per approfondimenti
- Le monde des automates, 1928
- Los falsos adanes. Historia y mito de los autómatas. Ceserani, G.P.
  Editorial Tiempo Nuevo, 1971.
- De Autómatas y otras maravillas, Vid. Alvar, C.
- Historia de Monstruos, Juan Jacobo Bajarlía.
- Máquinas de amar. Secretos del cuerpo artificial, Pilar Pedraza. Ed.
  Valdemar, 1998.
- Juego y Artificio. Autómatas y otras ficciones en la cultura del
  Renacimiento a la Ilustración, Alfredo Aracil
- El Turco: La Vida y Época de la Famosa Máquina Jugadora de Ajedrez del
  Siglo XVIII, Tom Standage, Editorial Walker & Company, 2002
- Secretos Medievales, Jesus Callejo, Editorial Temas de Hoy, 2006
- From music boxes to street organs R.DEWAARD 1967
- THE JAQUET-DROZ MECHANICAL PUPPETS EDMONDO DROZ 1971
- ENCYCLOPEDIA of Automatic Musical Instruments Q.David Bowers 1972
- CLOKWORK MUSIC W.J.G.ORD-HUME 1973
- Silver Anniversary Collection MUSICAL BOX SOCIETY INTERNATIONAL 1974
- The Marvelous World of Music Machines Heinrich Weiss-Stauffachｅr 1976
- MUSIC AND THE BRAIN MACDONALD CRITCHLEY & R.A.HENSON 1977
- MUSICAL INSTRUMENTS OF THE WORLD the Diagram Group 1976
- BARREL ORGAN W.J.G.ORD-HUME 1978
- ANDROIDS The Jaquet-Droz automaton F.M. Ricci 1979
- Musical Box W.J.G.ORD-HUME 1980
- The Musical Box Handbook Cylinder Boxes Graham Webb 1984
- Von der Aolsharfe zum Digitalspieler Jan _Brauers 1984
- Le MONDE des AUTOMATES ETUDE HISTORIQUE ET TECHNIQUEⅠⅡ A.Chapuis E.Gelis
  1984
- THE WONDERLAND OF MUSIC BOXES AND AUTOMATA Daniel Troquet 1989
- Clock and watch museum Geneva 1990 Musee d'art et d'histoire
- Museums of Horology La Chaux-de-Fonds Le Locle Francois Mercier 1991
- All'epoca delle scatole musicali
- AUTOMATES ET MUSIQUES Pendules Anne Winter-Jensen M.E.L.D.L. Geneve 1987
- L'Oregue de Barbarie Helmut Zeraschi Payot Lausanne 1980
- Faszinierende Welt der Automaten Annette Beyer Callwey Verlag Munchen
  1983
- Automaten Chrisian Bailly Hirmer
Testi in italiano
- Gian Paolo Cesarani, I falsi adami. Storia e mito degli automi, Milano,
  Feltrinelli, 1969.
- Gian Paolo Ceserani, Gli automi. Storia e mito, Roma-Bari, Laterza, 1983
  [1969], ISBN 88-420-2339-6.
- Monica Pugliara, Il mirabile e l'artificio, L'Erma di Bretschneider,
  2003, ISBN 88-8265-195-9.
- Cesare Rossi, Una breve rassegna sugli automi: la meccanica che ha
  preceduto i robot (atti del convegno) (PDF).
- Lucio Russo, La rivoluzione dimenticata, VII edizione, Milano,
  Feltrinelli, 2013, ISBN 9788807883231.
- Mario Losano, Storie di automi. Dalla Grecia Classica alla Belle Epoque.,
  Einaudi, 1990, ISBN 88-06-12224-X.

Voci correlate

- Androide
- Automa cavaliere
- Ginoide
- Mecha
- Robot

Altri progetti

- Wikimedia Commons contiene immagini o altri file su automi

Collegamenti esterni

- (EN) Breve storia degli automi, automata.co.uk.
- (EN) AutomatomaniA, automatomania.com.
- (EN) L'automa di Maillardet nel sito del Franklin Institute
- (EN) I Karakuri giapponesi, karakuri.info.
- Automa meccanico, in Thesaurus del Nuovo soggettario, BNCF, marzo 2013.

Robot

Il robot (pron. robòt o robó, all'inglese ròbot¹ , dalla parola ceca robota
che significa lavoro pesante, a propria volta derivata dall'antico slavo
ecclesiastico rabota, servitù² ) è una qualsiasi macchina (di forma più o
meno antropomorfa), in grado di svolgere più o meno indipendentemente un
lavoro al posto dell'uomo.

Che cos'è un robot

Nel linguaggio comune, un robot è un'apparecchiatura artificiale che compie
determinate azioni in base ai comandi che gli vengono dati e alle sue
funzioni, sia in base ad una supervisione diretta dell'uomo, sia
autonomamente basandosi su linee guida generali, magari usando processi di
intelligenza artificiale; questi compiti tipicamente dovrebbero essere
eseguiti al fine di sostituire o coadiuvare l'uomo, come ad es. nella
fabbricazione, costruzione, manipolazione di materiali pesanti e
pericolosi, o in ambienti proibitivi o non compatibili con la condizione
umana o semplicemente per liberare l'uomo da impegni.

Un robot così definito dovrebbe essere dotato di connessioni guidate dalla
retroazione tra percezione e azione, e non dal controllo umano diretto.
L'azione può prendere la forma di motori elettro-magnetici, o attuatori,
che muovono un arto, aprono e chiudono una pinza, o fanno deambulare il
robot. Il controllo passo-passo e la retroazione sono forniti da un
programma che viene eseguito da un computer esterno o interno al robot, o
da un microcontroller. In base a questa definizione, il concetto di robot
può comprendere quasi tutti gli apparati automatizzati.

In alternativa, il termine robot viene usato per indicare un essere
artificiale, un automa o androide, che replichi e somigli ad un animale
(reale o immaginario) o ad un uomo. Il termine ha finito per essere
applicato a molte macchine che sostituiscono direttamente un umano o un
animale, nel lavoro o nel gioco. In questo modo, un robot può essere visto
come un tentativo di biomimica. L'antropomorfismo è forse ciò che ci rende
così riluttanti a riferirci a una moderna e complessa lavatrice, come a un
robot. Comunque, nella comprensione moderna, il termine implica un grado di
autonomia che escluderebbe molte macchine automatiche dal venire chiamate
robot. Si tratta di una ricerca per robot sempre più autonomi, il che è il
maggiore obiettivo della ricerca robotica e il motivo che guida gran parte
del lavoro sull'intelligenza artificiale.

Le discipline coinvolte nella progettazione e realizzazione dei robot sono
molteplici: robotica, cibernetica, meccanica, automatica, elettronica,
meccatronica, informatica, intelligenza artificiale, ecc.

Origine del termine robot

Brano estratto da R.U.R. di Karel Čapek
«Il vecchio Rossum, grande filosofo, […] cercò di imitare con una sintesi
chimica la sostanza viva detta protoplasma finché un bel giorno scoprì una
sostanza il cui comportamento era del tutto uguale a quello della sostanza
viva sebbene presentasse una differente composizione chimica, era l'anno
1932 […]. Per esempio, poteva ottenere una medusa con il cervello di
Socrate oppure un lombrico lungo cinquanta metri. Ma poiché non aveva
nemmeno un pochino di spirito, si ficcò in testa che avrebbe fabbricato un
normale vertebrato, addirittura l'uomo. […] Doveva essere un uomo, visse
tre giorni completi. Il vecchio Rossum non aveva un briciolo di gusto. Quel
che fece era terribile. Ma dentro aveva tutto quello che ha un uomo.
Davvero, un lavoro proprio da certosino. E allora venne l'ingegner Rossum,
il nipote del vecchio. Una testa geniale. Appena vide quel che stava
facendo il vecchio, disse: È assurdo fabbricare un uomo in dieci anni. Se
non lo fabbricherai più rapidamente della natura, ce ne possiamo benissimo
infischiare di tutta questa roba. […] Gli bastò dare un'occhiata
all'anatomia per capire subito che si trattava d'una cosa troppo complicata
e che un buon ingegnere l'avrebbe realizzata in modo più semplice. […]
Quale operaio è migliore dal punto di vista pratico? È quello che costa
meno. Quello che ha meno bisogni. Il giovane Rossum inventò l'operaio con
il minor numero di bisogni. Dovette semplificarlo. Eliminò tutto quello che
non serviva direttamente al lavoro. Insomma, eliminò l'uomo e fabbricò il
Robot. »

Il termine robot deriva dal termine ceco robota, che significa lavoro
pesante o lavoro forzato (al plurale in ceco è roboty, mentre in italiano è
invariabile). L'introduzione di questo termine si deve allo scrittore ceco
Karel Čapek, il quale usò per la prima volta il termine nel 1920 nel suo
dramma teatrale I robot universali di Rossum. In realtà non fu il vero
inventore della parola, la quale infatti gli venne suggerita dal fratello
Josef, scrittore e pittore cubista, il quale aveva già affrontato il tema
in un suo racconto del 1917, Opilec (L'ubriacone), nel quale però aveva
usato il termine automat, automa. La diffusione del romanzo di Čapek, molto
popolare sin dalla sua uscita, servì a dare fama al termine robot.

Il termine non è solo della lingua ceca, infatti parole simili (derivate
dalla stessa radice) esistono in varie lingue slave: robota significa
lavoro anche in polacco, ed in russo ed ucraino è rabota; in polacco esiste
anche il termine robotnik, operaio, mentre il verbo robić significa fare.

Anche se i robot di Čapek erano uomini artificiali organici, la parola
robot viene oggi quasi sempre usata per indicare un uomo meccanico. Il
termine androide (dal greco anèr, andròs, uomo, e che quindi può essere
tradotto a forma d'uomo) può essere usato in entrambi i casi, mentre un
cyborg (organismo cibernetico o uomo bionico) indica una creatura che
combina parti organiche e meccaniche (uomo bionico).

Il termine robotica venne usato per la prima volta (su carta stampata) nel
racconto di Isaac Asimov intitolato Bugiardo! (Liar!, 1941), presente nella
sua famosa raccolta Io, Robot. In esso, egli citava le tre regole della
robotica, che in seguito divennero le Tre leggi della robotica (poi
accresciute a quattro con l'introduzione della Legge Zero).

L'idea di persone artificiali risale almeno all'antica leggenda di Cadmo,
che seppellì dei denti di drago che si trasformarono in soldati; e al mito
di Pigmalione, la cui statua di Galatea prese vita. Nella mitologia
classica, il deforme dio del metallo (Vulcano o Hephaestus) creò dei servi
meccanici, che andavano dalle intelligenti damigelle dorate a più
utilitaristici tavoli a tre gambe che potevano spostarsi di loro volontà.
La leggenda ebraica ci parla del Golem, una statua di argilla, animata
dalla magia cabalistica. Nell'estremo Nord canadese e nella Groenlandia
occidentale, le leggende Inuit raccontano di Tupilaq (o Tupilak), che può
essere creato da uno stregone per dare la caccia e uccidere un nemico.
Usare un Tupilaq per questo scopo può essere un'arma a doppio taglio, in
quanto una vittima abbastanza ferrata in stregoneria può fermare un Tupilaq
e riprogrammarlo per cercare e distruggere il suo creatore.

Il primo progetto documentato di un robot umanoide venne fatto da Leonardo
da Vinci attorno al 1495. Degli appunti di Da Vinci, riscoperti negli anni
cinquanta, contengono disegni dettagliati per un cavaliere meccanico, che
era apparentemente in grado di alzarsi in piedi, agitare le braccia e
muovere testa e mascella. Il progetto era probabilmente basato sulle sue
ricerche anatomiche registrate nell'Uomo vitruviano. Non si sa se tentò o
meno di costruire il robot (vedi: Automa cavaliere di Leonardo).

Il primo robot funzionante conosciuto venne creato nel 1738 da Jacques de
Vaucanson, che fabbricò un androide che suonava il flauto, così come
un'anatra meccanica che, secondo le testimonianze, mangiava e defecava. Nel
racconto breve di E.T.A. Hoffmann L'uomo di sabbia (1817) compariva una
donna meccanica a forma di bambola, nel racconto Storia filosofica dei
secoli futuri (1860) Ippolito Nievo indicò l'invenzione dei robot (da lui
chiamati 'omuncoli', 'uomini di seconda mano' o 'esseri ausiliari') come
l'invenzione più notevole della storia dell'umanità, e in Steam Man of the
Prairies (1865) Edward S. Ellis espresse l'affascinazione americana per
l'industrializzazione. Giunse un'ondata di storie su automi umanoidi, che
culminò nell'Uomo elettrico di Luis Senarens, nel 1885.

Una volta che la tecnologia avanzò al punto che la gente intravedeva delle
creature meccaniche come qualcosa più che dei giocattoli, la risposta
letteraria al concetto di robot rifletté le paure che gli esseri umani
avrebbero potuto essere rimpiazzati dalle loro stesse creazioni.
Frankenstein (1818), che viene spesso definito il primo romanzo di
fantascienza, è divenuto un sinonimo di questa tematica. Quando il dramma
di Čapek, R.U.R., introdusse il concetto di una catena di montaggio operata
da robot che costruivano altri robot, il tema prese delle sfumature
politiche e filosofiche, ulteriormente disseminate da film classici come
Metropolis (1927), il popolare Guerre stellari (1977), Blade Runner (1982)
e Terminator (1984).

Nella introduzione al suo romanzo Abissi d'acciaio, Asimov ha detto di
avere fatto in tale serie "Il primo uso della parola robotica nella storia
del mondo, per quanto ne so."

Uso contemporaneo dei robot

I robot attualmente utilizzati sono di fatto dei sistemi ibridi complessi
costituiti da vari sottosistemi quali computer (es. microcontrollori)
ovvero da una parte hardware elettronica opportunamente programmata tramite
software che regola o controlla una parte meccanica costituita da
servomeccanismi per l'esecuzione dei compiti meccanici desiderati; esistono
moltissime tipologie di Robot differenti sviluppate per assolvere i compiti
più disparati. Ormai è larghissimo l'impiego dei robot nell'industria
metalmeccanica (es. catene di montaggio) e non solo. Si possono catalogare
i robot in due macro categorie: "autonomi" e "non autonomi".

I robot "non autonomi" sono i classici robot utilizzati per adempiere a
specifici compiti che riescono ad assolvere in maniera più efficace
dell'uomo; alcuni casi sono i robot utilizzati nelle fabbriche con l'enorme
vantaggio di poter ottenere una produzione più precisa, veloce ed a costi
ridotti senza utilizzo o con ridotta manodopera umana; oppure i robot
utilizzati per lavorare in ambienti ostili (ad esempio su Marte) o con
sostanze tossiche; questi robot sono detti "non autonomi" poiché sono
guidati da un software deterministico che fa eseguire loro il lavoro in
modo ripetitivo (vedi automazione industriale) oppure sono direttamente
pilotati dall'uomo (vedi i robot utilizzati dagli artificieri).

Tra gli esempi di robot "non autonomi" gli ultimi esemplari introdotti
nella catena di montaggio del modello Fiesta negli stabilimenti di Colonia
in Germania della Casa automobilistica Ford. Già dall'agosto 2016 sono in
fase di sperimentazione l'uso dei CO-BOTS robot collaborativi in grado di
lavorare insieme agli operai della catena di montaggio.

I robot "autonomi" sono invece caratterizzati dal fatto che operano in
totale autonomia ed indipendenza dall'intervento umano e sono in grado di
prendere decisioni anche a fronte di eventi inaspettati. Questi Robot sono
programmati solitamente con algoritmi che si rifanno a tecniche di
intelligenza artificiale: algoritmi genetici, logica fuzzy, machine
learning, reti neurali. I robot autonomi sono adatti a svolgere compiti in
ambienti non noti a priori; tipicamente si tratta di robot mobili. Alcuni
piccoli robot autonomi vengono utilizzati per il taglio dell'erba nei
giardini e nelle pulizie domestiche: essi autonomamente decidono quando
partire, dove tagliare/pulire e quando tornare alla base per ricaricarsi.

Nell'industria cinematografica l'uso dei robot è applicato nella
realizzazione degli effetti speciali, realizzando macchine comandate (gli
animatronic) che simulino al meglio la verosimiglianza dei movimenti (ad
esempio lo squalo utilizzato nel film Lo squalo o i dinosauri di Jurassic
Park). Massimi realizzatori di questo genere di robot sono stati Carlo
Rambaldi e Stan Winston.

Sviluppi futuri

Quando gli studiosi di robotica iniziarono i primi tentativi di imitare
l'andatura di uomini e animali, scoprirono che era incredibilmente
difficile; era richiesta una capacità di calcolo molto superiore a quella
disponibile all'epoca. Così si diede enfasi ad altre aree di ricerca.
Semplici robot con le ruote furono usati per condurre esperimenti su
comportamento, navigazione, e studio del percorso. Quando gli ingegneri
furono pronti a tentare di far camminare di nuovo i robot, scelsero di
provare con esapodi o altre piattaforme a più zampe, simili per forma e
movimento agli insetti ed agli artropodi. Questa scelta ha portato a
risultati di grande flessibilità ed adattabilità a diversi ambienti. La
maggiore stabilità statica data dalle quattro o più zampe rende più facile
il lavorare con loro. Solo in tempi molto recenti si sono fatti progressi
verso robot deambulanti bipedi.

Un altro campo di grandi progressi è quello medico. Alcune società
produttrici hanno ottenuto le necessarie autorizzazioni per poter far
utilizzare i loro robot in operazioni chirurgiche dall'invasività minima.
Un settore affine, quello dell'automazione dell'attività di laboratorio
analitico, vede robot da banco impegnati nelle attività routinarie di
incubazione, manipolazione di campioni ed analisi chimica e biochimica.

Altri campi in cui è probabile che i robot sostituiscano il lavoro umano
sono l'esplorazione del mare profondo e l'esplorazione spaziale. Per questi
compiti sono di norma preferite delle strutture robotiche di tipo
artropode. Mark W. Tilden ex ricercatore dei Los Alamos National
Laboratories si è specializzata in "gambe" economiche, piegabili ma non
snodate, mentre altri cercano di replicare il movimento tipico dei granchi.

Il 17 agosto 2016 la NASA annuncia che su Marte potrebbero andare dei robot
umanoidi in grado di accompagnare l'uomo nelle prossime misioni spaziali.
Per tale motivo l'Ente americano ha lanciato un concorso internazionale per
incentivarne la messa a punto. Tale programmazione consentirà all'umanoide
di aiutare gli astronauti umani a compiere operazioni utili e propedeutiche
alla nostra sopravvivenza come la preparazione dell'habitat iniziale, la
messa a punto delle linee di comunicazione e i sistemi di supporto vitale
così come l'impostazione delle primissime fasi della ricerca scientifica
sul suolo marziano. Attualmente la sfida è già aperta e, dopo le
iscrizioni, per la programmazione di robot-astronauti in grado di
identificare e riparare guasti vari interni ed esterni ai moduli spaziali,
si preannuncia che le sfide termineranno nel giugno del 2017.

Robot alati sperimentali e altri esempi che sfruttano la biomimica sono
nelle prime fasi di sviluppo. I cosiddetti "nanomotori" e gli "smart wire"
promettono di semplificare drasticamente il movimento, mentre sembra
probabile che la stabilizzazione in volo verrà migliorata da giroscopi
estremamente piccoli. Un impulso fondamentale a questo tipo di lavoro è
data dalla ricerca militare nelle tecnologie di spionaggio.

Attualmente, un settore in pieno sviluppo è rappresentato anche dai sistemi
per la manipolazione con ritorno di forza, le cosiddette interfacce
aptiche.

Competizioni

Dean Kamen, fondatore di FIRST, e dell'American Society of Mechanical
Engineers (ASME) ha creato un forum competitivo che ispira i giovani, le
loro scuole e le comunità ad apprezzare la scienza e la tecnologia.

Le loro Robotics Competition sono delle competizioni multinazionali che
riuniscono giovani e professionisti per risolvere un problema di
progettazione ingegneristica in modo intenso e competitivo. Nel 2003 le
competizioni hanno interessato più di 20.000 studenti suddivisi in oltre
800 squadre per 24 competizioni. Le squadre provenivano da Canada, Brasile,
Regno Unito e Stati Uniti. Contrariamente alle competizioni di sumo
robotico che si svolgono regolarmente in alcuni luoghi, o le competizioni
tra robot da battaglia mostrate in televisione, queste comprendono la fase
di creazione del robot.

RoboCup è un'organizzazione dedicata allo sviluppo di una squadra di robot
completamente autonomi, che sia in grado di vincere entro il 2050 una
partita di calcio contro la squadra campione del mondo. Esistono molte e
diverse federazioni, che vanno dai robot a ruote a quelli a quattro zampe,
solo recentemente (2004) sono iniziate le competizioni per robot umanoidi,
per i quali si riscontrano ancora problemi di stabilità nella
deambulazione. A differenza di altre manifestazioni, la Robocup ha degli
scopi soprattutto scientifici, i membri sono soprattutto rappresentanti di
università, ed è sempre accompagnata da convegni dove si illustrano le
nuove scoperte. Tra le università italiane hanno preso parte o partecipano
tuttora, in varie categorie, i team di Politecnico di Milano, Politecnico
di Torino e Università di Roma "Sapienza".

Possibili pericoli

Nella narrativa fantascientifica, la preoccupazione che i robot possano
competere con l'uomo, ribellarsi o addirittura sterminarlo è un argomento
molto comune. Nella serie di racconti Io, Robot, Isaac Asimov enunciò le
Tre Leggi della Robotica nel tentativo di controllare la competizione fra
robot ed esseri umani:

- Un robot non può recar danno a un essere umano, né permettere che, a
  causa della propria negligenza, un essere umano patisca danno.
- Un robot deve sempre obbedire agli ordini degli esseri umani, a meno che
  contrastino con la Prima Legge.
- Un robot deve proteggere la propria esistenza, purché questo non
  contrasti con la Prima o la Seconda Legge.

La soluzione del problema però non è così semplice: Asimov stesso ha basato
molti dei suoi racconti e romanzi sui problemi dell'applicabilità e
sufficienza delle Tre Leggi. Le leggi che potrebbero o dovrebbero
applicarsi ai robot o ad altro "capitale autonomo" in cooperazione o in
competizione con gli esseri umani ha stimolato l'indagine macroeconomica di
tale competizione da parte di Alessandro Acquisti che si è basato su un
lavoro molto più vecchio di John von Neumann.

Le macchine che nella realtà vengono comunemente chiamate robot sono dei
semplici meccanismi automatici, capaci di muoversi ma solo in base alle
precise istruzioni fornitegli. Non hanno né volontà, né coscienza di sé o
del mondo che li circonda. Quindi gli eventuali incidenti che possono
accadere (come a Jackson nel Michigan, il 21 luglio 1984, un robot
industriale schiacciò un operaio contro una sbarra di sicurezza) non sono
concettualmente diversi dagli incidenti provocati dal crollo di un
pavimento. Gli scenari fantascientifici di "rivolta" dei robot contro gli
esseri umani non sono impossibili, ma presuppongono che i robot in futuro
possano diventare assai più sofisticati e utilizzare un livello sconosciuto
di intelligenza artificiale.

Generazioni di robot

Robot di prima generazione: Si definiscono così, i robot in grado
semplicemente di eseguire sequenze prestabilite di operazioni
indipendentemente dalla presenza o dall'intervento dell'uomo.

Robot di seconda generazione: Questi robot hanno la capacità di costruire
un'immagine (modello interno) del mondo esterno, di correggerla e
perfezionarla continuamente. È in grado di scegliere la migliore strategia
di controllo. Il robot di seconda generazione è in grado di finire ciò che
gli è stato programmato malgrado la presenza di fenomeni di disturbo non
prevedibili a priori.

Robot di terza generazione: Hanno un'intelligenza artificiale. Questo robot
è in grado di costruire nuovi algoritmi e di verificarne la coerenza da
solo.

Influenza nel cinema

- Il primo film in cui a "recitare" è un robot è Metropolis, un film muto
  diretto dal regista Fritz Lang.
- Due robot tra i più famosi in ambito cinematografico sono: C-3PO ed
  R2-D2. I due, amici inseparabili, compaiono nella celebre saga Guerre
  stellari ideata dal regista George Lucas.
- Blade Runner è un film del 1982 diretto da Ridley Scott. Protagonisti del
  film sono alcuni robot, chiamati "replicanti", che possiedono una forza
  superiore a quella umana ma una longevità molto ridotta (appena 4 anni).
- Un "robot-attore" di fama indiscussa è Terminator, protagonista
  dell'omonimo film del 1984 diretto dal noto regista James Cameron.
- Nel 1987 c'è la prima uscita del film RoboCop diretto da Paul Verhoeven.
  Il film ha come protagonista un "robot-poliziotto", che attraverso una
  programmazione informatica acquisisce tre direttive inviolabili: "ordine
  pubblico totale", "proteggere gli innocenti" e "far rispettare la legge".
- Per quanto riguarda il campo militare è da ricordare Solo un film del
  1996.

Note

[1] Robot (dizionario italiano), su Sapere.it. URL consultato il 1 gennaio
  2015.
    «La pronuncia più vicina a quella della lingua originale è ròbot;
    tuttavia la più comune in italiano, e come tale consigliabile, è robòt
    (con la variante robó), che riflette il passaggio di questa parola
    attraverso la lingua francese.».
[2] (EN) Online Etymology Dictionary

Voci correlate

Robot realizzati

- Aibo
- ASIMO
- Nabaztag
- NAO (robot)
- iCub
- InMoov

Androidi femminili

- Actroid
- EveR-1
- Project Aiko
- Repliee Q1

Tipi di robot

- Androide
- Cyborg
- Ginoide
- Mecha
- Robot industriali
- Robot mobili
- Rover (astronautica)
- Sonda spaziale
- Telescopio robotico
- Animatronica

Scienze e teorie

- Le Tre leggi della robotica di Isaac Asimov
- Cibernetica
- Automatica
- Teoria del Controllo
- Intelligenza artificiale
- Nanotecnologia
- Naturoid
- Reti neurali
- Roboetica
- Robotica
- Telepresenza
- Scienze cognitive

Roboticisti famosi

- Ronald Arkin, Georgia Tech College of Computing
- Rodney Brooks, MIT AI Lab
- Reymond Clavel, Inventore del robot Delta, École polytechnique fédérale
  de Lausanne, LSRO
- George Devol Inventor of the patented devices behind Unimation Inc.
- Joseph F. Engelberger Founder of Unimation Inc.
- Chico McMurtrie Founder of Amorphic Robot Works
- Hans Moravec, CMU Robotics Institute
- Masahiro Mori
- Sebastian Thrun, ex direttore del laboratorio di Intelligenza Artificiale
  della Stanford University
- Mark Tilden, LANL
- Red Whittaker,   CMU Robotics Institute
- Bruno Siciliano, Università degli Studi di Napoli Federico II Presidente
  della IEEE Robotics and Automation Society dal 2005

Altri progetti

- Wikiquote contiene citazioni di o su robot
- Wikizionario contiene il lemma di dizionario «robot»
- Wikimedia Commons contiene immagini o altri file su robot
- Wikiquote contiene citazioni di o su robot
- Wikimedia Commons contiene immagini o altri file su robot

Collegamenti esterni

- Robot, su Open Directory Project, Netscape Communications. (Segnala su
  DMoz un collegamento pertinente all'argomento "Robot")

Scienza dell'automazione

Per scienza dell'automazione o automatica si definisce quella disciplina
con applicazioni ingegneristiche che studia le modalità attraverso le quali
una sequenza di eventi desiderati avviene in maniera autonoma e senza
l'intervento umano¹ .

L'automatica si basa su due discipline:

- La teoria dei sistemi è un'area di studi interdisciplinari che si occupa
  dello studio delle proprietà di un sistema (es. motore, aereo, forno)
  nella sua interezza. Partendo da un modello matematico, ovvero un insieme
  di equazioni differenziali che permettono di descrivere il comportamento
  del sistema, si studiano le proprietà quali la stabilità, tipologia della
  risposta, ecc.
- La teoria del controllo (o controlli automatici) è un'area di studi che
  si occupa della definizione di algoritmi di controllo in retroazione o in
  anello aperto che consentano di modificare il comportamento del sistema,
  in modo da garantire delle specifiche desiderate.

Note

[1] Monaco, 2011

Bibliografia

- Salvatore Monaco, Sistemi lineari - Elementi di analisi, Bologna,
  Esculapio, 2011, ISBN 978-88-7488-196-3.
- Alberto Isidori, Sistemi di controllo, edizioni scientifiche Siderea,
  Roma, 1992

Retroazione

In fisica e automazione, la retroazione o retroregolazione (feedback in
inglese, ma usato spesso anche in italiano) è la capacità di un sistema
dinamico di tenere conto dei risultati del sistema per modificare le
caratteristiche del sistema stesso.

Descrizione

In un controllo in retroazione il valore della variabile in uscita dal
sistema viene letto dal controllore che agisce modificando l'ingresso del
sistema. Questa caratteristica differenzia i sistemi retroazionati (ad
"anello") dai sistemi non retroazionati (ad anello aperto), in cui cioè la
funzione di retroazione è nulla (e non "unitaria"). Per i sistemi in
retroazione esistono tre funzioni di trasferimento d'interesse per lo
studio: la funzione "ad anello aperto" è quindi quella del sistema
controllato g_d(s), in cui è presente la costante moltiplicativa
manipolabile in sede di progettazione detta "guadagno d'anello" ed indicata
con k; quella "d'anello" è quella del sistema in serie chiuso
controllore-controllato (considerata sia nel luogo delle radici che dal
criterio di Nyquist) che si ottiene facendo coincidere l'uscita con
l'ingresso L(s)=g_d(s) g_c(s) o moltiplicando quella ad anello aperto per
quella caratteristica del controllore stesso (g_c(s)); infine la funzione
equivalente totale (del sistema diretto equivalente a quello retroazionato
in esame, cioè che abbia stesso ingresso e stessa uscita), detta anche "ad
anello chiuso" è:

G(s) = \frac {g_d(s)} {1 \pm L(s)} = \frac {g_d(s)} {1 \pm g_c(s)g_d(s)}

a seconda che la retroazione sia positiva (meno) o negativa (più), ovvero
che nel primo nodo il segnale del controllore si sommi o sottragga al
segnale in ingresso. Nei sistemi di controllo ad anello aperto il valore
della variabile manipolabile viene determinato dentro il nostro sistema
sfruttando modelli matematici; tali sistemi vengono chiamati predittivi
perché non viene effettuata nessuna verifica sul valore. Nei sistemi di
controllo retroazionati invece il valore viene determinato e corretto in
base alla misura della variabile controllata e alla verifica della sua
rispondenza; per questo motivo i sistemi retroazionati vengono anche
chiamati "esplorativi".

Ad esempio, un sistema di puntamento ad anello aperto calcola a priori le
coordinate dell'obiettivo, quindi sia la direzione che l'alzata, calcola
gli effetti del vento o di altri agenti esterni e poi incomincia a sparare.
Il fatto che l'obiettivo sia stato centrato o meno non influisce sul
puntamento dei colpi successivi. In un sistema retroazionato invece, dopo
che è stato sparato il primo colpo si valuta la distanza dell'obiettivo e
in base a questa vengono modificate le impostazioni dell'arma. Il secondo
sistema è quindi molto più efficiente del primo.

La teoria dei sistemi retroazionati è utilizzata in molti campi delle
scienze pure, delle scienze applicate (tra cui i controlli automatici) e
della biologia. In quest'ultimo campo è interessante l'applicazione della
retroazione allo studio dell'ecosistema planetario nota come ipotesi Gaia.
Il concetto è stato introdotto dal matematico americano Norbert Wiener
negli anni quaranta.

Retroazione positiva

Si parla di "retroazione positiva" quando i risultati del sistema vanno ad
amplificare il funzionamento del sistema stesso, che di conseguenza
produrrà risultati maggiori che amplificheranno ulteriormente il
funzionamento del sistema. I sistemi con retroazione positiva sono
facilmente (ma non sempre) instabili e tipicamente portano il sistema a
divergere.

Ice albedo feedback
- un esempio di sistema o processo con retroazione positiva in natura è la
  fusione dei ghiacci ai poli. I ghiacci dei poli, essendo bianchi,
  riflettono i raggi solari. L'aumento della temperatura globale fa fondere
  i ghiacci e questo comporta l'aumento della quantità di raggi solari
  assorbiti dalla terra per diminuzione dell'effetto albedo, il che fa
  aumentare ulteriormente la temperatura globale e fondere altri ghiacci e
  così via. Questo sistema è instabile e porta alla fusione completa dei
  ghiacci. Lo stesso meccanismo o processo può anche agire al contrario,
  sempre in retroazione positiva, portando all'espansione dei ghiacci del
  Polo.
Effetto Larsen
- un altro esempio di retroazione positiva arriva dall'elettroacustica:
  posto il fatto che una catena elettroacustica è essenzialmente composta
  da un trasduttore di ingresso (ad esempio un microfono), da un apparato
  di amplificazione elettronica e da un trasduttore di uscita (generalmente
  un altoparlante), se il suono riprodotto dall'altoparlante ritorna
  acusticamente attraverso l'ambiente al microfono si può verificare
  l'insorgere di un acuto sibilo o una vibrazione grave continua, il cui
  volume, per effetto della reazione positiva, tende ad aumentare
  all'infinito.
- Questo fenomeno si chiama anche innesco o ritorno e si può eliminare solo
  allontanando il microfono dagli altoparlanti, rompendo quindi l'anello di
  retroazione, o abbassando drasticamente il volume ossia portando il
  coefficiente di amplificazione ad un valore minore di uno. Se nella
  catena di amplificazione è presente un equalizzatore, è talvolta
  possibile, operando un'attenuazione della frequenza del tono
  dell'innesco, eliminare o ridurre di parecchio l'insorgere dell'effetto
  Larsen; tale fatto si basa sul concetto che riducendo anche di poco con
  l'equalizzatore il livello della banda di frequenza interessata
  all'innesco, si riduce di fatto la possibilità dell'innesco senza dover
  necessariamente ridurre troppo il guadagno del segnale, e quindi senza
  alterare in modo troppo l'evidente le caratteristiche tonali di quel
  segnale. Questa tecnica è normalmente usata dai sound engineer durante
  gli spettacoli dal vivo e richiede sia ottimo orecchio acustico per
  individuare la frequenza da attenuare che velocità e precisione nella
  manovra.
- La manovra può essere anche solo temporanea; per esempio, abbassando di 3
  decibel una data banda di frequenze dell'equalizzatore per poi rialzarla
  di 3 decibel appena l'innesco cessa. Questa è considerata una manovra di
  emergenza, non in grado di assicurare stabilità al sistema di
  riproduzione sonora.
- Un'altra tecnica molto utilizzata, e di efficacia molto più alta,
  richiede un equalizzatore di tipo "parametrico" e consiste nell'eliminare
  esclusivamente una minima porzione di segnale nella banda dove avviene
  l'innesco; tale tecnica consente di rendere ancora più "trasparenti" gli
  interventi correttivi, a tutto beneficio dell'integrità tonale del
  segnale audio.
- Lo stesso effetto avviene anche nell'amplificazione di chitarre
  acustiche, che avviene per mezzo di un pickup acustico (quindi un
  microfono specializzato) e valgono le considerazioni di cui sopra per
  l'eliminazione. Molti amplificatori per chitarra acustica includono
  infatti un filtro "notch" regolabile progettato per eliminare o almeno
  ridurre l'effetto Larsen.
- L'effetto Larsen avviene difficilmente nelle chitarre elettriche a cassa
  piena, dove il pickup è di tipo elettromagnetico ad induzione, quindi ben
  poco sensibili ai rumori acustici, ma è stato utilizzato da diversi
  chitarristi per creare effetti speciali, semplicemente appoggiando la
  paletta della chitarra all'amplificatore.
- Sempre tale effetto può affliggere la riproduzione di dischi in vinile,
  soprattutto ad alto volume e con giradischi economici. Le vibrazioni
  delle frequenze basse emesse dal sistema di altoparlanti "rientrano" nel
  giradischi e poi alla testina per conduzione acustica, generando un
  fortissimo rumore a bassa frequenza, praticamente impossibile da
  controllare. Per contrastare tale fenomeno in ambito domestico, taluni
  amplificatori dispongono di un filtro "rumble" o passa alto. Nell'epoca
  d'oro delle discoteche era invece consuetudine realizzare i supporti per
  i giradischi in cemento armato o scatolato riempito di sabbia, tenuti
  separati dalla struttura della console del Disc jockey in modo da
  risultare più isolati acusticamente possibile e utilizzare giradischi
  particolarmente pesanti e inerti, come il celeberrimo modello SL 1200 del
  costruttore giapponese Technics, diventato un'icona nel settore e rimasto
  in produzione per circa 30 anni, a conferma della validità in ambito
  lavorativo.

Retroazione negativa o controreazione

Si parla di "retroazione negativa" (o "controreazione") quando i risultati
del sistema vanno a smorzare il funzionamento del sistema stesso
stabilizzandolo. I sistemi con retroazione negativa sono in genere stabili
e tipicamente portano il sistema a convergere.¹

È il sistema con il quale ogni amplificatore audio, sia di segnale che di
potenza, stabilizza autonomamente il proprio guadagno, ovvero la funzione
di trasferimento dell'amplificatore stesso, sia in termini di guadagno che
di risposta in frequenza. È una funzione automatica, del tutto trasparente
all'utente.

Il sistema di puntamento spiegato sopra è un sistema a retroazione
negativa: il risultato del tiro viene usato per stabilizzare il sistema
sull'obiettivo. Ogni tiro può essere utilizzato per puntare meglio l'arma e
arrivare più vicino al bersaglio.

Cloud (albedo) feedback
- un esempio di sistema con retroazione negativa preso dall'ipotesi Gaia è
  la presenza del vapore acqueo nell'atmosfera. Con l'aumento della
  temperatura globale una quantità maggiore di vapore acqueo si forma
  nell'atmosfera dando vita ad un quantità maggiore di nubi. Le nubi, così
  come i ghiacci del polo, sono bianche e quindi riflettono i raggi solari
  (cioè hanno una albedo alta). Un minore assorbimento dei raggi solari da
  parte della Terra riduce la temperatura globale e quindi diminuisce il
  vapore acqueo nell'atmosfera. Grazie a questo fenomeno, in assenza di
  altri ingressi, il quantitativo di vapore acqueo nell'atmosfera tende ad
  essere stabile.
Tuttavia lo stesso processo porta anche ad una retroazione positiva,
  infatti con l'aumento di temperatura aumenta la quantità di vapor d'acqua
  e, poiché questo è un gas serra, contribuisce ad aumentare ulteriormente
  la temperatura terrestre. Per questo motivo il dibattito tra gli
  scienziati è ancora aperto, infatti è difficile stimare l'effetto
  generale del cloud feedback e determinare quale delle diverse retroazioni
  abbia peso maggiore.
la boa galleggiante
- Un altro semplice esempio di retroazione negativa è dato dal
  galleggiamento di una boa. Infatti se la boa tende ad affondare, la forza
  di Archimede aumenta e tende a farla risalire; invece se la boa tende a
  risalire, la forza di Archimede diminuisce e quindi la boa ridiscende.
  L'intero sistema si porta alla stabilità, cioè la boa galleggia ad una
  ben determinata altezza. Se un disturbo influenza il sistema costituito
  dalla boa (per esempio le onde), il sistema reagisce oscillando, ma
  mantiene comunque la stabilità.

Ritardi nell'anello di retroazione

Il tempo che trascorre tra il momento in cui si ha l'effetto e il momento
in cui tale effetto viene preso in considerazione per modificare il sistema
viene definito "ritardo nell'anello di retroazione". Quando questo ritardo
è elevato, si possono avere problemi di stabilità anche nei sistemi con
retroazione negativa che spesso danno vita a fenomeni oscillatori.

Si consideri come esempio il sistema costituito da una persona che si fa la
doccia, il miscelatore e il tubo che porta l'acqua dal miscelatore al
soffione della doccia. Se la persona che si fa la doccia sente freddo gira
il miscelatore verso l'acqua calda, ma a causa della lunghezza del tubo
l'effetto dell'azione non viene percepito immediatamente dalla persona che,
sentendo ancora freddo, girerà ulteriormente il miscelatore verso il caldo.
A questo punto, però, l'acqua potrebbe divenire troppo calda, perciò la
persona girerà il miscelatore verso il freddo fino a che l'acqua non sarà
sufficientemente fredda ma, a causa del ritardo, anche in questo caso
l'azione sarà eccessiva, portando ad avere l'acqua troppo fredda. In questo
caso siamo in presenza di un sistema stabile (in quanto la temperatura
dell'acqua si mantiene sempre entro un certo intervallo di temperatura), ma
l'andamento non è convergente verso l'obiettivo, bensì oscillatorio.
L'oscillazione non si verificherebbe se la persona regolasse il miscelatore
più lentamente del tempo che impiega l'acqua a percorrere il tubo: se prima
di ogni spostamento infinitesimale del miscelatore attendesse l'affetto
dello spostamento precedente, non rischierebbe di ricevere acqua caldissima
o freddissima.

Stabilità nel transitorio

Altrettanto importante è lo studio della stabilità di un sistema di
controllo retroazionato durante il periodo transitorio: è infatti possibile
che il sistema sia stabile a regime, ma non lo sia nell'intervallo di tempo
tra l'innesco del controllo da parte del controllore e la situazione
(output) a regime (transitorio), ovvero presenti anche qui andamenti
oscillanti prima di stabilizzarsi, cosa che è del tutto indesiderata in
taluni sistemi di controllo come i sistemi di asservimento (ad esempio il
servosterzo) in cui l'uscita deve seguire fedelmente l'ingresso anche nel
transitorio. A tal fine, risulta utile la progettazione di reti
compensatrici o correttrici dell'errore, tramite nozioni e strumenti propri
della teoria del controllo (quali ad esempio diagrammi di Bode, diagrammi
di Nyquist, margine di fase e di guadagno).

Retroazione e clima

Il sistema climatico presenta numerosi esempi di fenomeni retroattivi:
quando una tendenza al riscaldamento provoca effetti che inducono ulteriore
riscaldamento si parla di "retroazione positiva", quando invece gli effetti
producono raffreddamento si parla di "retroazione negativa". La principale
retroazione positiva nel sistema climatico comprende il vapore acqueo,
mentre la principale retroazione negativa è costituita dall'effetto della
temperatura sull'emissione di radiazione infrarossa: all'aumentare della
temperatura di un corpo, la radiazione emessa aumenta in proporzione alla
quarta potenza della sua temperatura assoluta (legge di Stefan-Boltzmann).
Questo effetto fornisce una potente retroazione negativa che tende a
stabilizzare il sistema climatico nel tempo.

Uno degli effetti a retroazione positiva è invece in relazione con
l'evaporazione dell'acqua. Se l'atmosfera è riscaldata, la pressione di
saturazione del vapore aumenta e con essa aumenta la quantità di vapore
acqueo nell'atmosfera. Poiché esso è il principale gas serra, il suo
aumento rende l'atmosfera ancora più calda, e di conseguenza una maggiore
produzione di vapore acqueo. Questo processo "a valanga" continua finché un
altro fattore interviene per interrompere la retroazione. Il risultato è un
effetto serra molto più grande di quello dovuto alla sola CO₂, anche se
l'umidità relativa dell'aria rimane quasi costante² .

D'altra parte anche la fusione dei ghiacci sotto forma di calore latente di
fusione sottratto all'atmosfera e la capacità degli oceani di fungere da
serbatoi di calore sono da considerarsi anch'essi feedback negativi
rilevanti del sistema climatico.

Gli effetti di retroazione dovuti alle nuvole sono attualmente campo di
ricerca. Viste dal basso, le nuvole emettono radiazione infrarossa verso la
superficie, esercitando un effetto di riscaldamento; vista dall'alto, le
nuvole riflettono la luce solare ed emettono radiazione verso lo spazio,
con effetto opposto. La combinazione di questi effetti comporta un
raffreddamento o un riscaldamento netto a seconda del tipo e dell'altezza
delle nuvole. Queste caratteristiche sono difficili da includere nei
modelli climatici, in parte a causa della piccola estensione delle stesse
nei modelli simulativi² e costituiscono le parametrizzazioni del modello.
Un esempio in questo campo è l'ipotesi Iris, formulata nel 2001 dallo
scienziato Richard Lindzen.³

Un effetto più sottile è costituito dai cambiamenti nel gradiente
adiabatico mentre l'atmosfera si scalda. La temperatura atmosferica
diminuisce col l'aumentare dell'altezza nella troposfera. Poiché
l'emissione di radiazione infrarossa è legata alla quarta potenza del
valore della temperatura, la radiazione emessa dall'atmosfera superiore è
minore rispetto a quella emessa dall'atmosfera inferiore. La maggior parte
della radiazione emessa dall'atmosfera superiore viene irradiata verso lo
spazio mentre quella dell'atmosfera inferiore viene riassorbita dalla
superficie o dall'atmosfera. Quindi, l'intensità dell'effetto serra dipende
da quanto la temperatura decresce con l'altezza: se essa è superiore,
l'effetto serra sarà più intenso, mentre se è inferiore l'effetto sarà più
debole. Queste misurazioni sono molto sensibili agli errori, rendendo
difficile stabilire se i modelli climatici siano o meno aderenti alle
osservazioni sperimentali⁴ .

Un altro importante processo a retroazione è costituito dall'albedo del
ghiaccio⁵ : quando la temperatura globale aumenta, i ghiacci polari fondono
ad un tasso superiore. Sia la superficie emersa che le acque riflettono
meno la luce solare rispetto al ghiaccio, quindi l'assorbono maggiormente.
Per questo motivo aumenta il riscaldamento globale, che incrementa la
fusione dei ghiacci e continua il processo.

Anche l'aumento/diminuzione della copertura vegetale e più in generale la
modificazione dei suoli influirebbero sull'albedo planetario quindi come
feedback sul sistema climatico.

Il riscaldamento è anche un fattore scatenante per il rilascio di metano da
varie sorgenti presenti sia sulla terra che sui fondali oceanici. Il
disgelo del permafrost, come nelle torbiere ghiacciate in Siberia creano
una retroazione positiva a causa del rilascio di anidride carbonica (CO₂) e
metano (CH₄)⁶ . Analogamente, l'aumento della temperatura degli oceani, può
rilasciare metano dai depositi di idrati di metano e clatrati di metano
presenti nelle profondità in base all'ipotesi dei clatrati. Questi fenomeni
sono attualmente oggetto di intense ricerche.

Con il riscaldamento degli oceani si prevede inoltre un feedback positivo
sulla concentrazione di CO₂ in atmosfera a causa della diminuzione della
capacità di assorbimento diretto per solubilità ed anche da parte degli
ecosistemi oceanici. Infatti il livello mesopelagico (situato ad una
profondità compresa tra 200 m e 1000 m) subisce una riduzione delle
quantità di nutrienti che limitano la crescita delle diatomee in favore
dello sviluppo del fitoplancton. Quest'ultimo è una pompa biologica del
carbonio meno potente rispetto alle diatomee⁷ .

Infine un altro feedback climatico molto discusso è quello delle correnti
oceaniche: lo scioglimento dei ghiacci polari dovuto al riscaldamento
globale porterebbe ad una alterazione della circolazione termoalina e a una
conseguente alterazione del cosiddetto Nastro Trasportatore Oceanico, in
particolare del ramo superficiale nord-atlantico ovvero la Corrente del
Golfo, con effetto di raffreddamento sull'emisfero settentrionale, in
particolare sul continente europeo, contrastando, annullando o addirittura
invertendo il trend al riscaldamento degli ultimi decenni.

Note

[1] Non sempre una retroazione negativa porta a stabilità. Ad esempio,
  considerando un sistema SISO lineare stazionario con poli -10 -20 e -30,
  con retroazione dell'uscita sull'ingresso con una costante di
  amplificazione K minore di zero e dal metodo del luogo delle radici si
  vede che a valori di K elevati in modulo corrispondono due poli complessi
  a parte reale positiva, per cui il sistema retroazionato sarà in questo
  caso instabile.
[2] Brian J. Soden, Held, Isacc M., An Assessment of Climate Feedbacks in
  Coupled Ocean-Atmosphere Models (PDF), in Journal of Climate, vol. 19, nº
  14, 1º novembre 2005. URL consultato il 21 aprile 2007.
[3] (EN) R.S. Lindzen, M.-D. Chou, A.Y. Hou, Does the Earth have an
  adaptive infrared iris? (PDF), in Bull. Amer. Met. Soc., vol. 82, nº 3,
  2001, pp. 417–432, DOI:10.1175/1520-0477(2001)082<0417:DTEHAA>2.3.CO;2.
[4] Panel on Climate Change Feedbacks, Climate Research Committee, National
  Research Council, Understanding Climate Change Feedbacks, The National
  Academies Press, 2003, p. 166, ISBN 978-0-309-09072-8.
[5] Thomas F. Stocker et al., 7.5.2 Sea Ice, su Climate Change 2001: The
  Scientific Basis. Contribution of Working Group I to the Third Assessment
  Report of the Intergovernmental Panel on Climate Change,
  Intergovernmental Panel on Climate Change, 20 gennaio 2001. URL
  consultato l'11 febbraio 2007.
[6] Ian Sample, Warming Hits 'Tipping Point', The Guardian, 11 agosto 2005.
  URL consultato il 18 gennaio 2007.
[7] Ken O. Buesseler et al., Revisiting Carbon Flux Through the Ocean's
  Twilight Zone, in Science, vol. 316, nº 5824, 27 aprile 2007, pp.
  567-570, DOI:10.1126/science.1137959, PMID 17463282. URL consultato il 16
  novembre 2007.

Bibliografia

- Katsuhiko Ogata. Modern Control Engineering. Prentice Hall, 2002.
- Paolo Bolzern, Riccardo Scattolini, Nicola Schiavoni. Fondamenti di
  controlli automatici. McGraw-Hill Companies, giugno 2008. ISBN
  978-88-386-6434-2.

Voci correlate

- Criterio di Nyquist
- Luogo delle radici
- Diagramma di Nyquist
- Controllo in feedback linearization
- Visual servoing
- Teorema di scomposizione

Altri progetti

- Wikizionario contiene il lemma di dizionario «retroazione»
- Wikimedia Commons contiene immagini o altri file su retroazione

Luogo delle radici

In analisi complessa il luogo delle radici è il luogo geometrico delle
radici di una funzione complessa descritto al variare di un suo parametro
reale, rappresentato sul piano di Gauss.

Nel 1948 Evans lo impiegò per la prima volta per determinare la stabilità
interna di un sistema dinamico lineare stazionario in retroazione al
variare del guadagno d'anello per la funzione di trasferimento d'anello
L(s): in questo caso applicativo risulta costituito da rami, ciascuno la
traiettoria che compie una radice dipendente dalle posizioni degli zeri e
dei poli della funzione d'anello. Ciò è particolarmente utile in quanto le
variabili di stato non controllabili (dovute a rumore a bassa frequenza,
derive termiche, incertezza sui parametri e così via), di norma, agiscono
prevalentemente su questo, e non sulla posizione delle singolarità, che
tipicamente sono note. Il suo uso principale è dedicato a questa funzione,
anche al fine della sintesi per stabilire le modifiche necessarie ad un
controllore per il raggiungimento di alcune caratteristiche minime come la
velocità di risposta. La prima osservazione da fare riguarda la posizione
"iniziale" (con k → 0) delle radici. Se ritagliamo dal dominio intorni
arbitrariamente piccoli dei poli ad anello aperto, che chiameremo sorgenti,
per k prossimo a zero, avremo

L(s) ≈k ·G(s)=k ·\frac{N(s)}{D(s)} per k →0

dunque, le radici si trovano inizialmente a ridosso delle p sorgenti (per
convenzione, la radice di un polinomio va conteggiata un numero di volte
pari alla sua molteplicità). N(s) e D(s) definiscono rispettivamente il
numeratore e il denominatore di G(s). Va osservato che il numero di radici,
a meno di cancellazioni tra kN(s) e Pₖ(s)=D(s)+kN(s), è esattamente pari al
grado di Pₖ(s); in un sistema strettamente proprio (questa ipotesi verrà
mantenuta nel resto dell'articolo), tale quantità pareggia l'ordine di
D(s), che è proprio p, per qualunque k. Del resto, una cancellazione
comporta l'esistenza di una pulsazione complessa s₀ tale per cui valga

k ·N(s_0)=D(s_0)+k ·N(s₀₎₌₀

evidentemente, non esistono radici del genere per k non nullo. In
definitiva, possiamo concludere che in un sistema strettamente proprio, il
numero di radici si conserva: esso coincide sempre con il numero di
sorgenti, p. Si osservi che per k diverso da zero, i poli ad anello aperto
non sono sicuramente radici di Pₖ(s); dunque una radice non stazionerà mai
su una sorgente ma, al variare di k, si sposterà descrivendo, come già
evidenziato, una curva continua.

In ogni punto del luogo infine, il valore assoluto di k coincide con il
rapporto tra la produttoria dei valori assoluti dei poli e la produttoria
dei valori assoluti degli zeri:

|k|= \frac{ \prod _{i=1}^d |p_i|}{\prod _{i=1}ⁿ |z_i|}

Proprietà

La posizione delle radici di L(s) all'istante k è individuata dagli zeri
del polinomio Pₖ(s), ossia dalla condizione G(s)=-k⁻¹. Quest'ultima si
traduce in una condizione sul modulo, del tutto priva di interesse dato che
qualunque pulsazione complessa s verifica il vincolo per qualche k (in
altri termini, data una certa s, dalla condizione sul modulo non è
possibile affermare se il luogo delle radici la attraversa o meno), e in
una condizione sulla fase, dalla quale è possibile estrarre tutte le
informazioni necessarie. Se si assume per semplicità che i polinomi N(s) e
D(s) siano in forma canonica, essa diventa

Σ_{k=1}^z \arg (s-z_k) - Σ_{k=1}^p \arg (s-p_k)= π·Θ(k)

dove Θ(k) è il gradino di Heaviside e zₖ, pₖ rappresentano gli zeri e i
poli ad anello aperto, che chiameremo singolarità isolate; si osservi che
(s-s₀) rappresenta il vettore fissato in s₀ e che punta a s. Il diagramma
per valori di k positivi è detto luogo diretto, per k negativi luogo
inverso. Il fatto di trovarsi in uno dei due luoghi cambia radicalmente
l'aspetto del diagramma. Valgono le seguenti considerazioni

- il luogo diretto e il luogo inverso non hanno punti in comune
- i punti dell'asse reale che hanno a destra un numero dispari (pari, o
  nullo) di singolarità isolate reali appartengono al luogo diretto
  (inverso)

la prima è ovvia, la seconda si ottiene facilmente utilizzando la
condizione sulla fase.

Inizialmente (ovvero con k → 0), i poli ad anello chiuso coincidono a tutti
gli effetti con quelli ad anello aperto, perché la funzione di
trasferimento del sistema reazionato uguaglia kG(s). Dunque, da una
sorgente "sgorgheranno" o "convergeranno" traiettorie, ognuna associata ad
una radice, in numero pari alla molteplicità h di quella singolarità;
precisamente, in essa si congiungono h rami del luogo diretto e h rami del
luogo inverso. Possiamo pensare ad un polo ad anello aperto come ad un
centro di scattering se si interpreta k come un tempo. Un'ulteriore
proprietà del luogo delle radici è la simmetria rispetto all'asse reale:
infatti, essendo il polinomio Pₖ(s) a coefficienti reali, ad ogni suo zero
corrisponde uno zero coniugato. Come conseguenza di questo fatto, si può
affermare che una radice situata, in corrispondenza di un determinato k,
sull'asse reale, continuerà a mantenersi reale fino a che non "urta" o
contro un'altra radice proveniente dalla direzione opposta, o contro più
radici.

Luoghi multipli

Un luogo multiplo non è altro che una radice multipla di Pₖ(s), per qualche
k. Assumiamo, tanto per fissare le idee, di trovarsi nel luogo diretto (ma
considerazioni analoghe valgono in quello inverso), e che la radice abbia
molteplicità h. Essa sarà allora punto di incontro, o di scattering, di h
radici: h traiettorie entreranno nel luogo, altrettante ne usciranno (a
meno che quel punto non sia un punto terminale di qualche traiettoria,
ossia uno zero ad anello aperto; si veda più avanti). In un suo intorno,
questi rami formano una stella: facendo uso della condizione di fase, si
deduce facilmente che essa divide il piano in 2h porzioni equiangole, e che
i suoi bracci sono alternativamente entranti e uscenti. L'analogia con il
fenomeno fisico dell'urto è evidente.

Anche i poli ad anello aperto (di molteplicità almeno pari a due) possono
essere considerati luoghi multipli: semplicemente, descriveranno eventi di
scattering che occorrono per k prossimo a zero. Le considerazioni sono
identiche a quelle svolte sopra.

Invarianza del baricentro

Il baricentro B(k) del luogo è la media delle posizioni dei punti a k
assegnato, divisa per il loro numero, e per la simmetria del luogo
appartiene all'asse reale: È una quantità analoga al centro di massa di un
sistema di corpi puntiformi identici. Se il grado relativo del denominatore
m\ge 2, il baricentro è un punto B indipendente da k, che può essere
calcolato come:

B : (\frac 1 d Σ_{i=1}^d p_i , 0)

proprio come avviene in un sistema meccanico isolato (non soggetto a
forze). Per dimostrare questo fatto, è sufficiente osservare che B(k) è
univocamente determinato dai due termini di grado massimo di Pₖ(s), dato
che la somma delle sue radici è uguale al rapporto, cambiato di segno, di
questi.

Punti terminali

Per k prossimo all'infinito positivo o negativo, i p poli ad anello chiuso
vanno ad annullare G(s), cioè tendono o verso gli z zeri ad anello aperto,
o verso gli zeri all'infinito, anche detti asintoti, di G(s). Essi non sono
altro che le direzioni lungo le quali questa funzione tende ad annullarsi,
e sono determinati solamente dai termini di grado massimo di N(s) e D(s),
dato che i rimanenti sono irrilevanti all'infinito. Da ciò si deducono due
situazioni possibili

- uno zero all'infinito, coincidente con l'asse reale
- due o più zeri all'infinito, che suddividono il piano in due o più parti
  equiangole. L'invarianza del baricentro impone che, per k tendente
  all'infinito (positivo o negativo), le radici si spostino lungo rette
  aventi quelle direzioni e convergenti in X

i poli ad anello chiuso tenderanno verso gli zeri, finiti o infiniti, sia
nel luogo diretto che in quello inverso. Anche questi possono essere
interpretati come centri di scattering: si tratta di urti che occorrono
all'infinito. Ad esempio, se in uno zero finito convergono, nel luogo
diretto, h rami (h è la molteplicità dello zero), altrettanti ne
"usciranno" nel luogo inverso se immaginiamo idealmente una transizione
istantanea dall'infinito positivo a quello negativo; al solito, i 2h rami
formeranno una stella regolare costituita da bracci alternativamente
entranti e uscenti. Un discorso analogo vale per gli zeri all'infinito: in
corrispondenza della transizione dal luogo diretto a quello inverso, la
radice semplicemente si "rimaterializzerà" al capo opposto della direzione
corrispondente (come se avesse percorso istantaneamente una
semicirconferenza di raggio infinito), per poi proseguire asintoticamente
lungo di esso.

Procedura di tracciamento

Siano n, d, m rispettivamente il grado di N e D, e la loro
differenza:m=d-nVengono di seguito presentate le regole per il tracciamento
dei luoghi, in ordine di applicazione pratica.

Partenza

I rami partono dai poli cioè tendono ai poli per k →0.

Asse reale

- Fa parte del luogo totale tutto l'asse reale ad esclusione dei poli.
- Fanno parte del luogo diretto tutti i punti a sinistra di un numero
  dispari di molteplicità (di radici: zeri o poli che siano).

Quindi partendo da destra l'intervallo dalla radice massima all'infinito
non appartiene al luogo diretto, ma appartiene a quello inverso, e ogni
intervallo precedente (a sinistra) ha rispetto al successivo appartenenza
invertita solo se la radice che li separa ha molteplicità dispari.

Rami convergenti

In ciascuno zero arriva un numero di rami corrispondente alla propria
molteplicità per k →\infty .

Intersezioni reali

I punti di intersezione con l'asse reale (detti di diramazione) si
ottengono sempre dal sistema:

\left {\begin{matrix} N[1+L(s)]=0 \frac{\partial }{\partial s} N[1+L(s)]=0
\end{matrix} \right .

Si trovano così le coppie di s* e k* che corrispondono sul luogo ai punti
(s*,0), con k=k*.

Simmetria reale

Ciascun luogo è simmetrico rispetto all'asse reale.

Tangenti iniziali

In una radice (se reale ovviamente con molteplicità h_i > 1, altrimenti
questo passaggio è già stato realizzato considerando l'asse reale) i rami
hanno tangenti che dividono l'angolo giro in parti uguali, partendo nel
luogo diretto da: \frac 1 h_i \left (π+ Σ_{j=1}^n ϕ(z_j) - Σ_{j=1}^d
ϕ(p_j)\right ) (polo)

\frac 1 h_i \left (π- Σ_{j=1}^n ϕ(z_j) + Σ_{j=1}^d ϕ(p_j)\right ) (zero)

Nel luogo inverso da:

\frac 1 h_i \left (Σ_{j=1}^n ϕ(z_j) - Σ_{j=1}^d ϕ(p_j)\right ) (polo)

\frac 1 h_i \left (- Σ_{j=1}^n ϕ(z_j) + Σ_{j=1}^d ϕ(p_j)\right ) (zero)

Asintoti

Ciascun rimanente ramo diverge con un asintoto che passa per un punto A che
appartiene all'asse reale ed è comune a tutti gli asintoti:

A : \left (\frac 1 m \left{ - Σ_{i=1}^n z_i + Σ_{i=1}^d p_i \right } , 0
\right )

Gli asintoti dividono l'angolo giro in m angoli uguali, nel luogo diretto
partendo da \frac πm, e in quello inverso da 0

Intersezioni immaginarie

Sono le radici dell'equazione caratteristica:N[1+L(k)] = 0che si trovano
annullando la penultima riga della matrice di Routh e inserendo il valore
di k ottenuto nell'equazione ausiliaria, ovvero quella contenente solo i
monomi di grado pari in s, per trovare i valori di s corrispondenti.

Verifica complessiva

In ciascun luogo sono presenti d rami, di cui n arrivano negli zeri e m
agli asintoti. Non sono possibili intersezioni tra rami dello stesso luogo
che non siano sull'asse reale, e gli zeri sono le sole intersezioni fra i
rami del luogo diretto e quelli del luogo inverso.

Luoghi locali

In molti casi è utile essere in grado di tracciare dei luoghi locali,
ignorando cioè il contributo delle singolarità ad anello aperto situate a
grande distanza dalla regione di interesse. Se questa si trova in un
intorno di zero, le uniche singolarità lontane che interferiscono in
qualche maniera sono quelle puramente reali situate a destra, ossia le
radici positive: esse danno ciascuna un contributo fisso pari a π. Dunque,
il loro effetto è rilevante solo quando sono in quantità dispari, ed è
quello di invertire il luogo diretto con quello inverso (ma senza
conservare la punteggiatura: quello cioè che succederebbe normalmente in
corrispondenza di un certo k non occorre in generale, come conseguenza di
questo fatto, in -k). A parte questo, le singolarità lontane possono essere
ignorate.

Note

Bibliografia

- Katsuhiko Ogata. Modern Control Engineering. Prentice Hall, 2002.
- Paolo Bolzern, Riccardo Scattolini, Nicola Schiavoni. Fondamenti di
  controlli automatici. McGraw-Hill Companies, Giugno 2008. ISBN
  9788838664342.

Voci correlate

- Equazione algebrica
- Zero (analisi complessa)
- Polo (analisi complessa)
- Retroazione
- Diagramma di Bode
- Diagramma di Nyquist

Altri progetti

- Wikimedia Commons contiene immagini o altri file su Luogo delle radici

Funzione di variabile complessa

In matematica, si definisce funzione di variabile complessa una funzione
definita su un sottoinsieme dei numeri complessi a valori in quello stesso
insieme. In genere la variabile complessa si denota con z, la sua parte
reale con x e la sua parte immaginaria con y, in modo che si possa scrivere
z = x + iy. Una funzione di variabile complessa f(z) corrisponde ad una
legge che associa in modo univoco a un punto z di un sottoinsieme del piano
complesso, il dominio della funzione, un punto che può considerarsi
appartenere ad un secondo piano e più circoscrittamente costituisce il
codominio della funzione.

È interessante notare come nel campo complesso le funzioni trigonometriche
sono esprimibili in termini della funzione esponenziale e della
logaritmica.

In campo fisico, una funzione di variabile complessa può essere considerata
la funzione d'onda Ψ(x,t), utile in meccanica quantistica e presente, tra
l'altro, nell'equazione di Schrödinger. Sempre in meccanica quantistica,
non è tanto rilevante la funzione complessa Ψ(x,t), (poiché, producendo
numeri immaginari, non può rappresentare grandezze fisiche), ma è rilevante
il suo valore assoluto, elevato al quadrato |Ψ(x,t)|²

Le più utili e interessanti tra le funzioni di variabile complessa sono le
funzioni olomorfe, cioè, secondo la definizione di Cauchy, le funzioni
dotate di una funzione derivata prima e con derivata prima continua. Le
condizioni che garantiscono la derivabilità di una funzione di variabile
complessa sono dette condizioni di Cauchy-Riemann o condizioni di
monogeneità, ovviamente per l'esistenza delle derivate parziali è richiesta
la differenziabilità. Da una funzione olomorfa si ottiene, mediante
operazioni di prolungamento analitico una funzione analitica, entità che è
da considerare una funzione multivoca; le condizioni di monogeneità, di
conseguenza, sono chiamate anche condizioni di analiticità.

Fra le risorse gratuite presenti in Internet, esistono dei disegnatori di
funzioni complesse, e programmi gratuiti che funzionano off-line.

Per lo studio di funzioni complesse, il disegno di grafici tridimensionali
può essere un valido strumento per interpretare visivamente le funzioni
meno comuni.

Esempi

Segue un elenco delle principali funzioni di variabile complessa, che in
effetti, ad esclusione delle prime 5, sono funzioni olomorfe.

- parte reale: \Re z = x
- parte immaginaria: \Im z = y
- complesso coniugato: \bar{z} = x - iy
- argomento: \mbox{arg} z = \mbox{atan} \frac{y}{x}
- modulo: |z| = √(x²⁺y²) = √(z·\bar{z} )
- esponenziale: e^{iy} = \cos y+i \sin y \frac{}{}
- logaritmo principale: \ln z = \ln |z| +i \arg z +i2kπ ~~∀k\in \mathbb{Z}
- radice: √(n) = √(n)·\left (\cos \frac{z}{n} + i \sin \frac{z}{n} \right )
  \frac{}{}
- seno: \sin z = \frac{1}{2i} (e^{iz}-e^{-iz})
- coseno: \cos z = \frac{1}{2} (e^{iz}+e^{-iz})
- tangente: \tan z = \frac{\sin z}{\cos z}
- cotangente: \cot z = \frac{\cos z}{\sin z}
- secante: \sec z = \frac{1}{\cos z}
- cosecante: \csc z = \frac{1}{\sin z}
- arcoseno: \mbox{arcsin} z = i·\ln \left (-iz\pm √(1-z²)\right )+2kπ k\in
  \mathbb{Z}
- arcocoseno: \mbox{arccos} z = \mp i·\ln \left (z+√(z²-1)\right )+2kπ k\in
  \mathbb{Z}
- arcotangente: \mbox{arctan} z = \frac{i}{2} \ln \frac{i+z}{i-z}
- seno iperbolico: \sinh z = \frac{1}{2} (e^{z}-e^{-z})
- coseno iperbolico: \cosh z = \frac{1}{2} (e^{z}+e^{-z})
- tangente iperbolica: \tanh z = \frac{\sinh z}{\cosh z}
- cotangente iperbolica: \coth z = \frac{\cosh z}{\sinh z}
- secante iperbolica: \mbox{sech} z = \frac{1}{\cosh z}
- cosecante iperbolica: \mbox{csch} z = \frac{1}{\sinh z}
- settore seno iperbolico: \mbox{settsinh} z = \ln \left (z+√(z²⁺¹)\right )
- settore coseno iperbolico: \mbox{settcosh} z = \ln \left (z+√(z²-1)\right
  )
- settore tangente iperbolica: \mbox{setttanh} z = \frac{1}{2} \ln
  \frac{1+z}{1-z}

Voci correlate

- Logaritmo
- Esponenziale
- Trigonometria
- Funzione di variabile reale
- Numero complesso
- Derivazione complessa

Zero (analisi complessa)

In analisi complessa, uno zero di una funzione olomorfa f è un numero
complesso a tale che f(a) = 0.

Molteplicità di uno zero

Un numero complesso a è uno zero semplice di f, o uno zero di molteplicità
1 di f, se f può essere scritta nella forma

f(z)=(z-a)g(z)

dove g è una funzione olomorfa g tale che g(a) non è zero.

In generale, la molteplicità di uno zero di f in a è quel numero positivo n
(che, per le funzione olomorfe, risulta essere necessariamente un intero)
per il quale c'è una funzione olomorfa g tale che

f(z)=(z-a)^ng(z) \mbox{e} g(a)\neq 0.

Esistenza degli zeri

Il teorema fondamentale dell'algebra afferma che ogni polinomio non
costante a coefficienti complessi ha almeno uno zero nel piano complesso.
Questo non vale, in generale, nel caso in cui ci si limiti al campo dei
numero reali (ricerca di radici reali di polinomi a coefficienti reali): è
banalmente noto, in matematica, come esistano funzioni polinomiali a
coefficienti reali che non ammettono zeri reali (ma ammettono comunque zeri
complessi essendo i numeri reali dei particolari numeri complessi). Un
esempio è f(x) = x² + 1.

Proprietà

Una proprietà importante degli zeri di una funzione olomorfa (non
identicamente nulla) è che tali zeri sono isolati. In altre parole, per
ogni zero di una funzione olomorfa, esiste un intorno di tale zero che non
contiene altri zeri.

Voci correlate

- Radice (matematica)
- Polo (analisi complessa)
- Teorema di Hurwitz (analisi complessa)

Collegamenti esterni

- (EN) Calcolo delle radici complesse di un polinomio a coefficienti reali
  (free online solver)

Analisi complessa

L'analisi complessa (più precisamente, la teoria delle funzioni di
variabili complesse) è quella branca dell'analisi matematica che applica le
nozioni di calcolo infinitesimale alle funzioni complesse, cioè alle
funzioni definite che hanno per dominio e codominio insiemi di numeri
complessi.

Protagonista dell'analisi complessa è la funzione olomorfa: una funzione
complessa per cui è definita una nozione di derivata, in modo identico a
quanto fatto per le usuali funzioni reali. Un'estensione di questo concetto
è la funzione meromorfa.

L'analisi complessa è estremamente utile in numerose branche della
matematica, come ad esempio la teoria dei numeri e la geometria algebrica;
ha notevoli applicazioni anche in fisica e in ingegneria.

Funzioni olomorfe

Definizione

L'analisi complessa applica le tecniche del calcolo infinitesimale ai
numeri complessi. Per fare questo, è necessario modellizzare i numeri
complessi nel piano complesso, dotato della usuale topologia euclidea del
piano reale. La topologia permette quindi di parlare di successioni, di
limiti, di insiemi aperti e chiusi del piano complesso.

L'analisi complessa studia generalmente funzioni di variabile complessa

f:A→\mathbb C

definite su un aperto A del piano complesso \mathbb C , a valori complessi.
In modo del tutto analogo a quanto fatto nel caso reale, una tale funzione
è derivabile in senso complesso in un punto se il rapporto incrementale ha
limite in quel punto. Se la funzione è derivabile in senso complesso in
ogni punto di A , essa viene definita funzione olomorfa.

Relazione con la differenziabilità

Usando l'identificazione di \mathbb C con \R ² , la funzione f può essere
interpretata come funzione da un aperto di \R ² in \R ² . Una funzione
derivabile in senso complesso è necessariamente differenziabile se
interpretata in questo modo.

Non è vero però l'opposto: la derivabilità in senso complesso è una
condizione molto più restrittiva, che implica notevoli conseguenze sul
comportamento della funzione.

La condizione di derivabilità in senso complesso per una funzione f
differenziabile è sintetizzata nelle equazioni di Cauchy-Riemann, che danno
un esempio di quanto la condizione di derivabilità complessa sia più
restrittiva:

\left {\begin{array}{l} \displaystyle { \partial u \over \partial x } = {
\partial v \over \partial y } \displaystyle { \partial u \over \partial y }
= -{ \partial v \over \partial x } \end{array} \right .

dove u e v sono due funzioni di variabile reale e a valori reali, definite
su A , considerato come sottoinsieme di \R ² , tali che f = u+iv

Mappe conformi

Un altro esempio delle particolarità di cui gode una funzione derivabile in
senso complesso è data dal carattere "conforme" delle funzioni olomorfe con
derivata diversa da zero. Infatti, una funzione olomorfa avente derivata
ovunque diversa da zero è una mappa conforme: una simile funzione preserva
gli angoli, ma non necessariamente le distanze. Questa proprietà è dovuta
al fatto che una funzione olomorfa, esattamente come una funzione
differenziabile nel caso reale, è localmente approssimabile da una funzione
lineare. Ma una funzione lineare, nel caso complesso, consiste nella
composizione di una moltiplicazione complessa e di una traslazione
(quest'ultima rappresentata da una somma): la seconda è un'isometria mentre
la prima è sempre una roto-omotetia, ossia la composizione di una rotazione
nel piano complesso (un'altra isometria) e di una omotetia. Quindi, tutte e
tre le trasformazioni che entrano in gioco nell'approssimazione lineare
sono omotetie o isometrie che, componendosi tra di loro, conservano, in
particolare, gli angoli (è essenziale, in questo caso, l'ipotesi fatta che
la derivata complessa sia diversa da zero: in caso contrario il termine
moltiplicativo della funzione lineare, responsabile della roto-omotetia,
sarebbe nullo e non in grado di conservare gli angoli).

Allo stesso modo si può constatare un'altra conseguenza: una funzione
olomorfa conserva localmente i rapporti tra le distanze; in altre parole,
su piccola scala essa è approssimativamente una similitudine. Infatti, la
funzione lineare con cui è localmente approssimabile, come abbiamo visto, è
la composizione di isometrie e omotetie, tutte funzioni che conservano i
rapporti tra le distanze (si ritrova qualcosa di già come noto dalla
geometria elementare, lo stretto legame tra la conservazione degli angoli e
la conservazione dei rapporti tra le distanze).

Esistono peraltro trasformazioni conformi che non sono olomorfe: si veda
l'esempio delle cosiddette funzioni antiolomorfe un esempio delle quali,
illustrata più oltre, è la coniugazione complessa. In generale, se f(z) è
una funzione olomorfa e conforme, la funzione f(\bar{z} ) (dove \bar{z} è
il complesso coniugato di z ) è ancora conforme perché ottenuta da f
mediante composizione con un'isometria, ma non è in generale olomorfa (non
sono soddisfatte, ad esempio, le condizioni di Cauchy-Riemann).

Funzioni armoniche

D'altra parte, la parte reale e la parte immaginaria di una funzione
olomorfa sono entrambe funzioni armoniche: alcune proprietà delle funzioni
armoniche sono ereditate dalle funzioni olomorfe e, tra queste, quella di
non ammettere massimi e minimi locali.

Formula di Cauchy

L'ingrediente fondamentale dell'analisi complessa, che non ha analogie
nell'analisi reale, è la formula di Cauchy. Questa formula mette in
relazione il valore f(z) di una funzione olomorfa in un punto con
l'integrale di una funzione costruita a partire da f lungo una curva
semplice chiusa γ che "circonda" il punto z , nel modo seguente:

f(z) = \frac {1} {2πi} ·\oint _{γ} \frac {f(w)}{w - z} dw .

Dalla formula di Cauchy seguono molte proprietà delle funzioni olomorfe,
che non hanno analogie nell'ambito dell'analisi reale. Alcune di queste
proprietà sono descritte brevemente qui sotto.

Analiticità

Una funzione olomorfa è sempre analitica, ovvero è localmente esprimibile
come serie di potenze. In altre parole, in ambito complesso l'esistenza
della derivata prima è sufficiente a garantire non solo l'esistenza di
derivate di ogni ordine, ma anche l'analiticità della funzione. Nessuna
delle due conseguenze, in ambito reale, discende dalla sola
differenziabilità.

Teorema di Liouville

Una funzione olomorfa è intera se è definita su tutto il piano complesso.

Le funzioni intere sono quelle funzioni che in ogni punto hanno una
rappresentazione come serie di potenze con raggio di convergenza infinito.
Le funzioni intere sono soggette a molte restrizioni. Tra queste, il
teorema di Liouville asserisce che una funzione intera non costante non può
avere modulo limitato sul piano.

Non esistono quindi in ambito complesso funzioni come l'arcotangente reale,
che siano definite su tutto \mathbb C ma con modulo uniformemente limitato.

Teorema del massimo modulo

Per il teorema del massimo modulo, il modulo |f(z)| di una funzione
olomorfa f definita su un aperto A non può assumere massimo. Se il dominio
A è limitato e la funzione f è estendibile con continuità alla chiusura di
A , il modulo ammette massimo su uno dei punti del bordo.

Esempi di funzioni olomorfe

Rapporto fra polinomi

Ogni funzione definita a partire dalle quattro operazioni aritmetiche è
olomorfa nell'aperto in cui è ben definita. Ad esempio, se p(z) e q(z) sono
due polinomi, la funzione

f(z)=\frac {p(z)}{q(z)}

è olomorfa sull'aperto A ottenuto rimuovendo da \mathbb C i punti
corrispondenti alle radici di q .

Funzioni analitiche

Ogni funzione analitica reale si estende in modo unico a una funzione
olomorfa. Il procedimento con cui le funzioni analitiche vengono estese in
modo unico è detto prolungamento analitico. In particolare, le funzioni
esponenziale, seno, e le altre funzioni trigonometriche sono estensibili in
maniera univoca a funzioni olomorfe.

Il comportamento delle funzioni esponenziale e seno in ambito complesso è
più ricco di quello che "esse evidenziano" in ambito reale. Ad esempio, per
il teorema di Liouville, la funzione seno non è limitata nel piano
complesso (in contrasto con quanto accade sui reali, ove è limitata tra -1
e 1). Anzi, la funzione seno è suriettiva sui complessi.

Serie di Laurent

Una serie di Laurent centrata in un fissato punto c del piano complesso è
una serie del tipo

f(z)=Σ_{n=-\infty }^\infty aₙ₍z-c)ⁿ.

La serie è simile ad una serie di Taylor: l'unica differenza sta nella
possibile presenza di termini con esponenti negativi. Come le serie di
Taylor, una serie di Laurent può essere convergente in una delimitata zona
del piano: in questo caso la zona è un disco o, per la presenza di
esponenti negativi, un anello centrato in c. Molte funzioni olomorfe sono
agevolmente descritte tramite una serie di Laurent (ad esempio, quelle
aventi una singolarità isolata in c).

Funzioni non olomorfe

Esempi di funzioni complesse ma non olomorfe sono la coniugazione
complessa, il passaggio alla parte reale (o immaginaria) e la funzione
valore assoluto (anche al quadrato).

Funzioni meromorfe

Singolarità isolate

Un altro concetto centrale dell'analisi complessa è quello di singolarità
isolata. Una funzione olomorfa

f:A\setminus {z_0}→\mathbb C

definita su un aperto A , meno un suo punto interno z₀ , ha una singolarità
isolata in z₀ . Differentemente da quanto accade per le funzioni reali, il
comportamento della funzione vicino z₀ è catalogabile in tre tipologie,
determinate dal comportamento del modulo |f(z)| vicino al punto:

- Se |f(z)| è limitato in un intorno di z₀ , la singolarità è eliminabile:
  la funzione è estendibile con continuità al punto, e l'estensione è
  ancora olomorfa.
- Se |f(z)| tende a infinito per z tendente a z₀ , la singolarità è un
  polo.
- In tutti gli altri casi, |f(z)| non ha limite per z tendente a z₀ , e la
  singolarità è detta essenziale.

Sfera di Riemann

Se la funzione ha in z₀ una singolarità eliminabile, questa si estende ad
una funzione olomorfa su A . Se ha un polo, è possibile ugualmente
estendere la funzione ponendo f(z)=+\infty . Il risultato di questa
operazione è un nuovo tipo di funzione, detta meromorfa.

Le funzioni meromorfe si comportano localmente come le funzioni olomorfe: è
sufficiente aggiungere al piano complesso il punto +\infty tramite la
proiezione stereografica. Lo spazio che si ottiene è topologicamente
equivalente alla sfera, ed è detto sfera di Riemann. Viene spesso
identificato con la retta proiettiva complessa \mathbb {P}^1(\C ) . Una
funzione meromorfa è quindi una particolare funzione

f:A→\mathbb {P}^1(\C ).

Con questa costruzione, il punto all'infinito è trattato come tutti gli
altri, ed è possibile tradurre molti risultati sulle funzioni olomorfe nel
contesto delle funzioni meromorfe. Analoga estensione può essere quindi
ammessa sul dominio: A è un qualsiasi aperto di \mathbb {P}^1(\C ) ; un
tale aperto è un usuale aperto di \mathbb C oppure tutta la sfera.

Ad esempio, una trasformazione di Möbius

f(z) = \frac{az+b}{cz+d}

dove a,b,c,d sono complessi e

\det \begin{pmatrix} a & b c & d \end{pmatrix} \neq 0

è una funzione meromorfa

f:\mathbb {P}^1(\C )→\mathbb {P}^1(\C ).

Tale funzione è anche una corrispondenza biunivoca.

Biolomorfismi

In matematica, ogni categoria ha i suoi isomorfismi. Nell'ambito
dell'analisi complessa, un isomorfismo fra due aperti A e B di \mathbb C (e
più generalmente, di \mathbb {P}^1(\C ) ) è una funzione

f:A→B

che sia olomorfa, iniettiva, suriettiva, e la cui inversa sia anch'essa
olomorfa. Una tale funzione è detta biolomorfismo.

Una tappa fondamentale dell'analisi complessa, risolta alla fine del XIX
secolo, è stata la classificazione degli aperti semplicemente connessi a
meno di biolomorfismo. Sorprendentemente, in \mathbb {P}^1(\C ) ci sono
solo tre aperti semplicemente connessi a meno di biolomorfismo. Questi
sono:

- Il disco aperto Δ= {z\in \mathbb C | |z|<1},
- Il piano \mathbb C ,
- La sfera di Riemann \mathbb {P}^1(\C ) .

Questo risultato è una parte importante del Teorema di uniformizzazione di
Riemann. In particolare, qualsiasi aperto semplicemente connesso di \mathbb
C che non sia tutto il piano è biolomorfo al disco aperto: non soltanto le
parti interne di poligoni come il quadrato, ma anche aperti più complicati
come il fiocco di neve di Koch sono biolomorfi al disco aperto.

Bibliografia

- F. Casorati, Teorica delle funzioni di variabili complesse (Fratelli
  Fusi, Pavia, 1868)
- Stephen D. Fisher, Complex Variables, 2 ed. (Dover, 1999)
- H. Durège, Elements of the theory of functions of a complex variable with
  especial reference to the methods of Riemann (G.E. Fisher and I.J.
  Schwatt, Philadelphia, 1896)
- J. Pierpont, Functions of a complex variable (Ginn & co., Boston, 1914)
- E. J. Townsend, Functions Of a complex variable (Henry Holt And Company,
  1915)
- T. M. MacRobert, Functions of a complex variable (London, MacMillan,
  1917)
- H. F. Burkhardt, Theory of functions of a complex variable (D. C. Heath,
  Boston, 1913)
- A. R. Forsyth, Theory of functions of a complex variable (Cambridge
  University Press, 1918)
- J. Harkness e F. Morley, Introduction ToThe Theory Analytic Functions
  (Stechert & co., 1898)
- E. T. Whittaker e G. N. Watson, Modern Analysis (Cambridge University
  Press, 1922)
- E. Goursat, Functions of a complex variable I (Ginn & co. 1916)
- E. Goursat, Functions of a complex variable II (Ginn & co. 1916)
- S. Saks e A. Zygmund, Analytic functions (Polskie Towarzystwo
  Matematyczne, 1952)
- (FR) J. Hoüel, Cours de calcul infinitésimal. Tome troisième e Cours de
  calcul infinitésimal. Tome troisième deuxième partie (Gauthier-Villars,
  1881)
- (FR) E. Picard, Traité d'Analyse (vol. 2) (Gauthier-Villars, 1893)
- (EN) Lars Ahlfors, Complex Analysis, 3rd, McGraw-Hill, 1979, ISBN
  978-0-07-000657-7.
- (EN) E. Freitag, R. Busam, Complex Analysis; Springer-Verlag(2005).

Voci correlate

- Numero complesso
- Piano complesso
- Geometria complessa

Altri progetti

- Wikibooks contiene testi o manuali di analisi complessa
- Wikizionario contiene il lemma di dizionario «Analisi complessa»
- Wikimedia Commons contiene immagini o altri file su Analisi complessa

Collegamenti esterni

- Analisi complessa, in Thesaurus del Nuovo soggettario, BNCF, marzo 2013.

Polo (analisi complessa)

In matematica, e in particolare in analisi complessa, per polo di una
funzione olomorfa f(z), si intende una singolarità isolata z₀ della
funzione per cui

\lim _{z→z_0} |f(z)| = +\infty .

Il polo si distingue dalla singolarità eliminabile e dalla singolarità
essenziale, per le quali tale limite rispettivamente è finito e non esiste.

La conoscenza delle caratteristiche dei poli di una funzione olomorfa
consente di determinare molte delle sue caratteristiche; inoltre lo studio
dei poli è fondamentale nel calcolo dei residui.

Serie di Laurent

Una definizione equivalente può essere data tramite serie di Laurent. Una
singolarità isolata z₀ è un polo se e solo se lo sviluppo locale in serie
di Laurent è del tipo

f (z) = Σ_{n=0}^{+\infty } a_n \left ( z-z_0 \right )^n + \frac
{b_1}{z-z_0} + ⋯+ \frac {b_k}{\left ( z-z_0 \right )^k},

con b_k\neq 0, per qualche k>0.

In altre parole, una singolarità isolata è un polo se e solo se la parte
principale della serie di Laurent in un intorno bucato della singolarità è
costituita da un numero finito di termini, cioè se i coefficienti con apice
i negativo sono un numero finito k diverso da zero:

f(z) = Σ_{n=-k}^{+\infty } a_n \left ( z-z_0 \right )ⁿ.

Ordine del polo

L'ordine del polo è il numero naturale k di termini che costituiscono la
parte principale della serie di Laurent. Analogamente, z₀ è un polo se per
qualche h>0 il limite:

b_h = \lim _{z →z_0} f(z) \left ( z-z_0 \right )^h,

esiste, è finito ed è diverso da zero. In questo caso la funzione ha nel
punto z₀ un polo di ordine h.

Esempi

Una funzione

f(z) = \frac {p(z)}{q(z)},

dove p e q sono polinomi senza radici in comune (quindi la funzione è
ridotta ai minimi termini), è definita su

\C \setminus {z_1,…,z_n},

dove z_1,…,zₙ sono le radici di q. Ciascuno di questi punti è un polo, il
cui ordine è pari alla molteplicità della radice. Ad esempio,

f(z) = \frac {z+1}{z(z-1)²},

ha un polo di ordine 1 in 0 ed un polo di ordine 2 in 1.

La funzione

f(x) = \frac{1}{\sin x} ,

è definita su

\mathbb C\setminus {kπ | k\in \mathbb Z},

ed ha un polo di ordine uno su ogni punto kπ. Ha quindi infiniti poli.

Funzione meromorfa

Una funzione olomorfa f avente poli nei punti z_1,…zₙ può essere
considerata come una funzione il cui dominio comprende anche questi punti,
il cui codominio è la sfera di Riemann \C ∪{\infty }: è sufficiente imporre
f(z_i)=\infty . Il risultato di questa operazione è una funzione meromorfa.

Voci correlate

- Zero (analisi complessa)
- Residuo (analisi complessa)
- Funzione meromorfa
- Indicatore logaritmico

Equazione algebrica

In matematica si chiamano equazioni algebriche o polinomiali quelle
equazioni equivalenti (o riconducibili tramite opportune trasformazioni) ad
un polinomio uguagliato a zero. Il grado di tale polinomio è anche il grado
dell'equazione.

Descrizione

Un'equazione algebrica è detta fratta (o frazionaria) se l'incognita
compare al denominatore di una frazione; in caso contrario, l'equazione si
dice intera. Si conviene inoltre definire irrazionali le equazioni in cui
l'incognita compare sotto il segno di radice, e razionali in caso
contrario. A queste si aggiungono le equazioni parametriche, in cui sono
presenti delle quantità variabili dette parametri.

Un'equazione polinomiale di grado n in una incognita si può esprimere nella
forma:

a_nx^n+a_{n-1}x^{n-1}+...+a_1x+a_0=0

dove gli a_i sono numeri reali (o in generale complessi) e x è l'incognita
da determinare. Il tipo più semplice di equazioni algebriche sono le
equazioni lineari, cioè di primo grado. In virtù del teorema fondamentale
dell'algebra ogni equazione di grado n ammette esattamente n soluzioni
(radici) nel campo complesso. Le equazioni di secondo grado sono chiamate
quadratiche; seguono le cubiche e le quartiche. Per il teorema di
Abel-Ruffini le equazioni di grado superiore al quarto non sono
generalmente risolvibili per radicali. Tra le equazioni particolari di
grado superiore si ricordano: equazioni binomie (ax^n + b = 0 ), equazioni
biquadratiche (ax^4 + bx^2 + c = 0 ), equazioni trinomie (ax^{2n} + bx^n +
c = 0 ), equazioni reciproche (in cui, se un numero è soluzione, lo è anche
il suo reciproco).

Voci correlate

- Disequazione algebrica

Collegamenti esterni

- Alcuni momenti significativi della storia delle equazioni algebriche
  (PDF), ulisse.sissa.it.
- Equazione algebrica, in Thesaurus del Nuovo soggettario, BNCF, marzo
  2013.

Piano complesso

In analisi complessa, il piano complesso (chiamato anche piano di
Argand-Gauss) è un modo per visualizzare lo spazio dei numeri complessi.
Può essere pensato come un piano cartesiano modificato, con la parte reale
rappresentata sull'asse x e la parte immaginaria rappresentata sull'asse y.
L'asse x è chiamato anche l'asse reale e l'asse y asse immaginario.

Storia

Il piano complesso è a volte chiamato piano di Argand per il suo uso nei
diagrammi di Argand. La sua creazione è generalmente attribuita a
Jean-Robert Argand, in parallelo con Gauss, per cui viene da alcuni anche
definito Piano di Gauss. Per non sminuire uno o l'altro matematico viene
anche definito Piano di Argand-Gauss anche se fu descritto per la prima
volta nel 1799 dal matematico norvegese-danese Caspar Wessel.

Uso

Il concetto del piano complesso consente una interpretazione geometrica dei
numeri complessi. Sotto addizione, i numeri complessi si sommano come
vettori, mentre la moltiplicazione di numeri complessi può essere
geometricamente espressa usando le coordinate polari, dove il modulo del
prodotto è il prodotto dei moduli dei fattori e l'argomento del prodotto
(angolo dall'asse reale) è la somma degli angoli dei fattori.

I diagrammi di Argand sono frequentemente usati per graficare la posizione
dei poli o di zeri di una funzione nel piano complesso.

Uso e notazioni

Un numero complesso può essere separato in parte reale e immaginaria:

z = x + iy,

dove x e y sono numeri reali, e i è l'unità immaginaria. I numeri reali
sono in corrispondenza biunivoca con i punti della retta reale euclidea. In
questa notazione, il numero complesso z corrisponde al punto (x,y) del
piano cartesiano. L'ascissa è data da x= \mathrm{Re} (z) (la parte reale,
l'asse delle x) e da y= \mathrm{Im} (z) (la parte immaginaria, l'asse delle
ordinate).

Nel piano cartesiano, il punto (x,y) può anche essere rappresentato in
coordinate polari come:

(x, y) = (r\cos θ, r\sin θ)

dove il modulo r e la fase θ sono ricavate (per x>0) dalle formule

r = √(x²⁺y²); θ=\arctan \frac{y}{x} .

Per il calcolo della fase si può usare la funzione arcotangente2.

Bibliografia

- (EN) Lars Ahlfors, Complex Analysis, 3rd, McGraw-Hill, 1979, ISBN
  978-0-07-000657-7.
- (EN) E. Freitag, R. Busam, Complex Analysis; Springer-Verlag(2005).

Voci correlate

- Numero complesso
- Rappresentazione dei numeri complessi
- Sfera di Riemann
- Trigonometria

Altri progetti

- Wikimedia Commons contiene immagini o altri file su piano complesso

Rappresentazione dei numeri complessi

I numeri complessi hanno differenti rappresentazioni, tutte equivalenti.
Essendo il campo dei numeri complessi \mathbb{C} isomorfo a \mathbb{R} ²,
ogni numero complesso è rappresentabile come un vettore nel piano
complesso. Si tratta di scegliere il sistema di coordinate.

Rappresentazione cartesiana

La rappresentazione cartesiana (o rettangolare) è quella più vicina alla
definizione dei numeri complessi:

  z = a + ib

con a,b\in \mathbb{R} e i l'unità immaginaria.

Questa non è altro che una generica combinazione lineare di elementi della
base di \mathbb{R} ², (1,0)=1 e (0,1)=i con coefficienti reali a, b.

Rappresentazione polare

Usare la rappresentazione polare dei numeri complessi significa usare le
coordinate polari (ρ,θ)

z=ρ\left (\cos (θ)+i\sin (θ)\right )

dove ρ è il modulo (positivo o nullo) del numero complesso, mentre θ è la
fase o argomento. Dato un numero complesso espresso in coordinate
cartesiane a+ib, il modulo si ottiene banalmente come:

ρ= √(a² ⁺ b²)

La fase può essere ottenuta a partire dalla funzione trigonometrica di
arcotangente come¹ :

θ= \left {\begin{matrix} \arctan (b/a), \mbox{per } a > 0 \arctan (b/a)+π,
\mbox{per } a < 0\end{matrix} \right .

Ciò si rende necessario per ovviare al fatto che l'arcotangente fornisce
valori ristretti a mezzo angolo giro (convenzionalmente nell'intervallo
(-π/2,π/2) ), il che comporterebbe la perdita dell'informazione relativa al
semipiano entro cui si colloca il numero complesso dato.

Quando a=0 il rapporto b/a non è definito. Ciononostante si può attribuire
un significato alla precedente formula: per a=0 si intende il \lim _{a →0}
\arctan (b/a) = sgn(b) ·π/2 .

In generale, data la periodicità delle funzioni trigonometriche, non
sussiste una corrispondenza biunivoca tra numeri complessi e
rappresentazioni polari. È facilmente dimostrabile l'identità tra tutti i
numeri espressi nella forma (ρ,θ+2kπ), k\in \mathbb{Z} , in virtù della
quale lo spazio delle rappresentazioni polari risulta partizionato in
classi di equivalenza: queste sono in corrispondenza biunivoca con i numeri
complessi, eccezion fatta per lo 0, per il quale non è possibile
individuare una rappresentazione univoca (ogni rappresentazione polare con
ρ=0 e θ qualsiasi è una rappresentazione dello 0).

Rappresentazione esponenziale

Usando la formula di Eulero o equivalentemente la definizione di
esponenziale complesso, dalla rappresentazione polare discende direttamente
la cosiddetta rappresentazione esponenziale:

z=ρ(\cos (θ)+i\sin (θ)) = ρe^{iθ}

Questa è la notazione che viene più frequentemente utilizzata nelle
applicazioni in cui modulo e fase abbiano un significato preminente
rispetto a parte reale ed immaginaria (ad esempio per la descrizione dei
fasori), e preferita alla rappresentazione polare per la maggior
compattezza e per la maggior praticità nello svolgimento di operazioni di
moltiplicazione (e conseguentemente di elevamento a potenza).

Rappresentazione matriciale dei numeri complessi

Le rappresentazioni alternative del campo dei numeri complessi possono dare
una migliore comprensione della loro natura. Una rappresentazione
particolarmente elegante interpreta ogni numero complesso come una matrice
2×2 di numeri reali che dilata/contrae e ruota i punti del piano. La
matrice ha la forma

\begin{pmatrix} a & -b b & a \end{pmatrix}

con a e b numeri reali. La somma ed il prodotto di due tali matrici è
ancora di questa forma. Ogni matrice non nulla di questa forma è
invertibile ed il relativo inverso è ancora di questa forma. Di
conseguenza, le matrici di questa forma sono un campo. Di fatto, questo è
esattamente il campo dei numeri complessi. Ciascuna di queste matrici può
essere scritta come:

\begin{pmatrix} a & -b b & a \end{pmatrix} = a \begin{pmatrix} 1 & 0 0 & 1
\end{pmatrix} + b \begin{pmatrix} 0 & -1 1 & 0 \end{pmatrix}

questa rappresentazione implica che il numero reale 1 va rappresentato con
la matrice identità

\begin{pmatrix} 1 & 0 0 & 1 \end{pmatrix}

mentre l'unità immaginaria i si rappresenta con la matrice

\begin{pmatrix} 0 & -1 1 & 0 \end{pmatrix}

che rappresenta una rotazione in senso antiorario di 90 gradi. Si noti che
il quadrato di questa matrice è effettivamente uguale alla matrice
\begin{pmatrix} -1 & 0 0 & -1 \end{pmatrix} che rappresenta il numero reale
-1.

Il valore assoluto di un numero complesso espresso come matrice è uguale
alla radice quadrata del determinante di quella matrice. Se la matrice è
considerata come la trasformazione di un punto nel piano, allora la
trasformazione ruota i punti con un angolo uguale al coefficiente
direzionale del numero complesso e scala il punto di un fattore uguale al
valore assoluto del numero complesso. Il coniugato del numero complesso z
corrisponde alla trasformazione che contrae/dilata i punti del piano del
medesimo fattore di scala che z (il valore assoluto) e li ruota dello
stesso angolo che l'argomento di z, ma nel senso opposto; quest'operazione
corrisponde alla trasposta della tabella che rappresenta z.

Una notazione analoga si ha per il corpo dei quaternioni.

Note

[1] Molti linguaggi di programmazione forniscono una funzione apposita
  corrispondente a questa arcotangente estesa, spesso denominata atan2.

Bibliografia

- (EN) Lars Ahlfors, Complex Analysis, 3rd, McGraw-Hill, 1979, ISBN
  978-0-07-000657-7.
- (EN) E. Freitag, R. Busam, Complex Analysis; Springer-Verlag(2005).

Voci correlate

- Numero complesso
- Piano complesso

Numero complesso

Con l'espressione numero complesso si intende un numero formato da una
parte immaginaria e da una parte reale. Può essere perciò rappresentato
dalla somma di un numero reale e di un numero immaginario (cioè un multiplo
dell'unità immaginaria, indicata con la lettera i). I numeri complessi sono
usati in tutti i campi della matematica, in molti campi della fisica (e
notoriamente in meccanica quantistica), nonché in ingegneria, specialmente
in elettronica/telecomunicazioni o elettrotecnica, per la loro utilità nel
rappresentare onde elettromagnetiche e correnti elettriche ad andamento
temporale sinusoidale.

In matematica i numeri complessi formano un campo (nonché un'algebra reale
bidimensionale) e sono generalmente visualizzati come punti del piano,
detto piano complesso. La proprietà più importante che caratterizza i
numeri complessi è il teorema fondamentale dell'algebra, che asserisce che
qualunque equazione polinomiale di grado n ha esattamente n soluzioni
complesse, non necessariamente distinte.

Introduzione informale

L'unità immaginaria

Nel corso dei secoli gli insiemi dei numeri sono andati man mano
allargandosi per rispondere all'esigenza di dare soluzione a equazioni e
problemi sempre nuovi.

I numeri complessi sono un'estensione dei numeri reali nata inizialmente
per consentire di trovare tutte le soluzioni delle equazioni polinomiali.
Ad esempio, l'equazione

x²⁼-1

non ha soluzioni reali, perché in questo insieme non esistono numeri il cui
quadrato sia negativo.

Si definisce allora il valore i, chiamato anche unità immaginaria, che gode
della seguente proprietà:

i²⁼-1

I numeri complessi sono formati da due parti, una parte reale ed una parte
immaginaria, e sono rappresentati dalla seguente espressione:

a + ib

dove a e b sono numeri reali, mentre i è l'unità immaginaria.

Le leggi della somma algebrica e del prodotto nei numeri complessi si
applicano facendo i conti nel modo usuale e sapendo che i² ⁼ -1 .

Come i numeri reali sono in corrispondenza biunivoca con i punti di una
retta, quelli complessi sono in corrispondenza con i punti del piano, detto
piano complesso (o di Argand-Gauss): al numero complesso a+ ib si associa
il punto di coordinate cartesiane (a,b) .

Equazioni a coefficienti reali con soluzioni non reali

Usando la relazione i²⁼-1 si possono risolvere tutte le equazioni di
secondo grado

ax^2 + bx + c = 0,

con a,b,c\in \R , incluse quelle che non hanno soluzioni reali perché
dotate di discriminante negativo:

Δ=b²-4ac<0.

Le soluzioni sono determinate dalla formula risolutiva dell'equazione

x=\frac{-b\pm √(b²-4ac)}{2a} = \frac{-b\pm √(Δ)}{2a}

che nel caso in cui il discriminante sia negativo, si svolge nel modo
seguente:

√(-Δ) = √((-1)(Δ)) = √(-1)√(Δ) = i√(Δ).

Ad esempio:

x^2 + 4x + 8 = 0 ⇒x=\frac{-4\pm √(16-32)}{2} =\frac{-4\pm √(-16)}{2}
=\frac{-4\pm i√(16)}{2} =-2\pm 2i.

Più in generale è vero che se un numero complesso è soluzione di
un'equazione, allora anche il suo complesso coniugato è soluzione della
stessa equazione. Quindi nel caso di un'equazione di grado dispari, tra le
soluzioni ci sarà sempre almeno un numero reale.

Cenni storici

I numeri complessi hanno avuto una genesi dilatata nel tempo. Cominciarono
a essere utilizzati formalmente nel XVI secolo nelle formule di risoluzione
delle equazioni di terzo e quarto grado di Tartaglia. I primi che
riuscirono ad attribuire soluzioni alle equazioni cubiche furono Scipione
Dal Ferro, il Bombelli e anche Niccolò Tartaglia, quest'ultimo, dopo molte
insistenze, passò i risultati a Girolamo Cardano con la promessa di non
divulgarli. Cardano dopo aver verificato l'esattezza delle soluzioni di
Tartaglia non rispettò la sua promessa e pubblicò i risultati, citandone
l'autore però, nella sua nota Ars Magna del 1545. Tartaglia aveva molte
amicizie tra gli inquisitori e in seguito Cardano ebbe problemi legati alla
giustizia del tempo, molti dei quali provenienti da accuse di eresia.
Attualmente la comparsa di radici di numeri negativi viene attribuita
principalmente a Tartaglia mentre nelle meno numerose pagine dedicate a
Cardano non vi è traccia del suo probabile importante contributo a tale
rappresentazione numerica.

Inizialmente i numeri complessi non vennero considerati come "numeri" ma
solo come artifici algebrici utili a risolvere equazioni. Erano infatti
numeri "che non dovrebbero esistere": Cartesio nel XVII secolo li chiamò
"numeri immaginari". Abraham de Moivre ed Eulero nel XVIII secolo
iniziarono a fornire ai numeri complessi una base teorica, finché questi
assunsero piena cittadinanza nel mondo matematico con i lavori di Gauss.
Contemporaneamente si affermò l'interpretazione dei numeri complessi come
punti del piano.

Terminologia

In matematica molti oggetti e teoremi dipendono dalla scelta di un insieme
numerico di base: spesso la scelta è fra numeri reali e complessi.
L'aggettivo "complesso" è in questo caso usato per specificare questo
insieme di base. Per esempio, si definiscono le matrici complesse, i
polinomi complessi, gli spazi vettoriali complessi e l'algebra di Lie
complessa. Esistono anche il teorema di Sylvester complesso e il teorema
spettrale complesso.

Definizione moderna

Formalmente un numero complesso si può definire come una coppia ordinata di
numeri reali (a, b) . Si definiscono quindi somma e prodotto di due numeri
complessi nel modo seguente:

( a , b ) + ( c , d ) = ( a + c , b + d ),
( a , b ) ( c , d ) = ( ac - bd , bc + ad ).

Con queste due operazioni, l'insieme dei numeri complessi risulta essere un
campo, che viene indicato con \mathbb{C} .

Il numero complesso (a,0) viene identificato con il numero reale a , mentre
il numero (0,1) è chiamato unità immaginaria ed è descritto con la lettera
i . L'elemento 1 è l'elemento neutro per la moltiplicazione, mentre si
verifica che:

i² ⁼ ⁽⁰,1)(0,1) = (-1,0) = -1.

Ogni numero complesso z = (a,b) si scrive facilmente come combinazione
lineare nel modo seguente:

z =(a,b)=(a,0) + (0,b) = a + (b,0) (0,1) = a + b (0,1) = a + bi.

I numeri a e b sono rispettivamente la parte reale e la parte immaginaria
di z. Questa rappresentazione dei numeri complessi rende agevole lo
svolgimento delle operazioni di somma e prodotto. Ad esempio:

(2+4i)(1-i) = 2(1-i)+4i(1-i) = 2-2i+4i-4i² ⁼ ²⁺²ⁱ-4(-1) = 6+2i.

Definizioni alternative

Usando gli strumenti della teoria dei campi, il campo dei numeri complessi
può essere definito come la chiusura algebrica del campo dei numeri reali.

Usando gli strumenti della teoria degli anelli, può anche essere introdotto
come l'anello quoziente dell'anello dei polinomi reali con una variabile
tramite l'ideale generato dal polinomio x²⁺¹ :

\mathbb{C} = \mathbb{R}{ x } / (x² ⁺ ¹⁾.

Questo è effettivamente un campo perché x²⁺¹ è irriducibile. La radice del
polinomio x²⁺¹ è l'unità immaginaria i , quindi l'anello quoziente è
isomorfo a \mathbb{R}{i} =\mathbb{C} .

Geometria

Un numero complesso può essere visto come un punto del piano cartesiano,
chiamato in questo caso piano di Gauss. Una rappresentazione di questo tipo
si chiama diagramma di Argand-Gauss. Nella figura si vede che

z = x + iy = r (\cos φ+ i\sin φ)

essendo \cos φ e \sin φ funzioni trigonometriche.

Le formule inverse sono:

  r = √(x² ⁺ y²)φ= \arctan \frac{y}{x} per x > 0 φ= \arctan \frac{y}{x} +π
  per x < 0

Usando la formula di Eulero, possiamo esprimere z come

z = r(\cos φ+ i\sin φ) = re^{iφ}

tramite la funzione esponenziale. Qui r è il modulo (o valore assoluto o
norma) e φ (detta Anomalia) è l'argomento di z . L'argomento è determinato
da z se è inteso nell'intervallo [0,2π) , altrimenti è definito solo a meno
di somme con 2kπ per qualche intero k .

Operazioni con i numeri complessi

Modulo e distanza

| z | = √(x² ⁺ y²)

Il valore assoluto (modulo) ha le seguenti proprietà:

  | z + w | \leq | z | + | w |, | z w | = | z | | w |, | z / w | = | z | /
  | w | se w \neq 0 ,

valide per tutti i numeri complessi z e w .

La prima proprietà è una versione della disuguaglianza triangolare.

La distanza fra due punti del piano complesso è data semplicemente da

d(z, w) =|z - w|

Coniugato

Il complesso coniugato del numero complesso z = a+ib è definito come

\bar z = a-ib.

A volte è anche indicato come z^* . Nel piano complesso \bar{z} è ottenuto
da z per simmetria rispetto all'asse reale. Valgono le seguenti proprietà:

\overline{z+w} = \bar{z} + \bar{w} ,
\overline{zw} = \bar{z} \bar{w} ,
\overline{(z/w)} = \bar{z} /\bar{w} ,
\bar{\bar{z} } =z,
\bar{z} =z \Longleftrightarrow z\in \R ,
|z|=|\bar{z} |,
|z|^2 = z\bar{z} ,

Reciproco

Conoscendo il valore assoluto ed il coniugato di un numero complesso z \neq
0 è possibile calcolare il suo reciproco z^{-1} attraverso la formula:

z^{-1} = \frac{\bar{z} }{|z|²}

Ovvero, se z = a+ib otteniamo

z^{-1} = \frac{a-ib}{a²⁺b²} .

Somma algebrica

Valgono le relazioni

( a + ib ) + ( c + id ) = ( a + c ) + i ( b + d ),
( a + ib ) - ( c + id ) = ( a - c ) + i ( b - d ).

La somma di due numeri complessi equivale alla usuale somma fra vettori nel
piano complesso.

Prodotto

Vale

( a + ib )( c + id ) = ( ac - bd ) + i ( bc + ad )

In realtà il prodotto non è che il risultato di un normalissimo prodotto di
binomi. Usando la rappresentazione

z = re^{iθ}

e le proprietà della funzione esponenziale, il prodotto di due numeri
complessi

z_1 = r_1 e^{i θ_1}, z_2 = r_2 e^{i θ_2}

assume la forma più agevole

z_1·z_2 = r_1 e^{i θ_1} ·r_2 e^{i θ_2} = r_1 r_2 e^{i (θ_1 + θ₂₎}.

In altre parole, nel prodotto di due numeri complessi, si sommano gli
argomenti e si moltiplicano i moduli.

Questa affermazione consente di dimostrare la regola dei segni del
prodotto: -·-=+. Difatti se si considera che l'argomento di un numero reale
negativo è 180º, moltiplicando tra loro due di questi numeri si ottiene un
numero con argomento 360° e quindi 0° che è l'argomento di un numero reale
positivo.

Una moltiplicazione per un numero complesso può essere vista come una
simultanea rotazione e omotetia. Moltiplicare un vettore o equivalentemente
un numero complesso per l'elemento i produce una rotazione di 90°, in senso
antiorario, del numero complesso di partenza. Ovviamente la moltiplicazione
per i e poi ancora per i produce una rotazione di 180º; ciò è logico visto
che i² ⁼ -1 .

Rapporto

Il rapporto fra due numeri complessi z₁ ₌ ₐ₊ib e z₂ ₌ c+id è dato da:

{z_1 \over z_2} = {a+ib \over c+id} = {(a+ib) \over (c+id)}{(c-id) \over
(c-id)}= \frac{ac+bd+i(cb-ad)}{c²⁺d²} .

Usando la rappresentazione

z = re^{iθ},

il rapporto di due numeri complessi è

\frac{r_1 e^{i θ₁}}{r_2 e^{i θ₂}} = \frac{r₁}{r₂} e^{i (θ_1 - θ₂₎}.

Potenze

Rappresentando ogni numero complesso come

z = re^{iθ}

è facile descrivere la potenza n -esima

z^n = r^ne^{niθ}

per ogni n intero. Con una notazione lievemente differente:

z = |z|(\cos θ+ i \sin θ)

Si ottiene la formula di De Moivre:

z^n = |z|^n ( \cos (nθ) + i \sin (nθ) )

Inoltre, ogni numero complesso ha esattamente n radici n-esime: in
particolare non esiste un modo univoco di definire la radice quadrata di un
numero complesso.

Esponenziale

La funzione esponenziale complessa e^z è definita facendo uso delle serie e
degli strumenti del calcolo infinitesimale, nel modo seguente:

e^z = Σ_{n=0}^\infty \frac{zⁿ}{n!} .

In particolare, se z = a+ib si ottiene

e^{a+ib} = e^ae^{ib} = e^a(\cos b + i \sin b)

facendo uso della formula di Eulero.

Logaritmo

Il logaritmo naturale \ln z di un numero complesso z è per definizione un
numero complesso w tale che

e^w = z.

Se

z = a+ib = re^{iθ} = r(\cos θ+ i\sin θ)

il logaritmo di z è un qualsiasi numero complesso w del tipo

w = \ln z = \ln (re^{iθ}) = \ln r + i(θ+2kπ)

dove k è un numero intero qualsiasi. Poiché il valore k è arbitrario, un
numero complesso ha una infinità di logaritmi distinti, che differiscono
per multipli interi di 2πi.

Se a>0 si può scrivere

\ln (a+ib)=\ln √(2)+i\arctan \frac{b}{a} .

In questo caso, se z è reale (cioè se b=0) fra gli infiniti valori ce n'è
uno reale, che corrisponde all'usuale logaritmo di un numero reale
positivo.

Esempi

Supponiamo di voler individuare i numeri complessi z tali che

4z^2=\bar z⁴.

La prima possibilità è quella di porre z=a+ib e di uguagliare la parte
reale di 4z² alla parte reale del coniugato di z⁴ e analogamente per le
rispettive parti immaginarie. Seguendo questa strada si ottengono due
equazioni:

ab(a^2-b^2+2)=0,
a^4+b^4-6(ab)^2=4(a^2-b^2).

da cui si ricavano 7 soluzioni:

z=0, -2, 2, i√(3)+1, -i√(3)+1, i√(3)-1, -i√(3)-1.

In alternativa, si può usare la rappresentazione polare

z = r (\cos φ+ i\sin φ)

e uguagliare le norme e gli argomenti di 4z² e del coniugato di z⁴ ,
ottenendo anche qui due equazioni:

4r^2=r^4,
6φ=2kπ.

con k=0,1,...,5 . Ovviamente si ottengono le stesse soluzioni, per esempio

z=i√(3)+1=2e^{i{π}/3}.

Alcune proprietà

Perdita dell'ordinamento

Diversamente dai numeri reali, i numeri complessi non possono essere
ordinati in modo compatibile con le operazioni aritmetiche. Non è cioè
possibile definire un ordine tale che

a\leq b, ⇒a+c\leq b+c,
a\geq 0, b\geq 0 ⇒ab \geq 0,

come avviene con i numeri reali. Quindi non ha senso chiedere ad esempio se
i è maggiore o minore di 0, né studiare disequazioni nel campo complesso.
Infatti in ogni campo ordinato tutti i quadrati devono essere maggiori o
uguali a zero: per costruzione dell'unità immaginaria, invece i²⁼-1

Ciò non deve essere confuso con il dire che l'insieme dei numeri complessi
non può essere totalmente ben ordinato. Infatti i numeri complessi hanno,
ad esempio, un ordinamento in termini di ordine lessicografico, e
costituiscono quindi un insieme ordinabile (come ogni insieme in ZFC stante
l'assioma della scelta), ma non formano un campo ordinato (per la ragione
di cui sopra) né una struttura algebrica ordinabile rispetto alla metrica
indotta da una norma.

Piano cartesiano

Quando si disegna una funzione nel piano cartesiano il cui codominio
contiene numeri dell'insieme immaginario, tali numeri non possono essere
rappresentati da una coppia di coordinate (x;y), poiché essendo y complesso
non può avere ordinamento rispetto alla retta y.

Spazio dei vettori reali

L'insieme \C è contemporaneamente uno spazio vettoriale complesso ad una
dimensione (come tutti i campi), ed uno spazio vettoriale reale a due
dimensioni. In quanto spazio vettoriale reale a dimensione finita è inoltre
uno spazio normato completo, cioè uno spazio di Banach, e più in
particolare uno spazio di Hilbert.

Soluzioni delle equazioni polinomiali

Una radice complessa di un polinomio p a coefficienti reali è un numero
complesso z tale che p(z)=0. Il teorema fondamentale dell'algebra asserisce
che ogni polinomio di grado n ha esattamente n soluzioni complesse, contate
con molteplicità. Questo risultato indica che i numeri complessi sono (a
differenza dei reali) un campo algebricamente chiuso.

Analisi complessa

Lo studio delle funzioni con variabili complesse è detto analisi complessa
e trova largo impiego nella matematica applicata e nella teoria dei numeri,
oltre che in altre branche della matematica, della fisica e
dell'ingegneria. Spesso, le dimostrazioni più semplici per gli enunciati
dell'analisi reale o persino della teoria dei numeri impiegano tecniche di
analisi complessa (vedi teorema dei numeri primi per un esempio).
Diversamente dalle funzioni reali, che sono rappresentate comunemente come
grafici bidimensionali, le funzioni complesse hanno grafici a quattro
dimensioni e spesso vengono rappresentate come grafici colorati dove il
colore sopperisce alla dimensione mancante (si veda, ad esempio, la voce
Immagini conformi). Si possono anche usare delle animazioni per mostrare la
trasformazione dinamica della funzione complessa del piano complesso.

Applicazioni

In matematica

I numeri complessi sono presenti in tutta la matematica, e sono
protagonisti di interi settori, come l'analisi complessa o la geometria
algebrica. Elenchiamo qui soltanto alcune applicazioni dei numeri complessi
a settori della matematica in cui questi non hanno un ruolo dominante.

- Teoria dei numeri: La teoria dei numeri analitica usa l'analisi complessa
  per affrontare problemi sui numeri interi. Alcuni esempi sono il teorema
  dei numeri primi e la collegata ipotesi di Riemann.
- Integrali impropri: Alcuni integrali impropri possono essere risolti
  agevolmente con il teorema dei residui dell'analisi complessa.
- Equazioni differenziali: Le equazioni differenziali lineari a
  coefficienti costanti si risolvono trovando le radici complesse di un
  polinomio associato all'equazione.
- Frattali: Alcuni frattali sono definiti tramite i numeri complessi, per
  esempio l'insieme di Mandelbrot e l'insieme di Julia.

In fisica

- Dinamica dei fluidi: Nella dinamica dei fluidi i numeri complessi vengono
  utilizzati per descrivere il flusso potenziale in 2 dimensioni.
- Meccanica quantistica: Il campo dei numeri complessi è una componente
  essenziale della meccanica quantistica dato che la teoria è sviluppata in
  uno spazio di Hilbert a dimensione infinita derivato da C. L'unità
  immaginaria compare anche nell'equazione di Schrödinger.
- Relatività: Nella relatività generale e relatività speciale alcune
  formule dello spazio metrico diventano più semplici se si suppone la
  variabile temporale come una variabile immaginaria.

Ingegneria

I numeri complessi sono utilizzati per la risoluzione delle equazioni
differenziali associate al moto di tipo vibratorio dei sistemi meccanici.
Sono molto usati anche nell'ingegneria elettrica, soprattutto per
rappresentare lo sfasamento tra reattanza e resistenza.

Analisi dei segnali

I numeri complessi vengono utilizzati nell'analisi dei segnali e in tutti i
campi dove si trattano segnali che variano sinusoidalmente nel tempo, o
anche semplicemente periodici. Il valore assoluto di |z| è interpretato
come l'ampiezza del segnale mentre l'argomento di z è interpretato come la
fase. I numeri complessi rendono possibile anche l'analisi di Fourier, che
rende possibile scomporre un generico segnale tempo-invariante in una somma
di infinite sinusoidi: ogni sinusoide è scritta come un singolo numero
complesso

f ( t ) = z e^{jωt}

dove ω è la pulsazione della sinusoide e z la sua ampiezza.

Elettrotecnica ed elettronica

Nell'ingegneria elettrica ed elettronica vengono utilizzati per indicare la
tensione e la corrente. L'analisi dei componenti resistivi, capacitivi e
induttivi è stata unificata con l'introduzione dei numeri complessi, che
riassumono tutte e tre queste componenti in una sola entità detta
impedenza, semplificando notevolmente i calcoli. Possono esprimere delle
relazioni che tengono conto delle frequenze e di come i componenti varino
il loro comportamento al variare della frequenza. In questo tipo di calcoli
si usa tradizionalmente la lettera j per indicare l'unità immaginaria, dato
che la i è riservata alla corrente: i primi trattati di elettrotecnica,
all'inizio del XX secolo, stabilivano j = -i, cioè l'unità immaginaria
nelle formule usate per l'elettrotecnica era il negativo di quella usata
dai matematici. L'uso è stato mantenuto nel tempo, e questo dettaglio, sia
pure ignoto ai più, è parzialmente vero anche oggi. Anche se, la stragrande
maggioranza delle volte, nella letteratura tecnica con j oramai si intende
l'unità immaginaria stessa, per cui j=i

Bibliografia

- (EN) Lars Ahlfors, Complex Analysis, 3rd, McGraw-Hill, 1979, ISBN
  978-0-07-000657-7.
- (EN) E. Freitag, R. Busam, Complex Analysis; Springer-Verlag (2005).
- (EN) P. Lounesto, Clifford Algebras and Spinors, Cambridge University
  Press, 1997, ISBN 0-521-59916-4.
- (EN) Paul J. Nahin, An Imaginary Tale; Princeton University Press; ISBN
  0-691-02795-1 (hardcover, 1998). Una semplice introduzione ai numeri
  complessi e all'analisi complessa.
- (EN) Tristan Needham, Visual Complex Analysis; Clarendon Press; ISBN
  0-19-853447-7 (hardcover, 1997). Storia dei numeri complessi e
  dell'analisi complessa con un'utile interpretazione geometrica.

Voci correlate

- Parte reale
- Parte immaginaria
- Complesso coniugato
- Inverso di un numero complesso
- Formula di De Moivre
- Identità di Eulero
- Piano complesso
- Radice dell'unità
- Rappresentazione dei numeri complessi
- Storia dei numeri complessi
- Teorema fondamentale dell'algebra
- Leonhard Euler
- Caspar Wessel
- Jean-Robert Argand
- Carl Friedrich Gauss
- Numero ipercomplesso
- Quaternione
- Numero complesso iperbolico
- Numero duale
- Analisi complessa
- Geometria complessa
- Fasore

Altri progetti

- Wikiversità contiene lezioni su numero complesso
- Wikimedia Commons contiene immagini o altri file su numero complesso

Collegamenti esterni

- (AR, EN, ES, FR) Dimensions: a math film. Film introduttivo sui numeri
  complessi (capitoli 5 e 6).
- Numeri Complessi. Una lezione interattiva
- I numeri complessi. Note da lezioni alle superiori. Con GeoGebra.
- Numero complesso, in Thesaurus del Nuovo soggettario, BNCF, marzo 2013.

KUKA

KUKA è un produttore tedesco a livello mondiale di robot industriali e
soluzioni per l'automazione industriale. La società KUKA Robotics ha 25
filiali in tutto il mondo, tra cui: Stati Uniti, Canada, Messico, Brasile,
Cina, Giappone, Corea, Taiwan, India e la maggior parte degli stati
europei. Il nome KUKA, è un acronimo per Keller und Knappich Augsburg ed è,
allo stesso tempo, il marchio registrato che si trova sui robot industriali
e altri prodotti realizzati da KUKA.

Storia

La società è stata fondata nel 1898 ad Augusta, Germania, da Johann Josef
Keller e Jacob Knappich. Inizialmente l'azienda si focalizzava su luci
stradali e domestiche ma ben presto KUKA cominciò a concentrarsi su altri
prodotti (macchinari e soluzioni di saldatura; grandi container) diventando
nel 1966 il leader di mercato europeo di veicoli comunali. Nel 1973 KUKA
inventò il primo robot industriale al mondo, FAMULUS.² A quel tempo la
compagnia apparteneva al gruppo Quandt. Tuttavia nel 1980 la famiglia
Quandt si ritirò e fu istituita una società per azioni. Nel 1995 l'azienda
si divise fra KUKA Robotics Corporation e KUKA Schweißanlagen GmbH (oggi
KUKA Systems GmbH). Oggi, KUKA si concentra su soluzioni all`avanguardia
per l'automazione dei processi manufatturieri industriali. L'azienda
appartiene alla quotata in borsa KUKA AG (precedentemente IWKA Group).

Cronologia

- 1971 – Prima linea di trasferimento di saldatura europea costruita per
  Daimler-Benz.
- 1973 – KUKA costruisce FAMULUS, il primo robot industriale al mondo con
  sei assi comandati in modo elettromeccanico.
- 1976 – IR 6/60 – Un tipo di robot completamente nuovo con sei assi
  elettromeccanicamente comandati e un polso controbilanciato.
- 1989 – Viene sviluppata una nuova generazione di robot industriali –
  motori di trazione senza spazzole con una minor manutenzione e una
  maggior disponibilità tecnica.
- 2007 – KUKA "Titan" – Attualmente il più grande e più forte robot con sei
  assi. Entra a far parte del libro dei Guinness dei primati³ .
- 2010 – Come unico robot della famiglia, la serie KR QUANTEC copre
  completamente i carichi di lavoro da 90 kg fino a 300 kg con, per la
  prima volta, una portata fino a 3100 mm.
- 2012 – Viene lanciata a nuova serie KR AGILUS.
- 2014 - Lancio del nuovo modello Lbr iiwa che consente le prime
  applicazioni di collaborazione uomo-robot.
- 2014 - Lancio della serie Fortec.

Dati aziendali

La sede centrale si trova ad Augusta, Germania. KUKA impiega più di 3150
dipendenti (30.09.2012). I clienti dell`azienda si trovano soprattutto nel
settore dell`automazione industriale, ma sono in aumento anche clienti in
altri settori (industria generale).

Fatturato consolidato (KUKA AG):

- 1.286 Mln. Euro (2007)
- 1.266 Mln. Euro (2008)
- 902 Mln. Euro (2009)
- 1.078 Mln. Euro (2010)
- 1.435 Mln. Euro (2011)
- 1.739 Mln. Euro (2012)
- 1.775 Mln. Euro (2013)
- 2.096 Mln. Euro (2014)

Robot KUKA nella cultura di massa

Robot KUKA hanno fatto apparizione in diverse pellicole di Hollywood. Nel
film di James Bond "La morte può attendere", in una scena raffigurante un
palazzo di ghiaccio in Islanda, l'agente NSA Jinx (Halle Berry) viene
minacciato da dei robot che praticano la saldatura laser. Nel film diretto
da Ron Howard "Il codice da Vinci", un robot KUKA consegna al personaggio
Robert Langdon, interpretato da Tom Hanks, un contenitore contenente un
messaggio criptato. Nel 2001 KUKA ha sviluppato Robcoaster, il primo robot
industriale al mondo in grado di portare un passeggero. Dei sedili di
montagne russe vengono attaccati al braccio robotico che compie una
sequenza di movimenti, simili alle montagne russe, tramite una serie di
manovre programmabili. Vi è inoltre la possibilità che i passeggeri possano
loro stessi programmare i movimenti. Nel 2007 KUKA ha introdotto un
simulatore basato sul Robocoaster⁴ . Dal 2010 il parco divertimenti della
Universal, Isole di avventure, in Orlando, Florida utilizza la tecnologia
del braccio robotico di KUKA in una sua attrazione, Harry Potter e il
viaggio proibito. I sedili sono montati su dei bracci robotici che sono a
loro volta montati su un binario. Questo permette ai bracci di muoversi
lungo l'attrazione mentre eseguono i loro movimenti in sincronia con i
diversi elementi della corsa (oggetti di scena animati, superfici
proiettate, ecc.)⁵ ⁶ ⁷ ⁸

Note

[1] Geschäftsbericht 2014
[2] Company history located on the KUKA Robotics Homepage
[3] Guinness World Records Ltd. (Hrsg.): Guinness World Records 2007.
  Bibliographic Institute, Mannheim, 2007. ISBN 978-3411140770
[4] "KUKA Entertainment 4D Simulator". Retrieved 2008-01-11.
[5] Harry Potter World Orlando (March 22, 2010), ""Harry Potter and the
  Forbidden Journey" Attraction Details", Harry Potter World Orlando. URL
  consultato il 29 giugno 2010.
[6] Kuka Entertainment, Kuka Entertainment - Robocoaster, Kuka
  Entertainment. URL consultato il 29 giugno 2010.
[7] Kuka Industrial Robots, Kuka Industrial Robots - Robocoaster, Kuka
  Industrial Robots. URL consultato il 29 giugno 2010.
[8] Robocoaster (March 22, 2010), Large & Theme Park Solutions,
  Robocoaster. URL consultato il 29 giugno 2010.

Altri progetti

- Wikimedia Commons contiene immagini o altri file su KUKA

Collegamenti esterni

- Sito ufficiale, kuka.com.

Controllo industriale

Il controllo industriale¹ è l'applicazione della teoria del controllo
automatico all'ambito dei processi industriali.

I processi industriali coinvolti nell'azione di controllo possono essere di
vario tipo, ad esempio può essere richiesto il controllo delle
apparecchiature di un impianto chimico, dei sistemi di sicurezza
industriale, di una centrale elettronucleare, oppure di sistemi per
l'abbattimento degli inquinanti.

Obiettivi del controllo

Il controllo di un processo industriale in genere si prefigge i seguenti
scopi:

- Sicurezza per le persone: il controllo di un sistema abbassa le
  possibilità che si verifichino eventi che arrechino danno alle persone,
  in quanto l'azione di controllo mantiene il sistema entro un certo
  intervallo di condizioni operative sicure. Un esempio concreto è dato dal
  controllo di una centrale elettronucleare.
- Sicurezza ambientale: il controllo può essere svolto nel caso in cui ci
  sia il rischio di emissioni inquinanti o altri fattori nocivi per
  l'ambiente. Un esempio è il controllo dell'emissione di gas serra da un
  impianto chimico.
- Profitto: il controllo ha anche lo scopo di mantenere il funzionamento
  del sistema entro un intervallo di condizioni vantaggiose dal punto di
  vista economico o dal punto di vista delle prestazioni. Un esempio è il
  controllo effettuato dalla centralina del motore sul motore stesso, in
  cui si cerca di minimizzare il consumo di carburante e di aumentare le
  prestazioni dell'auto.

In genere il controllo si prefigge il raggiungimento di più obiettivi
contemporaneamente, anche se per alcuni sistemi un obiettivo può essere
primario rispetto agli altri, come negli esempi descritti in precedenza.

Regolazione

Con lo studio del tempo di reazione, del movimento, della risposta in
uscita del sistema, si ottengono dei parametri che permettono di "regolare"
la risposta con una retroazione o controreazione e quindi si andrà a
variare anche l'ingresso per modularne l'uscita.

L'applicazione di questo studio attraverso sensori, attuatori, comandi,
controllori, dà origine a quella che in ingegneria si chiama "regolazione".

Nelle automazioni, nel condizionamento, nel riscaldamento si applica la
teoria dei controlli e quindi si fa la regolazione.

Nell'ingegneria termica e del condizionamento, la regolazione è
fondamentale e può far risparmiare dal 30 al 60% dei consumi, per tutta la
vita dell'impianto, ma è importantissimo che gli impianti nascano già con
l'idea della regolazione.

Strumentazione di controllo

Gli strumenti per il controllo automatico includono, tra gli altri:
misuratori, regolatori, attuatori, trasduttori.

Il controllo può avvenire con strumentazione pneumatica o elettronica.

La normativa

La legge n. 10 del 1991 e il DPR n. 412, per impianti di una certa potenza,
obbligano la progettazione e la realizzazione della regolazione negli
impianti termici.

Note

[1] Spesso il termine "Controllo dei processi" viene utilizzato per
  identificare l'ambito del controllo industriale.

Voci correlate

- Controllo automatico
- Strumentazione di controllo
- Programmable logic controller

Collegamenti esterni

- The Michigan Chemical Engineering Process Dynamics and Controls Open
  Textbook, controls.engin.umich.edu.

Risposta in frequenza

In teoria dei sistemi dinamici, la risposta in frequenza o risposta
armonica di un sistema dinamico è la descrizione della sua uscita (una
funzione del tempo) utilizzando come variabile la frequenza invece che il
tempo (ovvero nel dominio della frequenza). Da un punto di vista matematico
la descrizione in frequenza di un sistema dinamico avviene tramite il
formalismo della rappresentazione spettrale dei segnali.

L'analisi in frequenza del comportamento di un sistema viene svolta molto
spesso quando si ha a che fare con sistemi lineari (in configurazione
stabile), i quali hanno la fondamentale proprietà di rispondere ad un input
puramente sinusoidale con un'uscita della stessa frequenza, ovvero
restituiscono la medesima sinusoide in ingresso sfasata e moltiplicata per
un fattore scalare. Se il sistema è un sistema dinamico lineare stazionario
(LTI) tale fattore moltiplicativo non varia nel tempo; per tale motivo la
risposta in frequenza di sistemi LTI viene caratterizzata completamente
dalla risposta all'impulso, cioè dall'uscita del sistema quando in ingresso
vi è un solo impulso che contiene tutte le frequenze, generalmente un
impulso a delta di Dirac. La risposta in frequenza è in tal caso
esplicitata dalla funzione di trasferimento (definita come la trasformata
di Laplace della risposta all'impulso a delta di Dirac).

In elettronica e telecomunicazioni sono molti i dispositivi utilizzati per
produrre una particolare risposta in frequenza; tra le applicazioni più
comuni vi sono i filtri elettrici, elettronici o ottici. Si tratta di
circuiti in grado di elaborare il segnale privandolo di alcune sue
componenti in frequenza, spesso per ripulirlo da disturbi. Sono detti
filtri passa basso, passa banda o passa alto grazie alla loro peculiarità
di lasciar passare frequenza basse, intermedie o elevate. Nel caso di
filtri attivi, la risposta in frequenza si usa per progettare filtri con
particolari caratteristiche. Infine, lo studio in frequenza è
indispensabile nell'analisi e sintesi degli amplificatori lineari e negli
amplificatore a retroazione.

Formalismo nel dominio delle frequenze

Sono stati sviluppati molti strumenti matematici che consentono di
descrivere un segnale come sovrapposizione delle frequenze elementari che
lo compongono. Nel caso si tratti di un segnale periodico s(t), è possibile
una scrittura in serie di potenze nota come sviluppo in serie di Fourier
del segnale:

s(t)=A_0+Σ_{n=1}^\infty (A_n\cos (n ω_0 t) +B_n \sin (n ω₀ ₜ₎₎

dove i valori di A₀, Aₙ e Bₙ sono dati da:

A_0=\frac{1}{T} ∫_{0}^T{s(t)dt}
A_n=\frac{2}{T} ∫_{0}^T{s(t)\cos (nω₀ₜ})dt
B_n=\frac{2}{T} ∫_{0}^T{s(t)\sin (nω₀ₜ})dt

Per segnali non periodici si deve ricorrere ad una rappresentazione
integrale; tra le più comuni vi è la trasformata di Fourier, anche se in
molti testi si ricorre all'utilizzo della trasformata di Laplace, che rende
possibile il superamento di alcune difficoltà matematiche che si presentano
con la trasformata di Fourier. La trasformata di Laplace L[f(t)](s) (nella
variabile s = σ+ i ω) di una funzione f(t) è:

L[f(t)]=F(s)=∫_{0}^{\infty }e^{-st}f(t)dt

In generale questo formalismo conduce a notevoli semplificazioni nei
calcoli; infatti, nel dominio della frequenza a operazioni come la
convoluzione, la derivazione o l'integrazione di funzioni nel tempo
corrispondono operazioni di tipo algebrico tra le relative trasformate
(rispettivamente il prodotto delle trasformate, la moltiplicazione per s e
la divisione per s).

Sistemi lineari

I sistemi lineari sono caratterizzati dal fatto che la loro risposta ad un
segnale periodico in input, avente una certa frequenza, ha la stessa forma
e la stessa frequenza dell'input: sollecitando una configurazione stabile
con una perturbazione periodica il sistema si troverà in uno stato
oscillante con la stessa frequenza ma con fase e ampiezza diverse da quelle
dell'oscillazione in ingresso.

Esplicitamente, dato un sistema lineare stabile, in cui il legame tra
ingresso ed uscita è rappresentato da una equazione differenziale lineare,
applicando un segnale sinusoidale u(t)=U_0 \sin (ωt) di ampiezza U₀ e
frequenza ω si ha che, dopo che è svanito il periodo transitorio, il
segnale in uscita risulta sinusoidale e della stessa frequenza di quello
d'ingresso, ovvero del tipo y(t)=Y_0 \sin (ωt+ϕ). L'ampiezza Y₀ e lo
sfasamento ϕ sono funzioni della frequenza. Il rapporto delle ampiezze Y_0
(ω) / X_0 (ω) è detto guadagno per la frequenza ω.

Un sistema lineare di n stati x \in \R ⁿ, m input u \in \R ^m e q uscite y
\in \R ^q viene descritto da un'equazione del tipo:

\dot x(t) = A x(t)+B u(t)
y(t) = C x(t)+D u(t)

Il sistema è detto stabile se tutti gli autovalori di A hanno parte reale
negativa. Si dimostra che se l'ingresso è un'oscillazione del tipo u= \bar
u e^{j ωt} , con \bar u \in \R ⁿ un vettore arbitrario, allora lasciando
evolvere il sistema l'uscita ha la forma:

\lim _{t →\infty } y(t)= [D+C(j ωI-A)^{-1} B] \bar u e^{jωt}

dove [D+C(jωI-A)^{-1} B], con I la matrice identità, è il fattore
(guadagno) per il quale è stato amplificato l'ingresso. Si vede in questo
modo che ad un'oscillazione complessa corrisponde una risposta oscillante
della stessa frequenza.

Di particolare importanza sono i sistemi lineari stazionari, la cui la
risposta non cambia nel tempo, e viene completamente descritta in frequenza
dalla funzione di trasferimento.

Sistemi LTI

Detto x(t) un segnale in ingresso ad un sistema LTI e y la sua risposta,
l'equazione che governa il sistema può essere scritta come:

a_n \frac{dⁿ}{dtⁿ} y(t) + a_{n-1} \frac{d^{n-1}}{dt^{n-1}} y(t) + …+ a_0
y(t) = b_m \frac{d^m}{dt^m} x(t) + b_{m-1} \frac{d^{m-1}}{dt^{m-1}} x(t) +
…+ b₀ ₓ ₍ₜ₎

e la funzione di trasferimento è data da:

k(j ω) = \frac{b_m (j ω)^m + b_{m-1} (j ω)^{m-1} + …+ b₀}{a_n (j ω)^n +
a_{n-1} (j ω)^{n-1} + …+ a₀}

Si tratta della trasformata di Laplace della risposta impulsiva h, ovvero:

k(j ω) = ∫_{-\infty }^{\infty } e^{-iωt} ·h(t) dt
h(t) = \frac{1}{2 π} ∫_{-\infty }^{\infty } k(j ω) e^{iωt} dω

La risposta impulsiva e quella in frequenza sono dunque una la trasformata
dell'altra.

Esempio

Si consideri un circuito elettrico costituito da una resistenza ed una
induttanza posti in serie. L'equazione che lo caratterizza è:

L\frac{di}{dt} +Ri=E

Effettuando la trasformata:

L[si(s)-i(0+)]+Ri(s)=\frac{E}{s}

e risolvendo per i(s), posto i(0+)=0, risulta:

i(s)=\frac{E}{s(sL+R)}

la cui antitrasformata è:

i=\frac{E}{R} (1-e^{-\frac{Rt}{L} })

Bibliografia

- (EN) Luther, Arch C.; Inglis, Andrew F. Video engineering, McGraw-Hill,
  1999. ISBN 0-07-135017-9
- (EN) Stark, Scott Hunter. Live Sound Reinforcement, Vallejo, California,
  Artistpro.com, 1996–2002. ISBN 0-918371-07-4
- (EN) Billings S.A. "Nonlinear System Identification: NARMAX Methods in
  the Time, Frequency, and Spatio-Temporal Domains". Wiley, 2013

Voci correlate

- Diagramma di Bode
- Dominio della frequenza
- Funzione di trasferimento
- Rappresentazione spettrale dei segnali
- Risposta impulsiva
- Sistema dinamico lineare
- Sistema dinamico lineare stazionario
- Trasformata di Laplace

Collegamenti esterni

- (EN) Andrew Packard - Frequency Response for Linear Systems (PDF),
  jagger.berkeley.edu.
- (EN) University of Michigan - Frequency Response Analysis and Design
  Tutorial, engin.umich.edu.
- (EN) Smith, Julius O. III - Introduction to Digital Filters with Audio
  Applications (Frequency Response)

Risposta libera

Nella teoria dei sistemi dinamici, la risposta libera o risposta ad
ingresso nullo di un sistema dinamico, anche detta "risposta libera nello
stato" in quanto interessa le variabili di stato del sistema, è la sua
risposta quando l'ingresso è nullo, in modo che il comportamento del
sistema dipende soltanto dalle condizioni iniziali. Nei sistemi lineari il
principio di sovrapposizione stabilisce in particolare che è possibile
scomporre l'uscita come la somma della risposta libera più la risposta
forzata.

Sistemi LTI

Si consideri un sistema dinamico lineare stazionario:

\left {\begin{matrix} \frac{d\vec{x} (t)}{dt} =A\vec{x} (t)+B\vec{u} (t)
\vec{y} (t)=C\vec{x} (t)+D\vec{u} (t)\end{matrix} \right .

in cui A, B, C e D sono matrici costanti caratteristiche del modello
matematico del sistema studiato, \vec{x} (t) \in \R ⁿ rappresenta il
vettore delle variabili di stato, \vec{u} (t) \in \R ^q il vettore degli
ingressi e \vec{y} (t) \in \R ^p il vettore delle uscite. La matrice A ha
dimensione n \times n, B ha dimensione n \times q, C ha dimensione p \times
n e D ha dimensione p \times q.

Grazie al principio di sovrapposizione è possibile scomporre la risposta di
un sistema dinamico lineare come la somma della risposta libera \vec{y} _L
più la risposta forzata \vec{y} _F:

\vec{y} (t) = \vec{y} _L(t) + \vec{y} _F(t)

Nel dominio della trasformata di Laplace:

L[\vec{y} (t)](s) = Y(s) = Y_L(s) + Y_F(s) = F(s) \vec{x} (0) + G(s)U(s)

dove U è la trasformata di u e le matrici F e G sono date da:

F(s) = C(sI - A)^{-1} \qquad G(s) = C(sI - A)^{-1}B + D

Il termine Y_L è lineare rispetto a \vec{x} (0) e rappresenta la risposta
del sistema quando l'ingresso è nullo: lo stato del sistema dipende quindi
linearmente dallo stato iniziale \vec{x} (0). Il termine Y_F è la risposta
del sistema quando lo stato iniziale è nullo, ed è pertanto una funzione
lineare solo dell'ingresso u. I denota la matrice identità e (sI - A)^{-1}
indica l'inversa di (sI - A).

Nell'ipotesi che la matrice A sia diagonalizzabile con autovalori reali la
risposta libera nello stato risulta:

\vec{x} _{l}(t)=Pe^{Λ(t-t_{0})}P^{-1}\vec{x} (t_{0})

dove le colonne della matrice P sono gli autovettori \vec{v} _1,\vec{v}
_2,...,\vec{v} ₙ di A relativi agli autovalori distinti λ_1,λ_2,...,λₙ;
P^{-1} indica l'inversa di P e e^{Λ(t-t_{0})} l'esponenziale della matrice
diagonale degli autovalori.

Posto t₀₌₀ si può scrivere:

\vec{x} _{l}(t)=\left (\begin{array}{cccc} v_{11} & v_{21} & ⋯& v_{n1}
v_{12} & v_{22} & ⋯& v_{n2} \vdots & \vdots & \vdots & \vdots v_{1n} &
v_{2n} & ⋯& v_{nn} \end{array} \right ) \left (\begin{array}{cccc} e^{λ_1t}
& 0 & ⋯& 0 0 & e^{λ_2t} & ⋯& 0 \vdots & \vdots & \vdots & \vdots 0 & 0 & ⋯&
e^{λ_nt} \end{array} \right ) \left (\begin{array}{c} α_1(0) α_2(0) \vdots
α_n(0) \end{array} \right )

dove α_i(0) è il prodotto della riga i-esima della matrice P^{-1} per lo
stato iniziale x(0). Sviluppando i prodotti matriciali si ottiene:

\vec{x} _l(t)=Σ_{i=1}^nα_i(0)e^{λ_it}\vec{v} _i

La funzione α_i(0)e^{λ_i t}\vec{v} _i viene detta modo aperiodico i-esimo.
Un modo si dice eccitato se compare nella risposta libera nello stato.

La risposta libera si può quindi esprimere come la sovrapposizione di più
modi. In particolare, si nota che nell'ipotesi che lo stato iniziale
\vec{x} (0) coincide con l'autovettore α_i(0)\vec{v} _i allora si ha:

P^{-1}\vec{x} (0)=P^{-1}{α}_i(0)\vec{v} _i=\left (\begin{array}{c} 0 \vdots
0 {α}_i(0) 0 \vdots 0 \end{array} \right )

e quindi soltanto il modo i-esimo risulta eccitato. Pertanto la traiettoria
è la retta individuata dall'autovettore v_i

Voci correlate

- Analisi dei sistemi dinamici
- Diagonalizzabilità
- Funzione di trasferimento
- Principio di sovrapposizione
- Risposta impulsiva
- Risposta in frequenza
- Sistema dinamico lineare
- Sistema dinamico lineare stazionario
- Spazio di stato

Collegamenti esterni

- Michele Basso, Luigi Chisci e Paola Falugi - Fondamenti di Automatica
  (PDF), dsi.unifi.it.

Controllabilità

Nell'analisi dei sistemi dinamici, la controllabilità di un sistema
dinamico è la sua capacità di raggiungere qualsiasi punto dello spazio
delle configurazioni mediante un qualche insieme di manipolazioni. La
definizione rigorosa dipende dal contesto in cui viene presentato il
problema dinamico; generalmente si riferisce alla capacità di un ingresso
(controllo esterno) di agire sullo stato del sistema in modo tale da
condurlo da un'arbitraria configurazione iniziale ad una arbitraria
configurazione finale in un intervallo di tempo finito. Il concetto duale a
quello di controllabilità è l'osservabilità, che riguarda la possibilità di
studiare lo stato del sistema a partire dalle uscite.

Si parla nello specifico di controllabilità per riferirsi alla capacità di
portare il sistema da uno stato qualsiasi all'origine, e di raggiungibilità
per riferirsi, al contrario, alla possibilità di controllare il sistema una
volta che esso ha raggiunto un certo stato iniziale, ovvero di poter
raggiungere qualsiasi stato a partire dall'origine. Nei sistemi LTI le due
proprietà si implicano a vicenda.¹

Gli autovalori della parte non raggiungibile di un sistema non compaiono
come poli della funzione di trasferimento, e in particolare si dimostra che
un sistema è controllabile se e solo se tutti gli autovalori della sua
parte non raggiungibile sono nulli. La raggiungibilità implica dunque la
controllabilità, ma non vale il viceversa.

Si tratta di proprietà introdotte per valutare le condizioni operative
(come il suo stato o la sua uscita) in cui è possibile portare un sistema
dinamico, specialmente se è lineare, applicando un controllo al sistema.
Una nozione più debole di controllabilità è quella di stabilizzabilità: un
sistema è stabilizzabile se tutti gli stati (variabili di stato) non
controllabili possono essere resi stabili.

Sistemi dinamici lineari

Dato un sistema lineare:

\dot{x} (t) = A(t) x(t) + B(t) u(t)
y(t) = C(t) x(t) + D(t) u(t)

esiste un controllo u dallo stato x₀ al tempo t₀ allo stato x₁ al tempo t₁
> t₀ se e solo se x_1 - ϕ(t₀,t₁₎ₓ₀ è nello spazio delle colonne di:

W(t_0,t_1) = ∫_{t_0}^{t_1} ϕ(t_0,t)B(t)B(t)^{T}ϕ(t₀,t)^{T} dt

dove ϕ è la matrice di transizione di stato e W(t₀,t₁₎ è la matrice
gramiana di controllabilità.

Infatti, se η₀ è la soluzione di:

W(t_0,t_1)η= x_1 - ϕ(t₀,t₁₎ₓ₀

allora il controllo dato da:

u(t) = -B(t)^{T}ϕ(t_0,t)^{T}η₀

realizza il trasferimento richiesto.

Si nota che W in questo modo è simmetrica, semidefinita positiva e soddisfa
le equazioni:

\frac{d}{dt} W(t,t_1) = A(t)W(t,t_1)+W(t,t_1)A(t)^{T}-B(t)B(t)^{T},
W(t₁,t₁₎ ₌ ₀
W(t_0,t_1) = W(t_0,t) + ϕ(t_0,t)W(t,t_1)ϕ(t₀,t)^{T}

Sistemi dinamici lineari stazionari

Dato il sistema lineare stazionario (LTI):

\dot{x} (t) = A x(t) + B u(t)
y(t) = C x(t) + D u(t)

dove x ha dimensione n \times 1 ed è il vettore di stato, y ha dimensione m
\times 1 ed è l'uscita, u ha dimensione r \times 1 ed è l'ingresso
(controllo), A ha dimensione n \times n, B ha dimensione n \times r, C ha
dimensione m \times n e D ha dimensione m \times r.

La matrice di controllabilità ha dimensione n \times nr ed ha la forma:

R = \begin{bmatrix} B & AB & A^{2}B & ...& A^{n-1}B\end{bmatrix}

Il sistema LTI è controllabile se la matrice ha tutte le colonne (o tutte
le righe) linearmente indipendenti (ha rango n).

In modo equivalente, il sistema:

\dot{x} (t) = A x(t) + B u(t)

è controllabile se per ogni coppia di stati iniziale x₀₌ₓ₍₀₎ e finale x_f
esistono un tempo T < \infty e un ingresso u tali che:

x(T)=e^{At}x_0 + ∫_0^T e^{A(t-τ)}B u(τ) dτ= x_f

Sistemi lineari stazionari discreti

Per un sistema a tempo discreto (k\in \mathbb{Z} ) l'equazione di stato ha
la forma:

\textbf{x} (k+1) = A\textbf{x} (k) + B\textbf{u} (k)

dove A è una matrice n \times n e B ha dimensione n \times r matrix (u sono
r input in un vettore colonna r \times 1). Similmente al caso continuo, se
la matrice n \times nr data da:

C = \begin{bmatrix} B & AB & A^{2}B & ⋯& A^{n-1}B\end{bmatrix}

ha rango massimo (pari ad n) il sistema è controllabile.

L'insieme degli stati raggiungibili è dato dall'immagine Im(C) di C, mentre
l'insieme degli stati controllabili è dato da A^{-n} Im(C). Se C ha rango
massimo i due insiemi coincidono.

Infatti, preso lo stato \textbf{x} (0) al tempo iniziale k=0, l'equazione
di stato fornisce:

\textbf{x} (1) = A\textbf{x} (0) + B\textbf{u} (0)

allora:

\textbf{x} (2) = A\textbf{x} (1) + B\textbf{u} (1)= A^2\textbf{x}
(0)+AB\textbf{u} (0)+B\textbf{u} (1)

e procedendo in tal modo (ovvero effettuando ricorsivamente la sostituzione
del vettore \textbf{x} delle variabili di stato al tempo precedente) si
ottiene una forma del tipo:

\textbf{x} (n)=B\textbf{u} (n-1) + AB\textbf{u} (n-2) + ⋯+
A^{n-1}B\textbf{u} (0) + A^n\textbf{x} (0)

o in modo equivalente:

\textbf{x} (n)-A^n\textbf{x} (0)= [B AB ⋯ A^{n-1}B] [\textbf{u} ^T(n-1)
\textbf{u} ^T(n-2) ⋯ \textbf{u} ^T(0)]^T.

Assegnando un valore a \textbf{x} (n), l'equazione può essere sempre
risolta per un vettore di vettori di controllo \textbf{u} ^T(n-i) se e
soltanto se la matrice delle matrici B AB ⋯ A^{n-1}B ha rango massimo.

Sistemi non lineari

Note

[1] Gustavo Belforte - Controllabilità ed Osservabilità

Bibliografia

- (EN) Katsuhiko Ogata, Modern Control Engineering, 3rd, Upper Saddle
  River, NJ, Prentice-Hall, 1997, ISBN 0-13-227307-1.
- (EN) Roger W. Brockett, Finite Dimensional Linear Systems, John Wiley &
  Sons, 1970, ISBN 978-0-471-10585-5.
- (EN) Jean-Pierre Aubin, Viability Theory, Birkhauser, 1991, ISBN
  0-8176-3571-8.
- (EN) Jan Polderman, Jan Willems, Introduction to Mathematical Systems
  Theory: A Behavioral Approach, 1st, New York, Springer Verlag, 1998, ISBN
  0-387-98266-3.
- (EN) Brian D.O. Anderson e John B. Moore, Optimal Control: Linear
  Quadratic Methods, Englewood Cliffs, NJ, Prentice Hall, 1990, ISBN
  978-0-13-638560-8.

Voci correlate

- Attrattore
- Controllo automatico
- Equazione differenziale
- Matrice di transizione di stato
- Matrice gramiana di controllabilità
- Osservabilità
- Sistema dinamico
- Sistema dinamico lineare stazionario
- Spazio di stato
- Spazio delle fasi
- Teoria ergodica
- Teoria della stabilità
- Variabile di stato

Osservabilità

Nella teoria del controllo, la proprietà di osservabilità di un sistema
dinamico determina la possibilità di risalire allo stato del sistema a
partire dalla conoscenza delle sue uscite. Osservabilità e controllabilità
sono generalmente due caratteristiche legate fra loro; in particolare, nei
sistemi dinamici lineari stazionari sono matematicamente duali.

Sistemi dinamici lineari

Un sistema si dice osservabile se, per qualunque combinazione possibile di
stati e ingressi, lo stato corrente può essere determinato in tempo finito
attraverso le uscite del sistema. In altri termini, se un sistema è
completamente osservabile significa che lo spazio delle fasi è
sufficientemente grande da contenere tutti gli stati possibili.

Per i sistemi dinamici lineari tempo invarianti:

\dot{x} (t) = A x(t) + B u(t)
y(t) = C x(t)

se lo stato x ha dimensione n ed il rango della matrice di osservabilità:

\begin{bmatrix} C CA CA^2 \vdots CA^{n-1} \end{bmatrix}

è pieno, ovvero uguale a n, il sistema è osservabile. Si nota che, in altri
termini, se n righe sono linearmente indipendenti allora ognuno degli n
stati è osservabile attraverso combinazioni lineari delle variabili di
uscita y(k). Uno modulo progettato per misurare lo stato di un sistema
dalla misurazione delle uscite viene chiamato un osservatore di stato o
semplicemente "osservatore" per quel sistema.

Si definisce inoltre l'indice di osservabilità di un sistema LTI come il
più piccolo numero naturale v per cui vale rank{(O_v)} = rank{(O_{v+1})},
dove:

O_v= [ C CA CA^2 … CA^{v-1} ]^T

Per i sistemi LTI osservabilità e controllabilità sono proprietà duali;
nello specifico si definisce il sistema duale:

\dot{x} (t) = A^T x(t) + C u(t)
y(t) = B x(t)

e si verifica che il sistema originale è completamente osservabile se e
solo se il sistema duale è completamente controllabile, ed è completamente
controllabile se e solo se il sistema duale è completamente osservabile.

Bibliografia

- (EN) Roger W. Brockett, Finite Dimensional Linear Systems, John Wiley &
  Sons, 1970, ISBN 978-0-471-10585-5.

Voci correlate

- Controllabilità
- Sistema dinamico
- Sistema dinamico lineare
- Sistema dinamico lineare stazionario

Collegamenti esterni

- (EN) Stanley G.M. and Mah, R.S.H., "Observability and Redundancy in
  Process Data Estimation, Chem. Engng. Sci. 36, 259 (1981) (PDF),
  gregstanleyandassociates.com.
- (EN) Stanley G.M., and Mah R.S.H., "Observability and Redundancy
  Classification in Process Networks", Chem. Engng. Sci. 36, 1941 (1981)
  (PDF), gregstanleyandassociates.com.
- (EN) Observability su PlanetMath
- (EN) Control Systems - Controllability and Observability (PDF),
  faculty.uml.edu.

Spazio delle fasi

Nella teoria dei sistemi dinamici si chiama spazio delle fasi di un sistema
lo spazio i cui punti rappresentano univocamente tutti e soli i possibili
stati del sistema. Nella meccanica classica lo spazio delle fasi di solito
rappresenta tutte le possibili posizioni e velocità di ogni punto
materiale.

In generale lo spazio delle fasi è una varietà differenziabile che ha come
dimensione due volte il numero di gradi di libertà del sistema. Lo spazio
delle fasi di un pendolo semplice ad esempio è un cilindro: c'è un grado di
libertà per la variabile angolare che individua la posizione e che si muove
su un cerchio e un grado di libertà per la velocità che a priori può
variare lungo una retta illimitata.

L'evoluzione del sistema dinamico continuo può essere rappresentata da una
curva nello spazio delle fasi. Se il sistema dinamico è discreto la sua
evoluzione appare nello spazio delle fasi come una successione di punti.

In meccanica hamiltoniana lo spazio delle fasi (chiamato anche spazio degli
stati, per non creare confusione di termini) è lo spazio rappresentativo
del moto del sistema formato dalle 2n coordinate q_1, …, q_n, p_1, …, pₙ
dove p_i sono i momenti coniugati alle coordinate generalizzate q_i.

Voci correlate

- Sistema dinamico
- Grado di libertà (meccanica classica)
- Meccanica hamiltoniana
- Meccanica lagrangiana
- Spazio delle configurazioni

Grado di libertà (meccanica classica)

In fisica il numero di gradi di libertà di un punto materiale è il numero
di variabili indipendenti necessarie per determinare univocamente la sua
posizione nello spazio (coordinate del moto). In effetti il numero di gradi
di libertà di un sistema è per definizione pari a quello del numero di
coordinate generalizzate necessario a descrivere il suo moto. Un punto
libero di muoversi nello spazio a 3 dimensioni ha quindi 3 gradi di
libertà; se il punto deve muoversi su un piano o una superficie (2
dimensioni) ha 2 gradi di libertà; se deve muoversi lungo una retta o una
curva (1 dimensione) ha 1 grado di libertà. Esistono molti esempi di punti
soggetti ad uno o più vincoli:

- una massa attaccata ad un pendolo può muoversi lungo la superficie di una
  sfera, quindi ha 2 gradi di libertà
- una massa poggiata su un piano e attaccata ad un punto fisso ha 1 grado
  di libertà perché può muoversi solo lungo una circonferenza

e così via.

Queste considerazioni si possono estendere ai sistemi di n punti materiali:
se tutti i punti sono liberi di muoversi nello spazio, il sistema avrà 3n
gradi di libertà. Se sono presenti f vincoli, i gradi di libertà scendono a
3n - f.

Esempio - gradi di libertà di un corpo rigido

Come esempio, si può dimostrare che un corpo rigido ha 6 gradi di libertà,
3 di tipo traslazionale (rispetto ai 3 assi cartesiani x-y-z) e tre di tipo
rotazionale (sempre rispetto ai 3 assi cartesiani).

Per determinare univocamente la posizione di un corpo rigido basta
conoscere la posizione di 3 punti A, B, C non allineati. Infatti ogni altro
punto D si può determinare nel modo seguente: considerato il triangolo ACD,
la base AC è fissata; il punto D ha distanza fissata da A e C, e ha una
certa distanza da B. Ruotando il triangolo ACD, si perviene alla posizione
D' che si trova alla stessa distanza di D da B. Tuttavia, D' si trova dalla
parte opposta rispetto al piano ABC, quindi esiste solo un punto D che
abbia una distanza fissata da A, B, e C e che si trovi da un lato fissato
del piano ABC.

Ora, è chiaro che il sistema di punti ABC ha 9 - f gradi di libertà, dove f
è il numero di vincoli. Poiché le distanze AB, BC e AC devono rimanere
costanti, ne consegue che f = 3 e quindi il corpo ha 6 gradi di libertà.

Voci correlate

- 6dof
- Coordinate generalizzate
- Spazio delle configurazioni
- Formula di Grubler
- Formula di Kutzbach

6dof

6DOF è l'acronimo di sei gradi di libertà in inglese (Six Degrees Of
Freedom) e si riferisce al movimento nello spazio tridimensionale, ovvero
l'abilità di muoversi liberamente avanti/indietro, su/giù, sinistra/destra
(traslare in tre assi perpendicolari) combinati con rotazione lungo tre
assi perpendicolari (imbardata, beccheggio, rollio).

Poiché il movimento lungo ognuno di questi assi è indipendente quanto per
gli assi di traslazione che per gli assi di rotazione, il movimento ha
quindi sei gradi di libertà.

I bracci robotici sono spesso classificati per i loro gradi di libertà
(tipicamente raggiungendo più di sei gradi). Questo numero si riferisce al
numero di giunture a singolo asse nel braccio, dove un numero più alto
indica una maggiore flessibilità e precisione nel posizionare un utensile.
Questo è un esempio pratico, in contrasto con la definizione astratta di
gradi di libertà che misura la capacità aggregata di posizionamento di un
sistema.

Videogiochi

Sei gradi di libertà è anche un tipo di videogioco in cui non vi è gravità,
e i giocatori sono liberi di muoversi in qualsiasi direzione
tridimensionale. È impiegato in giochi come Descent e i suoi seguiti, e
meno estesamente nei giochi Homeworld 1 e 2. Altri videogiochi come Aquanox
invece, sembrano offrire un gioco a 6 gradi di libertà, ma in realtà è a 5
gradi di libertà (non è possibile, ad esempio, picchiare su/giù per
capovolgersi). In molti videogiochi viene scelta questa variante, per
semplificarne la giocabiltà.

L'acronimo 3DOF, inteso solo come movimento e non rotazione, è a volte
utilizzato.

SCADA

Nell'ambito dei controlli automatici, l'acronimo SCADA (dall'inglese
"Supervisory Control And Data Acquisition", cioè "controllo di supervisione
e acquisizione dati") indica un sistema informatico distribuito per il
monitoraggio elettronico di sistemi fisici.

Descrizione

Tipicamente, i sistemi di tipo SCADA sono utilizzati come sistemi di
controllo in ambito industriale per il monitoraggio e controllo
infrastrutturale o di processi industriali e sono composti da:

- uno o più sensori, che effettuano misurazioni di grandezze fisiche di
  interesse sul sistema in oggetto;
- uno o più microcontrollori, che possono essere PLC o microcomputer, che,
  continuativamente o a intervalli di tempo, effettuano misurazioni tramite
  i sensori a cui sono collegati e memorizzano i valori misurati in una
  memoria locale;
- un sistema di telecomunicazione tra i microcontrollori e il supervisore.
  Può essere una rete di computer, oppure un insieme di linee seriali; può
  essere basato su cavo o su radio. Nei casi tipici sono cavi seriali
  digitali per brevi distanze, doppini di tipo telefonico a cui sono
  collegati o dei modem a bassa velocità, per medie distanze, oppure ponti
  radio o telefoni cellulari, per grandi distanze;
- un computer supervisore (es. server), che periodicamente raccoglie i dati
  dai microcontrollori, li elabora per estrarne informazioni utili,
  memorizza su disco i dati o le informazioni riassuntive, eventualmente fa
  scattare un allarme, permette di selezionare e di visualizzare su schermo
  i dati correnti e passati, eventualmente in formato grafico, ed
  eventualmente invia informazioni selezionate al sistema informativo
  aziendale.

Un sistema SCADA utilizza una rete di telecomunicazioni geografica (Wide
Area Network). Sistemi simili, ma basati su una rete di comunicazione
locale (Local Area Network) sono propriamente definiti DCS (Distributed
Control System): tipici esempi sono i sistemi di controllo e supervisione
di impianti industriali.

I sistemi DCS sono ad un livello superiore, potendo, oltre che
supervisionare, anche comandare i sistemi di automazione, cosa che ai
sistemi SCADA è invece inibita.

Sicurezza

Nel novembre 2008 è apparso un virus informatico chiamato Stuxnet che
prendeva come bersaglio i sistemi SCADA. Il virus ha usato come mezzo
trasmissivo una chiave USB e aveva il compito di contaminare il software
WinCC sviluppato dall'azienda Siemens. All'inizio del 2011 Stuxnet è uscita
sotto una nuova forma chiamata Stars.

Note

[1] Basic SCADA Animations

Voci correlate

- Acquisizione dati
- Controllo automatico

Altri progetti

- Wikimedia Commons contiene immagini o altri file su SCADA

Acquisizione dati

La locuzione acquisizione dati, sinonimo di input, si utilizza in
particolare nei sistemi di misurazione continua, in ambito di gestione
processi.

La locuzione è talvolta abbreviata in DAQ dall'inglese Data AcQuisition.

Descrizione

I dati possono essere sia di tipo digitale (es. numero di pezzi che passano
in un nastro trasportatore nell'unità di tempo) o analogica (es. velocità
di un corpo in meccanica classica, temperatura di un forno di cottura,
pressione di una camera iperbarica, ecc).

I componenti base dei sistemi di acquisizione di dati sono i sensori, il
cui scopo fondamentale è la conversione del parametro da misurare in
segnale elettrico.

Nei processi a ciclo continuo come ad esempio chimico, petrolchimico,
petrolifero, così come nella gestione di infrastrutture in movimento, ad
esempio le stazioni ferroviarie, l'acquisizione dei dati di processo
riveste un'importanza fondamentale nel controllo e nella regolazione del
processo stesso.
In questi casi i dati acquisiti convergono verso una sala di controllo
centralizzata, presidiata 24 ore su 24.

Una branca specifica dell'acquisizione dati è quella delle sale di
registrazione, dove il segnale sonoro (analogico) viene campionato su varie
frequenze, visualizzato in genere con pannelli grafici a barre, miscelato
con altri segnali, registrato.

Prima dello sviluppo dell'informatica le strumentazioni di visualizzazione
erano costituite da apparecchi elettromagnetici che reagivano al segnale
analogico proveniente dal sensore facendo muovere una lancetta in un
quadro, o una penna in un registratore continuo su carta. Oggi la gran
parte delle misure analogiche passano attraverso un processo di
digitalizzazione, in genere ottenuta mediante campionamento (rilevamento
del valore ad intervalli regolari, il più possibile ravvicinati).

Sistemi di acquisizione e trattamento dei dati

I dati acquisiti tipicamente vengono trattati, cioè analizzati, miscelati,
memorizzati, visualizzati mediante software specializzato che lavora in
elaboratori di processo e in personal computer di servizio.

- Un produttore noto per i sistemi di controllo interattivo e del relativo
  software di processo è PowerLab.
- EPICS è usato per sviluppare sistemi di acquisizione di dati di grande
  scala.
- Si possono anche sviluppare sistemi ad hoc usando un linguaggio di
  programmazione come experix, LabVIEW, Visual Basic, o C.

Voci correlate

- Digitalizzazione
- Elaborazione numerica dei segnali
- Processo di produzione industriale
- LabVIEW
- Telemetro laser

Altri progetti

- Wikimedia Commons contiene immagini o altri file su Acquisizione dati

Collegamenti esterni

- (EN) Learn Data Acquisition using Visual Basic Express 2005, emant.com.
- (EN) Acquisizione dati in applicazioni industriali e manifatturiere,
  data-acquisition.us.

Software:

- (EN) Sito ufficiale experix, software con licenza GPL
- (EN) Sito ufficiale EPICS, aps.anl.gov.
- (EN) Midas PSI software (con licenza GPL) usato in esperimenti di fisica
  nucleare e delle particelle.

Input

Input è un termine inglese con significato di "immettere" che in campo
informatico definisce una sequenza di dati o informazioni, immessi per
mezzo di una "periferica detta appunto di input" e successivamente
elaborati. Il termine, approdato in Italia con la prima informatica degli
anni sessanta indicava al contempo i dati di entrata e i supporti che li
contenevano.

Successivamente, in particolare con l'avvento delle metodologie di gestione
per processo, si è diffuso in quasi tutte le discipline, anche non
tecniche, nel senso più generale di "insieme di elementi in entrata" in un
sistema per realizzare o produrre qualcosa.

Nel linguaggio corrente, input è divenuto sinonimo di impulso o direttiva
che consenta l'avvio di qualche opera, iniziativa o azione, spesso usato
anche nella forma italianizzata di "input".

La fortuna del termine, insieme al suo opposto output, è stata la sua
sinteticità e il fatto che era molto semplice schematizzare un qualsiasi
processo (non necessariamente fisico, ma anche ad esempio decisionale) con
tre soli simboli: una freccia in entrata, un riquadro, una freccia in
uscita.

Input in informatica

Dati di input

Nei primi elaboratori il più semplice dato di input era il bit, che
conteneva un'informazione binaria: zero oppure uno. Era fornito con
l'impostazione di un interruttore (switch) o un pulsante. Successivamente
diventava un carattere quando all'elaboratore veniva connessa una tastiera;
la pressione del singolo tasto veniva convertita in una serie di bit
(inizialmente 5 (codice Baudot), poi 7 e 8 (codice ASCII)). Altro passo in
avanti fu l'avvento delle schede perforate che permettevano di introdurre
80 caratteri alla volta. Prima delle schede perforate i dati di input erano
indifferentemente istruzioni o dati di lavoro. Con l'avvento delle schede
perforate si iniziò a distinguere le istruzioni dai dati di lavoro,
soprattutto per il fatto che le istruzioni (di fatto il programma) erano
(quasi sempre) le stesse, mentre i dati di lavoro, per loro natura,
cambiavano ad ogni elaborazione. Nacque quindi il termine libreria dei
programmi, ad indicare la residenza di questo specifico tipo di input. La
residenza era un nastro magnetico, poi un disco magnetico.

Comandi e istruzioni interattive

Con l'avvento delle interfacce video, prima testuali poi grafiche, è nato
un nuovo tipo di input, il comando diretto. Quando il cursore è posizionato
su una determinata zona del video, la pressione di un tasto, il click o
doppio click del mouse o il puntamento dello stilo di un palmare, attivano
una procedura di elaborazione predeterminata, che può essere di qualunque
natura, anche molto complessa. La zona video può essere testuale (come i
classici link HTML) e può essere un'immagine ben delimitata come un
pulsante o una icona attiva. Un insieme organizzato di caselle su una o più
righe costituisce un menù di scelta delle operazioni da compiere.

Supporti, strumenti e metodi di input

Come accennato nel paragrafo precedente, per molto tempo l'input è stato
strettamente correlato al suo supporto fisico e al metodo di acquisizione.
Con l'avvento del teleprocessing (primi anni settanta) l'input inizia ad
essere fornito anche con un mezzo nuovo, la comunicazione via filo e via
radio. Le schede perforate furono sostituite gradualmente (anni ottanta)
con i floppy disk da 8 pollici, nati molti anni prima, ma fino allora usati
solo per scopi particolari. Questo per grandi volumi di input. Per piccoli
volumi e, soprattutto, per la produzione del software era già disponibile
il terminale, non più simile ad una telescrivente, ma dotato di monitor
video. Dal terminale (tuttora strumento valido per determinati lavori) si è
passati direttamente al personal computer, che può emulare il terminale, o
meglio ancora, colloquiare con un elaboratore in rete, locale o remota. Con
lo sviluppo delle applicazioni basate sul web è nato un ulteriore metodo di
gestione dell'input, attraverso i form delle pagine video.

Input in altri campi

Telecomunicazioni

In questo campo il termine input è usato per indicare le informazioni
per...

Non è raro il caso di sentire, specialmente in ambienti molto dinamici un
capo che fornisce l'input ad un collaboratore, o del collaboratore che
dice: mi hai dato l'input sbagliato.

Economia

- In ambito macro-economico l'input/output è l'oggetto di analisi
  statistica dell'interazione tra le aziende della stessa nazione e tra
  diverse nazioni.
In questo caso sottintende beni e servizi scambiati nelle operazioni di
  acquisto/vendita e importazione/esportazione.
- In ambito aziendale si intende l'insieme di risorse (finanziarie, umane,
  materiali, immateriali) che entrano nell'impresa e viste in un'ottica di
  sistema produttivo.
- Stesso significato di risorse in entrata si ha quando ci si riferisce
  all'input di un processo produttivo.

Voci correlate

- Output
- Informatica
- Comunicazione
- Economia
- Periferica
- Scheda perforata
- Nastro perforato
- Floppy
- Terminale (informatica)
- Form
- Webcam
- Input/output
- Metodi di input/output
- Sistema input-output
- Processo aziendale

Altri progetti

- Wikizionario contiene il lemma di dizionario «input»

Output

Il termine output, dall'inglese messo fuori, indica in senso stretto il
risultato di una elaborazione ed in senso più ampio il risultato o
l'insieme dei risultati prodotti.

In Italia il termine cominciò ad essere utilizzato con la prima informatica
degli anni sessanta, indicava al contempo i dati in uscita e i supporti che
li contenevano.

Successivamente, in particolare con l'avvento delle metodologie di gestione
per processo, si è diffuso in quasi tutte le discipline, anche non
tecniche, nel senso più generale di insieme di elementi in uscita da un
sistema dinamico, come risultato o prodotto anche immateriale di un
trattamento fisico o di una attività intellettuale di qualsiasi natura.

La fortuna del termine, insieme al suo opposto input, è stata la sua
sinteticità e il fatto che era molto semplice schematizzare un qualsiasi
processo (non necessariamente fisico, ma per esempio decisionale) con tre
soli simboli: una freccia in entrata, un riquadro, una freccia in uscita.

Output in informatica

Dati di output

Agli inizi erano dati elementari forniti dall'elaboratore mediante
l'accensione o meno di mini lampadine (i led non esistevano) organizzate in
file orizzontali sul pannello di controllo dell'elaboratore. Erano in
pratica file di bit, da interpretare in esadecimale oppure ottale, secondo
la casa costruttrice dell'elaboratore.

Un rapido passo avanti fu l'adozione della consolle (sorta di
telescrivente), come unità di input e di output, con la quale iniziò l'era
del colloquio uomo-macchina.

Il salto di qualità fu l'avvento delle stampatrici (poi pian piano
denominate stampanti), che, a differenza della consolle, che pure stampava,
erano in grado di produrre volumi notevoli di output stampato, nei classici
formati a striscia continua, in pacchi da 1000 o duemila fogli.

Questo per quanto riguarda l'output finale, quello che è immediatamente
interpretabile dall'essere umano.

Non va dimenticato infatti che esisteva (ed esiste), l'output interno, ad
esempio destinato alla memorizzazione stabile su nastri o dischi magnetici,
ed anche l'output intermedio, destinato a diventare input in successive
elaborazioni.

Con l'avvento del monitor video e successivamente delle interfacce grafiche
è nato l'output visuale diretto, prima solo testo, poi grafica ed immagine
fissa, ed infine immagine in movimento.

Con gli sviluppi delle tecniche audio (di per sé più antiche
dell'informatica) è arrivato anche l'output sonoro (da non confondere con i
beep del cicalino montato sui primi personal computer).

Supporti e strumenti

Il nastro perforato, già in dotazione alle telescriventi, è stato il primo
supporto permanente delle informazioni di output. Conteneva le stesse
informazioni via via stampate dalla telescrivente ed era adatto ad essere
conservato come documento storico. La carta è stato il primo supporto di
output di grande diffusione e grande consumo. Intorno agli anni novanta si
iniziava a parlare di società paperless, visto che per scambiarsi
informazioni bastava connettersi o scambiarsi un dischetto (allora si
diceva così). Questo però valeva solo per documenti che non avevano
carattere formale o legale. In realtà il trend del consumo di carta ha
smesso di salire solo quando le Istituzioni Pubbliche hanno iniziato ad
ammettere e accettare scambio di informazioni su supporto diverso dalla
carta. Oggi il consumo di carta tende effettivamente a diminuire, anche se
è aumentato quello di carte speciali, ad esempio per le fotografie
(l'output delle fotocamere digitali).

Output in altri campi

Elettrotecnica

In ambito elettrico-elettronico l'output è l'uscita o l'erogazione di
corrente di un Circuito elettrico o Componente elettronico.

Economia

In ambito macro-economico l'input/output è l'oggetto di analisi statistica
dell'interazione tra le aziende della stessa nazione e tra diverse nazioni.
In questo caso sottintende beni e servizi scambiati nelle operazioni di
acquisto/vendita e importazione/ esportazione.

- in ambito economico-sociale come output si intendono anche le innovazioni
  tecnologiche, le influenze sui rapporti di potere, i mutamenti della
  struttura sociale, l'impatto ecologico e i modelli culturali.
- In ambito aziendale si intende l'insieme di risultati prodotti
  dall'impresa (finanziari, materiali, immateriali) visti in ottica di
  sistema produttivo.
- Stesso significato di risultati ottenuti quando ci si riferisce
  all'output di un processo produttivo.

Voci correlate

- Input
- Informatica
- Elettrotecnica
- Economia
- Nastro perforato
- Stampante
- Floppy
- Plotter
- Altoparlante
- Nastro magnetico
- Periferica
- Sistema input-output
- Processo aziendale

Controllore (strumento)

Il controllore o regolatore o compensatore dinamico è l'organo che
determina l'andamento delle variabili di controllo in un problema di
controllo automatico.

Ogni controllore, per agire in maniera opportuna sul processo, deve
necessariamente avere delle informazioni sul segnale di riferimento;
infatti l'obiettivo del controllore, nell'esercizio dell'azione di
controllo, è quello di far sì che l'andamento della variabile controllata
non si discosti troppo dall'andamento del segnale di riferimento stesso.

Quando il controllore possiede informazioni solo sul segnale di riferimento
o eventualmente anche sul disturbo, si dice "in anello aperto" (in inglese
feedforward). Se il controllore invece possiede anche informazioni sulla
variabile controllata (o eventualmente su variabili dipendenti da quella
controllata) si dice "in anello chiuso" o in retroazione (in inglese
feedback). Se tale informazione è parziale, si ricorre ad un osservatore
dello stato che produce una stima delle variabili controllate istante per
istante.

L'applicazione tipica si ha in presenza di un sistema dinamico lineare
stazionario, per il quale si vogliono ottenere diversi tipi di stabilità,
come la stabilità interna o quella esterna. Facendo riferimento ai sistemi
causali, ovvero nei sistemi in cui le uscite non dipendono dai valori
futuri degli ingressi, la funzione di trasferimento ha un polinomio a
denominatore di grado non inferiore al grado del polinomio a numeratore. Se
gli zeri dei denominatori, che sono i poli della funzione di trasferimento,
appartengono al semipiano a parte reale positiva del piano complesso, il
sistema è instabile e la risposta all'impulso tende ad un valore infinito
al crescere del tempo.

Se invece i poli della funzione di trasferimento appartengono al semipiano
a parte reale negativa del piano complesso, il sistema è asintoticamente
stabile e la risposta impulsiva tende asintoticamente a zero al crescere
del tempo. Se, infine, i poli della funzione di trasferimento appartengono
alla retta verticale a parte reale nulla del piano complesso ed hanno
molteplicità singola, il sistema è semplicemente stabile e la risposta
all'impulso è maggiorata in valore assoluto da un certo valore al crescere
del tempo.

Per determinare come variano le posizioni dei poli e degli zeri al variare
dei guadagni e di altre caratteristiche associate al regolatore che si
vuole progettare per stabilizzare il sistema, si usano particolari grafici,
quali ad esempio il diagramma di Bode, il diagramma di Nyquist e il luogo
delle radici.

Voci correlate

- Controllo automatico
- Controllo PID
- Strumentazione di controllo
- v:Monitoraggio dei regolatori

Elaborazione numerica dei segnali

L'elaborazione numerica dei segnali o digital signal processing (DSP),
termine inglese con lo stesso significato, è una tecnica di analisi ed
elaborazione digitale dei segnali elettrici che si basa sull'uso di
processori dedicati con un elevato grado di specializzazione: i processori
di segnale digitale.

Descrizione

Un tipo importante di DSP è quello in grado di svolgere operazioni
aritmetiche ad elevata precisione (virgola mobile) quali somma, sottrazione
e prodotto. Queste tre operazioni sono sufficienti per l'implementazione di
filtri numerici FIR e IIR.

I DSP sono di grande importanza per il controllo automatico e per sistemi
di elaborazione dei segnali senza retroazione quali ad esempio impianti
audio o video.

Poiché lo scopo della DSP è di solito la misura o il filtraggio di segnali
analogici del mondo reale, la prima cosa da fare è convertire il segnale da
analogico a digitale usando un convertitore analogico-digitale. Spesso il
segnale di uscita richiesto è un altro segnale analogico, ed in questo caso
è richiesta la presenza di un convertitore digitale-analogico. Sebbene
l'elaborazione di un segnale digitale sia più complessa dell'elaborazione
fatta direttamente su un segnale analogico, essa offre molti vantaggi, come
l'applicazione di tecniche di rilevamento e correzione automatica degli
errori e la minor vulnerabilità ai rumori, tanto da essere più vantaggiosa
in molte, anche se non tutte, le applicazioni.

Nel caso non ci sia alcuna eleborazione dei segnali si parla di bitPerfect.
Per la conversione dei segnali da analogico a digitale, di solito si usa un
convertitore tensione-frequenza.

Voci correlate

- Teorema del campionamento di Nyquist-Shannon
- Level Crossing Rate
- Average Duration of Fades
- Algoritmo di Goertzel

Altri progetti

- Wikimedia Commons contiene immagini o altri file su Elaborazione numerica
  dei segnali

Teorema del campionamento di Nyquist-Shannon

In elettronica e telecomunicazioni, il teorema del campionamento di
Nyquist-Shannon o semplicemente teorema del campionamento, il cui nome si
deve a Harry Nyquist e Claude Shannon, è un risultato di notevole rilevanza
nell'ambito della teoria dei segnali.

Definisce la minima frequenza, detta frequenza di Nyquist (o anche cadenza
di Nyquist), necessaria per campionare un segnale analogico senza perdere
informazioni, e per poter quindi ricostruire il segnale analogico tempo
continuo originario. In particolare, il teorema afferma che, data una
funzione la cui trasformata di Fourier sia nulla al di fuori di un certo
intervallo di frequenze (ovvero un segnale a banda limitata), nella sua
conversione analogico-digitale la minima frequenza di campionamento
necessaria per evitare aliasing e perdita di informazione nella
ricostruzione del segnale analogico originario (ovvero nella riconversione
digitale-analogica) è pari al doppio della sua frequenza massima.

Il teorema, comparso per la prima volta nel 1949 in un articolo di C. E.
Shannon, dovrebbe chiamarsi Whittaker-Nyquist-Kotelnikov-Shannon (WNKS),
secondo l'ordine cronologico di chi ne dimostrò versioni via via più
generalizzate.

Il teorema

Il campionamento è il primo passo del processo di conversione
analogico-digitale di un segnale. Consiste nel prelievo di campioni
(samples) da un segnale analogico e continuo nel tempo ogni Δt secondi. Il
valore Δt è detto intervallo di campionamento, mentre f_s = \frac{1}{Δt} è
la frequenza di campionamento. Il risultato è un segnale analogico in tempo
discreto, che viene in seguito quantizzato, codificato e reso accessibile a
qualsiasi elaboratore digitale.

Il teorema del campionamento di Nyquist-Shannon stabilisce che, dato un
segnale analogico s(t) la cui banda di frequenze sia limitata dalla
frequenza f_M, e dato n\in \Z , il segnale s(t) può essere univocamente
ricostruito a partire dai suoi campioni s(nΔt) presi a frequenza
f_s=\frac{1}{Δt} se fₛ > 2f_M.

Dimostrazione

L'idea è che lo spettro di un segnale campionato è uguale allo spettro del
segnale originale ripetuto periodicamente con periodo uguale alla frequenza
di campionamento fₛ. Se la frequenza massima del segnale originale supera
fₛ/2 le ripetizioni nello spettro del segnale campionato si sovrappongono,
rendendo impossibile l'esatta ricostruzione del segnale originale, che
risulterà distorta.

Sia F(ω) la trasformata di Fourier di f(t). Poiché f(t) ha come limite di
banda f_M, risulta F(ω)=0 per |ω|> 2πf_M. Sia W= fₛ / 2, allora per ipotesi
se W\ge f_M si ha che F(ω)=0 per ogni |ω| > 2 πW. Sia Q(ω) la funzione
periodica di periodo 4πW che coincide con F(ω) nell'intervallo [-2πW,2πW].
Il suo sviluppo in serie di Fourier è dato da:

Q(ω)=Σ_{n=-\infty }^{+\infty }c_ne^{j\frac{n}{2W} ω}

dove:

c_n=\frac{1}{4πW} ∫_{-2πW}^{2πW}Q(ω)e^{-j\frac{n}{2W} ω}dω

Poiché Q(ω) = F(ω) in [-2πW,2πW] si può porre:

c_n=\frac{1}{4πW} ∫_{-2πW}^{2πW}F(ω)e^{-j\frac{n}{2W} ω}dω

Dato che f(t) è l'antitrasformata di Fourier di F(ω), cioè:

f(t)=\frac{1}{2π} ∫_{-\infty }^{+\infty }F(ω)e^{jωt}dω=\frac{1}{2π}
∫_{-2πW}^{2πW}F(ω)e^{jωt}dω

dalle precedenti due relazioni si ottiene:

c_n=\frac{1}{2W} f\left (-\frac{n}{2W} \right )=Δt f(-nΔt) \qquad
W=\frac{fₛ}{2} =\frac{1}{2Δt}

Definendo:

rett_W(ω)=\left {\begin{matrix} 1 & \textrm{se} |ω|\le 2πW 0 & \textrm{se}
|ω|>2πW \end{matrix} \right .

allora:

F(ω) =Q(ω)·rett_W(ω)=Σ_{n=-\infty }^{\infty }c_n e^{j\frac{n}{2W}
ω}rett_W(ω)=ΔtΣ_{n=-\infty }^{\infty }f(-nΔt) e^{jnΔtω}rett_W(ω)

e inoltre antitrasformando:

f(t)=\mathcal{F} ^{-1}[F(ω)]=ΔtΣ_{k=-\infty }^{+\infty } f(kΔt)\frac{\sin
(\frac{π}{Δt} t-kπ)}{π(t-kΔt)}

Queste equazioni mostrano che F(ω), e quindi anche la sua antitrasformata
f(t), possono essere ricostruite sulla base della conoscenza di f(nΔt),
come volevasi dimostrare.

Formula di sommazione di Poisson

Sia X(f) la trasformata di Fourier di una funzione a banda limitata x(t),
ovvero:

X(f) \stackrel{\mathrm{def} }{=} ∫_{-\infty }^{\infty } x(t) e^{- i 2 πf t}
t

con X(f) = 0 per |f| > B. La formula di sommazione di Poisson mostra che i
campioni x(nT) di x(t) sono sufficienti a creare una sommazione periodica
di X(f):

X_s(f) \stackrel{\mathrm{def} }{=} Σ_{k=-\infty }^{\infty } X\left (f - k
f_s\right ) = Σ_{n=-\infty }^{\infty } T·x(nT) e^{-i 2πn T f}

che è una funzione periodica equivalente alla serie di Fourier, dove i
coefficienti sono T ·x(nT). Si tratta della trasformata di Fourier a tempo
discreto (DTFT) della successione T ·x(nT) per n intero.

La somma Xₛ è composta da copie di X(f) traslate di un fattore k fₛ. Se
queste copie non si sovrappongono (ai loro estremi sull'asse delle ascisse)
allora il termine k=0 può essere ricavato tramite il prodotto:

X(f) = H(f) ·Xₛ₍f)

dove:

H(f) \stackrel{\mathrm{def} }{=} \begin{cases} 1 & |f| < B 0 & |f| > f_s -
B \end{cases}

In questo modo, X(f) definisce univocamente x(t).

Per ricostruire x(t), si nota che H(f) non deve essere definita in [B,fₛ-B]
poiché all'interno di tale intervallo Xₛ₍f) è nulla.

Tuttavia, il caso peggiore si verifica quando B=fₛ/2 (la frequenza di
Nyquist). Una funzione che si presta allo scopo è:

H(f) = \operatorname{rect} \left (\frac{f}{fₛ} \right ) = \begin{cases} 1 &
|f| < \frac{fₛ}{2} 0 & |f| > \frac{fₛ}{2} \end{cases}

dove \operatorname{rect} è la funzione rettangolo. Si ha:

X(f) = \operatorname{rect} \left (\frac{f}{fₛ} \right ) ·X_s(f)
= \operatorname{rect} (Tf)·Σ_{n=-\infty }^{\infty } T·x(nT) e^{-i 2πn T f}
= Σ_{n=-\infty }^{\infty } x(nT)·\underbrace{T·\operatorname{rect} (Tf)
·e^{-i 2πn T f}} _{ \mathcal{F} \left {\operatorname{sinc} \left ( \frac{t
- nT}{T} \right ) \right }}

La trasformata inversa di entrambi i membri produce la formula di
interpolazione di Whittaker-Shannon:

x(t) = Σ_{n=-\infty }^{\infty } x(nT)·\mathrm{sinc} \left ( \frac{t -
nT}{T} \right )

Aliasing nella conversione analogico-digitale

Ogni apparato di conversione analogico-digitale ha un filtro anti-alias a
monte del campionatore, il cui ruolo è quello di eliminare dal segnale in
ingresso le componenti di frequenza maggiori della metà della frequenza di
campionamento dell'apparato fₛ / 2. Tuttavia, essendo questo filtro
analogico, non è possibile tagliare le frequenze indesiderate a partire
esattamente dalla frequenza massima del segnale, poiché occorrerebbe un
filtro con un numero di poli elevatissimo (ognuno in grado di abbassare la
pendenza della retta di taglio di -20 dB/decade).

Data l'impossibilità di realizzare filtri di ordine superiore a 11-12,
solitamente si preferisce utilizzare un filtro anti-alias meno preciso con
frequenza di taglio maggiore rispetto a quella imposta dal teorema di
Nyquist. Questo porta ad avere un sovracampionamento di un fattore K, che
allontana tra loro le varie repliche del segnale nel dominio della
frequenza. Per ricostruire il segnale digitale si utilizza allora un filtro
digitale passa-basso seguito da un blocco decimatore con il compito di
eliminare i campioni ridondanti. Con questa soluzione ibrida si ottiene un
filtro analogico-digitale con una pendenza elevatissima ed un costo
limitato, a discapito di una maggiore velocità richiesta per il
convertitore.

Se si ha a disposizione un apparato di conversione A/D che lavora ad una
data frequenza fₛ e si è interessati alle componenti di un segnale che
superano fₛ / 2 si possono seguire strade diverse: utilizzare uno strumento
più veloce o utilizzare tecniche di sottocampionamento. La seconda opzione
è realizzabile quando le frequenze di interesse sono racchiuse in un range
del tipo:

Δf = f_max - f_min < \frac{fₛ}{2}

e questo è possibile anche se sia f_max che f_min superano fₛ / 2. In
questo caso, tuttavia, il limite imposto dal teorema del campionamento non
è più sufficiente a garantire un campionamento corretto.

Bibliografia

- Alessandro Falaschi, cap. 4, in Elementi di trasmissione dei segnali e
  sistemi di telecomunicazione, Roma, Sapienza - Università di Roma,
  ottobre 2009.
- (EN) J. R. Higgins: Five short stories about the cardinal series,
  Bulletin of the AMS 12(1985)
- (EN) V. A. Kotelnikov, "On the carrying capacity of the ether and wire in
  telecommunications", Material for the First All-Union Conference on
  Questions of Communication, Izd. Red. Upr. Svyazi RKKA, Moscow, 1933
  (Russian). (english translation, PDF)
- (EN) Karl Küpfmüller, "Utjämningsförlopp inom Telegraf- och
  Telefontekniken", ("Transients in telegraph and telephone engineering"),
  Teknisk Tidskrift, no. 9 pp. 153–160 and 10 pp. 178–182, 1931.
- (EN) R.J. Marks II: Introduction to Shannon Sampling and Interpolation
  Theory, Spinger-Verlag, 1991.
- (EN) R.J. Marks II, Editor: Advanced Topics in Shannon Sampling and
  Interpolation Theory, Springer-Verlag, 1993.
- (EN) R.J. Marks II, Handbook of Fourier Analysis and Its Applications,
  Oxford University Press, (2009), Chapters 5-8. Google books.
- (EN) H. Nyquist, "Certain topics in telegraph transmission theory",
  Trans. AIEE, vol. 47, pp. 617–644, Apr. 1928 Reprint as classic paper in:
  Proc. IEEE, Vol. 90, No. 2, Feb 2002.

Voci correlate

- Aliasing
- Campionamento (teoria dei segnali)
- Dithering
- Formula di interpolazione di Whittaker-Shannon
- Formula di sommazione di Poisson
- Quantizzazione (elettronica)
- Trasformata di Fourier

Collegamenti esterni

- (EN) Learning by Simulations Interactive simulation of the effects of
  inadequate sampling
- (EN) Undersampling and an application of it, spazioscuola.altervista.org.
- (EN) Sampling Theory For Digital Audio (PDF), web.archive.org.
- (EN) Journal devoted to Sampling Theory, stsip.org.
- (EN) Sampling Theorem with Constant Amplitude Variable Width Pulse,
  ieeexplore.ieee.org.

Quantizzazione (elettronica)

Quando si misura una grandezza fisica, l'insieme di valori che essa può
assumere in natura è un insieme continuo e composto da infiniti punti. Le
grandezze fisiche sono dunque "analogiche".

A causa dell'impossibilità di una rappresentazione reale a precisione
infinita, nelle comunicazioni di tipo numerico o digitale, il valore della
grandezza in questione deve essere convertito in formato discreto
(equivalentemente definito a precisione finita). Ciò avviene tipicamente in
concomitanza di un processo di discretizzazione nel dominio temporale
(ascissa del riferimento cartesiano) definito campionamento.

Il processo non-lineare di quantizzazione, a differenza di quello di
campionamento (di un processo/segnale limitato), non è reversibile, non è
pertanto possibile ricostruire i valori reali assunti originariamente dalla
grandezza fisica. La quantizzazione è dunque una fonte di distorsione.

Descrizione

Affinché una grandezza sia trasmissibile e codificabile con un numero
finito di bit ovvero in forma numerica, è però necessario che essa possa
assumere solo un numero finito di valori di codominio discreti; ciò avviene
tramite un successivo processo di quantizzazione del valore in ordinata
della grandezza in questione.

Per ottenere ciò, i valori possibili della grandezza in questione vengono
innanzitutto limitati tra un massimo ed un minimo intorno a dei valori
discreti preventivamente definiti definendo così le relative regioni di
decisione e la dinamica del quantizzatore stesso: in tal modo il valore
analogico della grandezza originaria, in corrispondenza del valore
campionato in ascissa, verrà ricondotto al più prossimo dei valori discreti
preventivamente definiti tramite il processo di decisione.

Con la quantizzazione vengono però introdotti degli errori detti errori di
quantizzazione pari alla differenza tra il valore quantizzato e il suo
valore "reale" nel campo continuo. L'errore massimo possibile che potrà
essere introdotto volta per volta sarà quindi pari alla metà
dell'intervallo discreto discriminabile o regione di decisione, nel caso
limite in cui il valore di ingresso si collochi esattamente a metà tra due
valori discreti di uscita ovvero sulla frontiera di due regioni di
decisione contigue. L'insieme di questi errori conduce al rumore di
quantizzazione. Il Signal to Noise Quantization Ratio (SNQR) misura la
bontà del processo di quantizzazione ed è il parametro che più influisce
sulla qualità del segnale digitalizzato.

Nella conversione analogico-digitale al processo di quantizzazione segue
quello di codifica del valore discreto in ordinata.

La quantizzazione, in particolare, può essere di due tipologie: uniforme e
non-uniforme. La distinzione si basa sulla distribuzione dei valori finiti
assumibili dalla grandezza quantizzata all'interno del range disponibile
(dinamica).

Quantizzazione uniforme (o lineare)

Quantizzatore Lineare = PCM

La dimensione degli intervalli di decisione in cui si suddivide l'insieme
dei possibili valori è sempre la medesima. Ovunque cada (all'interno della
dinamica) il valore quantizzato, l'accuratezza dell'operazione sarà sempre
la stessa.

Detto n il numero di bit del quantizzatore,

- il suo numero di livelli sarà M = 2ⁿ
- l'ampiezza di ogni livello sarà q = Vpp / M
- e la varianza sarà q² / 12

Quantizzazione non-uniforme (o non lineare)

Si creano intervalli più piccoli (e quindi più accurati) dove la
concentrazione di valori dei campioni è più alta e intervalli più grandi (e
quindi meno accurati) dove la concentrazione di valori di campioni è più
bassa; facendo così si presta quindi più attenzione nella quantizzazione di
valori che si presentano con maggiore probabilità diminuendo così l'errore
di quantizzazione.

La quantizzazione è un processo irreversibile, che modifica il segnale
originario, approssimandone il valore con uno vicino, ma non identico. Per
questo il processo di quantizzazione introduce rumore. Il rumore di
quantizzazione in uscita dal filtro di ricezione in un sistema di
comunicazione è bianco e gaussiano.

La potenza media del rumore di quantizzazione si calcola come:

sq^2 = 2 ·f_2 ·\frac {q^2}{12} ·f_c

Rapporto Segnale-Rumore (Ru o SNR)

Il rapporto tra il segnale ed il rumore, in uscita da un sistema di
comunicazione è un parametro importante per definire la qualità della
comunicazione stessa. Si indica con Ru (o SNR), ed è definito dal rapporto
tra la potenza del segnale e quella del rumore.

Viene stabilito prima della realizzazione del sistema di comunicazione un
tetto massimo oltre il quale non si può salire perché la qualità sia
accettabile (detto Ru0).

Dimensionare un sistema significa anche scegliere il corretto numero di bit
per quantizzare il segnale trasmesso: in queste formule compare sempre un
termine 2ⁿ, che verrà appunto scelto per fare in modo di rispettare le
specifiche.

Si deve inoltre ricordare che il dimensionamento del sistema va fatto
considerando il caso peggiore in cui ci si potrebbe venire a trovare: dato
che il rumore è inversamente proporzionale alla frequenza di campionamento,
il caso peggiore in relazione ad f_c sarà f_c = 2·f₂.

Voci correlate

- Convertitore analogico-digitale
- Conversione analogico-digitale

Distorsione (fisica)

Per distorsione si intende l'alterazione della forma originale di un
oggetto, di un'immagine, di un suono, di un'onda o altra forma di
informazione o rappresentazione. Di solito è considerata un fenomeno
indesiderato. Nelle telecomunicazioni, ad esempio, produce un disturbo
nella ricezione del segnale, quindi ad un'alterazione dell'informazione
originariamente trasmessa. In alcuni settori invece la distorsione è un
fenomeno volutamente cercato, come nel suono della chitarra elettrica,
ottenuta per mezzo di un amplificatore o tramite un effetto elettronico. La
distorsione leggera delle registrazioni su nastro e delle valvole, in certe
situazioni è considerata piacevole. L'aggiunta del rumore o di altri
segnali estranei, tipo interferenza o ronzio, non sono considerati
distorsione, in quanto si sommano col segnale utile, benché gli effetti
della distorsione talvolta siano considerati alla stregua del rumore.

Segnali elettrici

Nelle telecomunicazioni e nella teoria dei segnali, un "sistema" esente da
rumori può essere caratterizzato da una funzione di trasferimento, tale che
l'uscita y(t)possa essere scritta in funzione dell'ingresso x come:

y(t) = F(x(t))

Quando la funzione di trasferimento comprende solo un guadagno A costante e
un ritardo T

y(t) = A·x(t-T)

l'uscita non è distorta e il segnale o grandezza in uscita si definisce
come fedele al segnale o grandezza di ingresso. La distorsione avviene
quando la funzione di trasferimento F è più complessa della precedente. Se
F è una funzione lineare, per esempio un filtro il cui guadagno e/o ritardo
varia in frequenza, allora il segnale subirà una distorsione lineare. Una
distorsione lineare non cambia la forma di una singola sinusoide, ma di
solito cambierà la forma di un segnale combinato(multi-tono). Nella figura
si nota il comportamento di un segnale, costituito da un'onda quadra
seguita da un'onda sinusoidale, che passa attraverso varie funzioni di
distorsione.

- Il primo segnale, in nero, mostra l'ingresso. Mostra anche l'uscita da
  una funzione di trasferimento non distorta, la linea dritta.
- Un filtro passa alto, il segnale in verde, distorce la forma dell'onda
  quadra al diminuire della frequenza. Questa è la causa dell'attenuazione,
  vista in cima al segnale.
- Un filtro passa basso, il segnale in blu, attenuerà i segnali alle alte
  frequenze. La maggior parte dei sistemi fisici sono filtri passa basso.
  Da notare che la fase della sinusoide è diversa per i sistemi passa basso
  e passa alto, dovuta alla distorsione di fase dei filtri.
- Una funzione di trasferimento leggermente non lineare, in viola, è una
  leggera compressione tipica di un amplificatore audio, che comprime il
  picco dell'onda sinusoidale. Questo causerà un piccolo aumento delle
  armoniche a basso ordine.
- Un forte taglio alla funzione di trasferimento, in rosso, genererà delle
  armoniche ad alto ordine. Parte della funzione di trasferimento è piatta,
  e questo indica che tutta l'informazione del segnale d'ingresso andrà
  persa se il dispositivo lavora in quella regione.

La funzione di trasferimento di un amplificatore ideale, con un perfetto
guadagno e ritardo, è solo un'approssimazione. Il vero comportamento di un
sistema è di solito differente. La non linearità in una funzione di
trasferimento di un dispositivo attivo, tipo le valvole, i transistor e gli
amplificatori operazionali, sono una comune fonte di distorsione non
lineare. Nei componenti passivi, come un cavo coassiale o la fibra ottica,
la distorsione lineare può essere causata dalle disomogeneità, dalla
riflessione, e anche dal mezzo di propagazione.

Alla distorsione della forma d'onda nel dominio del tempo, corrisponde una
distorsione nel dominio della frequenza e viceversa.

Distorsione armonica

L'onda può essere affetta da componenti non lineari, portando il sistema in
risonanza oppure in distorsione di intermodulazione (IMD). Guarda anche
distorsione armonica totale (THD).

Distorsione d'ampiezza

Una distorsione d'ampiezza è una distorsione presente nei sistemi,
sottosistemi o dispositivi quando l'ampiezza d'uscita è una funzione non
lineare dell'ampiezza d'ingresso sotto specifiche condizioni.

Distorsione della risposta in frequenza

Questo tipo di distorsione avviene, per mezzo di filtri, quando frequenze
diverse sono amplificate con coefficienti diversi. Nel caso particolare
dell'audio, questa distorsione è principalmente causata dai seguenti
fattori: dall'acustica dell'ambiente, dai microfoni e altoparlanti
scadenti, dai cavi per altoparlanti troppo lunghi che influiscono con la
risposta in frequenza dipendente dell'impedenza dell'altoparlante.

Un particolare tipo di distorsione causato dalla risposta in frequenza del
sistema attraversato è la distorsione detta per "taglio di banda", dovuta
alla banda passante del canale che può essere inferiore a quella del
segnale in input.

Distorsione di fase

Questa forma di distorsione avviene soprattutto nel caso di componenti
reattivi, come la reattanza capacitiva o l'induttanza. Qui, tutti i
componenti di un segnale d'ingresso non sono amplificati con la stessa
fase, portando il segnale di uscita ad essere fuori fase con il resto
dell'uscita.

Distorsione del ritardo di gruppo (group delay)

Può essere visto solo nei mezzi dispersivi. In una guida d'onda, la
velocità di propagazione varia con la frequenza. In un filtro, il ritardo
di gruppo tende ad avere un picco nelle vicinanze della frequenza di
taglio, causando una distorsione dell'impulso. In presenza di trasmissioni
a lunga distanza, la distorsione del ritardo di gruppo può essere corretta
con i ripetitori.

Cause ed effetti di una distorsione

Le cause di una distorsione in un sistema di telecomunicazione possono
essere diverse: una risposta in frequenza non piatta del canale
trasmissivo, il rumore aleatorio, che nei casi reali si accompagna al
segnale trasmesso nel canale, la dispersione del mezzo trasmissivo deputato
a canale, l'interferenza, dovuta alla eventuale presenza di altri segnali
informativi nella banda del segnale utile, e il multipath.

Gli effetti di una distorsione rappresentano l'alterazione del segnale
trasmesso, effetti che possono alterare l'informazione associata al segnale
stesso, generando un errore di trasmissione o un'interferenza
intersimbolica a valle nel ricevitore.

Correzione della distorsione

L'uscita di un sistema è data dalla funzione: y(t) = F(x(t)), allora se è
possibile individuare un risultato per la funzione inversa y(t)=1/F(x(t)),
questa può essere intenzionalmente usata per individuare la distorsione sia
all'ingresso che all'uscita del sistema, ed eventualmente operare per
correggerla. Un esempio di tale correzione avviene quando le registrazioni
di LP / vinile o le trasmissioni audio FM sono pre-enfatizzate da un filtro
lineare, filtro che riproduce un effetto inverso alla distorsione
originale, in modo da lasciare il sistema intatto. La correzione non è
possibile se la funzione inversa non esiste, per esempio se la funzione di
trasferimento ha delle zone piatte¹ . Questo risultato rappresenta una
perdita d''informazione, quindi incorreggibile. Tale situazione può
accadere quando un amplificatore è "affaticato", risultando in uno stato,
definito come "clipping", o in una distorsione dello "slew rate", quando
per un momento l'uscita viene determinata dalle caratteristiche
dell'amplificatore e non dal segnale d'ingresso.

Misure anti-distorsione

Per annullare una distorsione di un segnale è possibile usare a valle del
sistema distorcente un equalizzatore che modifichi i toni in frequenza
dell'onda ricevuta, oppure utilizzare a monte del sistema distorcente e
conoscendo le caratteristiche della distorsione, un predistorsore con
distorsione reciproca al sistema distorcente in cascata, in modo tale che
in uscita alla doppia distorsione il segnale rimanga fedele a quello di
ingresso.

Telescrivente o segnali modem

Nei segnali binari come la FSK, per distorsione si intende lo spostamento
di un istante significativo del segnale d'impulsi dalla propria posizione
relativa. La grandezza di questa distorsione è espressa nella percentuale
di un ideale unità di lunghezza dell'impulso. Alcune volte chiamata "bias"
della distorsione. La distorsione telegrafica è un problema simile, dove
viene distorto il rapporto tra intervalli di segno e spazio.

Distorsione audio

In questo contesto, la distorsione si riferisce ad alcuni tipi di
deformazione della forma d'onda in uscita, in relazione alla forma d'onda
di ingresso, di solito il clipping, la distorsione armonica e/o la
distorsione di intermodulazione² che causano un comportamento non lineare
nella risposta dei componenti elettronici. La distorsione nella musica a
volte è usata intenzionalmente per ottenere degli effetti specifici. Altre
forme di distorsione audio possono essere riferite a un andamento non- flat
della risposta in frequenza, compressione, modulazione, aliasing,
quantizzazione, rumore, variazioni lente o veloci dei parametri da parte di
dispositivi analogici come i dischi in vinile e nastri magnetici.
L'orecchio umano non è in grado di percepire la distorsione di fase, a meno
che non sia un affetto delle distorsioni avvenute durante la registrazione.
Come argomenti correlati si veda anche, misure dei sistemi audio.

Ottica

In ottica, la distorsione delle immagini è una divergenza da una proiezione
rettilinea causata dal cambiamento della magnificazione, con l'incremento
della distanza dall'asse ottico del sistema ottico.

Proiezione cartografica

Nella cartografia, una distorsione è la modifica di un'area o di una forma.
Per esempio, nella proiezione cilindrica centrografica modificata di
Mercatore, la forma della Groenlandia viene distorta a causa della sua alta
latitudine, nel senso che la sua forma e le sue dimensioni non sono
equivalenti alle forme e alle dimensioni degli altri continenti presenti
alle latitudini situate più a sud.

Note

[1] la funzione inversa avrà molti punti d'ingresso per ottenere un unico
  punto d'uscita.
[2] Un fenomeno causato dal mixing.

Altri progetti

- Wikizionario contiene il lemma di dizionario «distorsione»
- Wikimedia Commons contiene immagini o altri file su distorsione

Campionamento (teoria dei segnali)

Nella teoria dei segnali il campionamento è una tecnica che consiste nel
convertire un segnale continuo nel tempo in un segnale discreto,
valutandone l'ampiezza a intervalli di tempo regolari. In questo modo, a
seguito di una successiva operazione di quantizzazione e conversione, è
possibile ottenere una stringa digitale (discreta nel tempo e
nell'ampiezza) che approssimi quella continua originaria.

Descrizione

In parole povere il campionamento consiste nell'andare a "sentire"
(misurare, registrare) il valore del segnale analogico in diversi istanti
di tempo. Il tempo T che intercorre tra una valutazione e l'altra si chiama
periodo di campionamento. La frequenza di campionamento f_c = \frac{1}{T} è
invece il reciproco del periodo di campionamento.

Il teorema che stabilisce quale sia la frequenza minima di campionamento
con una determinata caratterizzazione in frequenza (trasformata di Fourier)
affinché il segnale analogico possa essere ricostruito a valle a partire da
quello discreto in input è il teorema del campionamento di Shannon-Nyquist,
ovvero:

f_c > 2 ·fₘ

Dove f_c è la frequenza di campionamento ed fₘ è la massima frequenza dello
spettro del segnale da campionare. Se viene rispettata tale condizione è
allora possibile ricostruire, con l'utilizzo di apposite funzioni
interpolatrici, il segnale analogico senza perderne alcuna informazione;
generalmente per una buona e fedele ricostruzione del livello analogico è
richiesta una frequenza di campionamento che sia 5-10 volte superiore alla
frequenza massima contenuta nel segnale campionato. Qualora invece non
venga rispettata tale condizione, si riscontra un effetto conosciuto con il
nome di Aliasing, che comporta una distorsione del segnale analogico
ricostruito rispetto a quello originale campionato.

Definendo la frequenza di Nyquist come fₙ ₌ f_c/2 , la ricostruzione di un
segnale analogico costituito da componenti in frequenza superiori alla
frequenza di Nyquist porta ad ottenere un segnale dove tali componenti
hanno una frequenza detta "specchiata" rispetto alla frequenza di Nyquist,
cioè simmetrica rispetto alla frequenza di Nyquist a quella del segnale
analogico originale. Ad esempio se il livello analogico è una sinusoide di
frequenza fₛ₌₁₂ Hz e la frequenza di campionamento è f_c=20 Hz, allora si
ottiene f_r = fₙ-(fₛ-fₙ₎ ₌ ₈Hz , con f_r la frequenza della sinusoide
ricostruita. Per evitare il fenomeno dell'aliasing è allora necessario:

- adottare una frequenza di campionamento superiore se non si vogliono
  perdere le informazioni contenute nelle componenti ad alta frequenza del
  segnale analogico acquisito
- adottare un filtraggio anti-aliasing (filtro passa-basso) così da
  eliminare le frequenze contenute nel segnale analogico superiori alla
  frequenza di Nyquist del campionatore

Collegamenti esterni

- Teoria dei Segnali - Alessandro Falaschi, infocom.uniroma1.it.
- università degli studi di Milano, ens.di.unimi.it.
- Università degli studi di Firenze, eprints.unifi.it.

Serie di Fourier

In matematica, in particolare in analisi armonica, la serie di Fourier è
una rappresentazione di una funzione periodica mediante una combinazione
lineare di funzioni sinusoidali. Questo tipo di decomposizione è alla base
dell'analisi di Fourier.

Storia

La serie prende il nome dal matematico francese Joseph Fourier (1768-1830),
il quale fu il primo a studiare sistematicamente tali serie infinite. In
precedenza esse erano state oggetto di investigazioni preliminari da parte
di Eulero, d'Alembert e Daniel Bernoulli. Fourier ha applicato tali serie
alla soluzione dell'equazione del calore, pubblicando i suoi risultati
iniziali nel 1807 e nel 1811. L'opera più ampia, intitolata Théorie
analytique de la chaleur, è del 1822. Dopo la metà del secolo Dirichlet e
Riemann hanno riformulato i risultati di Fourier con maggiore rigore e
precisione e in forma più soddisfacente.

Successivamente sono state introdotte molte altre forme di trasformate
integrali che hanno esteso l'idea iniziale di rappresentare ogni funzione
periodica come sovrapposizione di armoniche. Esistono infatti molte altre
successioni di funzioni ortogonali che godono di proprietà simili a quelle
dell'analisi di Fourier, spesso corrispondenti a soluzioni di una opportuna
equazione differenziale come, ad esempio, le successioni di funzioni di
Bessel. Un'ampia classe di successioni utili, inoltre, è quella delle
soluzioni dei cosiddetti problemi di Sturm-Liouville. Essi si riconducono
anche alle soluzioni di equazioni di Schrödinger della meccanica
ondulatoria.

Definizione

Un polinomio trigonometrico è una funzione periodica di periodo 2π definita
sul campo reale del tipo:¹

f(t) = \frac{a₀}{2} + Σ_{n=1}^{N} \left{a_n\cos (nt)+b_n\sin (nt)\right } =
Σ_{n=-N}^{N} cₙ ₑ^{int}

dove a_i e b_i sono numeri reali, c_i complessi e n è intero.

Sia:

u_n (t) = e^{int}

e sia:

\langle f, g \rangle \stackrel{\mathrm{def} }{=} \frac{1}{2π} ∫_{-π}^{π}
f(t)\overline{g(t)} dt

un prodotto interno in L²⁽T), dove T è la circonferenza unitaria.

Allora {u_n = e^{i n t},n\in \mathbb{Z} } è una base ortonormale rispetto
al prodotto interno così definito, infatti:²

\langle u_n , u_m \rangle = \frac{1}{2π} ∫_{-π}^{π} e^{i (n-m) t}dt =
δ_{n,m}

Un tale sistema ortonormale in L²⁽T) è detto sistema ortonormale
trigonometrico, ed è un sistema completo.

Si definisce serie di Fourier di una funzione f \in L²⁽T) a quadrato
sommabile la rappresentazione della funzione per mezzo di una combinazione
lineare dei vettori di base uₙ del sistema ortonormale trigonometrico:³

Σ_{n=-\infty }^\infty f_n u_n = Σ_{n=-\infty }^\infty fₙ ₑ^{int}

I coefficienti della combinazione sono quindi la proiezione della funzione
sui vettori di base stessi:

f_n = \frac{\langle f,u_n \rangle }{\| u_n \| ²} = \langle f,u_n \rangle =
\frac{1}{2π} ∫_{-π}^π f(t) e^{-int}dt

e sono detti coefficienti di Fourier.

Le somme parziali della serie di Fourier sono inoltre:

S_N (t) = Σ_{n=-N}^N f_n e^{int} \qquad N=0,1,2 …

La serie di Fourier di una funzione può essere espressa in diverse forme
matematicamente equivalenti: rettangolare, complessa e polare.

Forma rettangolare

Si consideri una funzione di una variabile reale a valori complessi f(x)
che sia periodica con periodo 2 π e a quadrato integrabile sull'intervallo
. Si definiscono i coefficienti tramite la formula di analisi:

F_n = \frac{1}{2π} ∫_{-π}^π f(x) e^{-inx}dx

e la rappresentazione mediante serie di Fourier di f(x) è allora data dalla
formula di sintesi:

f(x) = Σ_{n=-\infty }^{\infty } F_n e^{inx}

Ciascuno dei termini di questa somma è chiamato modo di Fourier.
Nell'importante caso particolare nel quale la f(x) è una funzione a valori
reali, spesso risulta utile servirsi dell'identità e^{inx} = \cos
(nx)+i\sin (nx) per rappresentare equivalentemente f(x) come combinazione
lineare infinita di funzioni della forma \cos (nx) e \sin (nx). Si ottiene
la serie di Fourier:

f(x) = \frac{a₀}{2} + Σ_{n=1}^\infty \left{a_n\cos \left (\frac{2π}{T}
nx\right )+b_n\sin \left (\frac{2π}{T} nx\right )\right }

Con T periodo della funzione e dove:

a_0 = \frac{2}{T} ∫_{-\frac{T}{2} }^{\frac{T}{2} }f(x)dx \qquad a_n =
\frac{2}{T} ∫_{-\frac{T}{2} }^{\frac{T}{2} } f(x)\cos \left (\frac{2π}{T}
nx\right ) dx \qquad b_n =\frac{2}{T} ∫_{-\frac{T}{2} }^{\frac{T}{2} }f(x)
\sin \left (\frac{2π}{T} nx\right )dx

Per funzioni pari (dove compaiono solo i coseni) si ha:

a_0= \frac{4}{T} ∫_{0}^{\frac{T}{2} }f(x)dx \qquad a_n = \frac{4}{T}
∫_{0}^{\frac{T}{2} } f(x)\cos \left (\frac{2π}{T} nx\right ) dx \qquad bₙ₌₀

mentre per funzioni dispari (dove compaiono solo i seni):

a_0 =0 \qquad a_n=0 \qquad b_n= \frac{4}{T} ∫_{0}^{\frac{T}{2} } f(x)\sin
\left (\frac{2π}{T} nx\right ) dx \qquad

I coefficienti aₙ e bₙ esprimono le ampiezze, ovvero i pesi delle sinusoidi
e cosinusoidi, e a₀ / 2 corrisponde al valore medio in un periodo della
funzione f(x). Tale formulazione si riconduce alla precedente
rappresentazione se:

F_n = \frac{aₙ - i bₙ}{2} \mbox{e} Fₙ ₌ F_{-n}^*

Forma complessa

La serie di Fourier in forma complessa di una funzione f(x) è:

f(x)= Σ_{n=-\infty }^\infty γ_n e^{ \frac{i2πnx}{T} }

in cui

γ_n \in \mathbb{C} \qquad i= √(-1)

I coefficienti γₙ sono calcolati tramite la relazione:

γ_n = \frac{1}{T} ∫_0^T f(x) e^{ \frac{-i2πnx}{T} }dx

Se la funzione f(x) è reale i coefficienti γₙ soddisfano la proprietà di
simmetria hermitiana:

γ_n^* = γ_{-n}

Questo fatto si può vedere esplicitando la somma dei termini di ordine n e
-n della serie:

γ_n e^{inx} + γ_{-n} e^{-inx} = γ_n [\cos (nx)+i\sin (nx)]+γ_{-n} [\cos
(-nx)+i\sin (-nx)]

Da cui, servendosi delle proprietà delle funzioni trigonometriche (in
particolare della parità del coseno e della disparità del seno) si trova:

γ_n e^{inx} + γ_{-n} e^{-inx} =(γ_n+γ_{-n})\cos (nx)+(γ_n-γ_{-n})i\sin (nx)

Si vede dunque che per avere una funzione reale descritta in serie di
Fourier, la quantità γ_n+γ_{-n} deve essere reale, mentre la quantità
γ_n-γ_{-n} deve essere immaginaria pura per ogni n \in \mathbb{Z} .
Entrambe le condizioni sono verificate dalla proprietà di simmetria
hermitiana dei coefficienti.

Forma polare

Un'altra forma in cui è possibile esprimere la serie di Fourier di una
funzione f(x) reale è la forma polare:

f(x)= c_0 + 2Σ_{n=1}^\infty c_n \cos \left ( \frac{2πnx}{T} + ϕ_n \right )

I coefficienti c₀, cₙ e ϕₙ possono essere definiti partendo dai
coefficienti γₙ della forma complessa:

c_0=γ_0 ; c_n= | γ_n | ; ϕ_n=\angle γₙ

Convergenza delle serie di Fourier

In generale, la serie di Fourier di una funzione continua definita sulla
circonferenza unitaria non converge alla funzione stessa, e di conseguenza
la scrittura:

f(x) = \lim _{n→\infty } S_N (f,x) = \lim _{n→\infty } \frac{1}{2π}
∫_{-π}^πf(t) Σ_{k=-n}^n e^{ikt} dt \qquad n=0,1,2 …

non vale per ogni funzione.⁴ Questo può essere provato, ad esempio,
attraverso il teorema di Banach-Steinhaus. In particolare, per ogni numero
reale x esiste un sottoinsieme denso Eₓ dello spazio C(T) delle funzioni
continue definite su T tale che:⁵

\sup _n | S_N (f,x) | = \infty ∀f \in Eₓ

Si dimostra tuttavia che per f \in C(T) esiste un polinomio trigonometrico
P tale che:

|f(t) - P(t) | < ϵ

per ogni t reale. In particolare, nel 1904 il matematico ungherese Lipót
Fejér mostrò che la media aritmetica delle somme parziali della serie di
Fourier di f converge uniformemente al valore della funzione stessa.³

Nonostante i coefficienti di Fourier aₙ e bₙ si possano definire
formalmente per ogni funzione tale per cui abbia senso considerare gli
integrali che li caratterizzano, la convergenza della serie definita
attraverso di essi alla funzione dipende dalle proprietà specifiche di tale
funzione. Se f(x) è a quadrato integrabile si ha:

\lim _{N→\infty }∫_{-π}^π\left |f(x)-Σ_{n=-N}^{N} F_n e^{inx}\right |^2
dx=0

Ottenendo così una convergenza nella norma dello spazio L².

Esistono altri criteri che consentono di garantire che la serie converga in
un dato punto, ad esempio il fatto che la funzione sia differenziabile nel
punto. Anche una discontinuità con salto è accettabile, poiché se la
funzione possiede derivate a sinistra e a destra allora la serie di Fourier
converge al valore medio dei rispettivi limiti a sinistra e a destra. Si
può tuttavia riscontrare il fenomeno di Gibbs, e si ha la possibilità che
la serie di Fourier di una funzione continua non converga punto per punto.

Proprietà

Le proprietà delle serie di Fourier sono in gran parte conseguenze delle
proprietà di ortogonalità e di omomorfismo delle funzioni e^{inx}, ed in
generale delle proprietà del gruppo delle rotazioni. Le funzioni e^{ikx}
appartenenti alla base ortonormale sono omomorfismi del gruppo additivo
della retta reale sul gruppo circolare, ovvero dell'insieme dei numeri
complessi di modulo unitario dotato dell'ordinaria moltiplicazione del
campo complesso. Come conseguenza di questo fatto, se:

g(x)=f(x-y)

allora, denotando con G la trasformata di g, si ha:

G_k = e^{-iky}Fₖ

Inoltre, se Hₖ è la trasformata di h = f * g , allora:

Hₖ ₌ Fₖ Gₖ

Ovvero, il coefficiente di Fourier della convoluzione di due funzioni è il
prodotto dei coefficienti di Fourier dello stesso grado delle due funzioni
stesse.

Scambiando i ruoli di prodotto usuale e prodotto di convoluzione, se h =
f·g allora i coefficienti di tale funzione prodotto sono dati dalla
convoluzione su \Z dei coefficienti delle funzioni f e g:

H_k=Σ_{i=-\infty }^\infty F_i G_{k-i}

I teoremi di Riesz-Fischer e Parseval determinano inoltre due importanti
proprietà delle serie di Fourier.

Il teorema di Riesz-Fischer

Il teorema di Riesz-Fischer stabilisce che in uno spazio completo ogni
successione in \ell ² definisce una funzione a quadrato integrabile. In
particolare, il teorema determina le condizioni per cui gli elementi di una
successione in l² sono i coefficienti di Fourier di un qualche vettore di
L².

Sia {u_n } un sistema ortonormale di polinomi in uno spazio di Hilbert H e
sia cₙ una successione. Allora esiste un unico vettore f \in H tale che gli
elementi della successione siano i coefficienti di Fourier di f:⁶

cₙ ₌ ₍f, uₙ₎

dove (,) è un prodotto interno. La successione definisce quindi una
funzione f in L².

Il teorema di Parseval

Siano A(x) e B(x) due funzioni Riemann integrabili a valori complessi
definite su \R . Siano esse periodiche con periodo 2 π; e siano le loro
serie di Fourier date rispettivamente da:

A(x)=Σ_{n=-\infty }^\infty a_ne^{inx} \qquad B(x)=Σ_{n=-\infty }^\infty
bₙₑ^{inx}

Allora:⁷

Σ_{n=-\infty }^\infty a_n\overline{bₙ} = \frac{1}{2π}
∫_{-π}^πA(x)\overline{B(x)} dx

Come caso particolare, se A(x) = B(x) = f(x) \in L^2([-π,π]) si ha:

Σ_{n=-\infty }^\infty |\hat{f} (n)|^2 = \frac{1}{2π} ∫_{-π}^{π} |f(x)|^2 dx

Esempio

Si consideri la funzione f(x) = x (funzione identità) per x \in{-π,π} . Se
si vuole considerare il suo sviluppo all'esterno di questo dominio, la
serie di Fourier richiede implicitamente che questa funzione sia periodica
(l'estensione periodica della funzione identità è una funzione a dente di
sega).

Per calcolare i coefficienti di Fourier di questa funzione conviene
osservare che \cos (nx) è una funzione pari, mentre f e \sin (nx) sono
funzioni dispari:

\frac{a₀}{2} = \frac{1}{2π} ∫_{-π}^{π}f(x)dx=\frac{1}{2π} ∫_{-π}^{π} x dx=
0
a_n=\frac{1}{π} ∫_{-π}^{π}f(x)\cos (nx)dx= \frac{1}{π} ∫_{-π}^{π}x \cos
(nx)dx = 0
b_n= \frac{1}{π} ∫_{-π}^{π}f(x)\sin (nx)dx=\frac{1}{π} ∫_{-π}^{π} x \sin
(nx)dx =
=\frac{2}{π} ∫_{0}^{π} x\sin (nx) dx= \frac{2}{π} \left (
\left{-\frac{x\cos (nx)}{n} \right } _0^{π}+\left{\frac{\sin (nx)}{n²}
\right } _0^{π} \right )=(-1)^{n+1}\frac{2}{n}

Si osservi che a₀ e aₙ sono nulli in quanto x e x\cos (nx) sono funzioni
dispari. Quindi la serie di Fourier per la funzione in esame è:

f(x)=x=\frac{a₀}{2} + Σ_{n=1}^{\infty }(a_n\cos (nx)+b_n\sin (nx))
=Σ_{n=1}^{\infty }(-1)^{n+1}\frac{2}{n} \sin (nx) \qquad ∀x\in (-π,π)

Può essere interessante vedere l'applicazione della serie di Fourier al
calcolo del valore ζ(2) della funzione zeta di Riemann.

Note

[1] W. Rudin, Pag. 88
[2] W. Rudin, Pag. 89
[3] W. Rudin, Pag. 91
[4] W. Rudin, Pag. 101
[5] W. Rudin, Pag. 102
[6] W. Rudin, Pag. 85
[7] W. Rudin, Pag. 92

Bibliografia

- (EN) Walter Rudin, Real and Complex Analysis, Mladinska Knjiga,
  McGraw-Hill, 1970, ISBN 0-07-054234-1.
- Carlo Cercignani, Teoria e applicazioni della serie di Fourier, Milano,
  Tamburini Editore, 1972.
- Ulisse Dini (1880): Serie di Fourier e altre rappresentazioni analitiche
  delle funzioni di una variabile reale T. Nistri.
- (EN) William E. Byerly (1893): An elementary treatise on Fourier's series
  and spherical, cylindrical, and ellipsoidal harmonics with applications
  to problems in mathematical physics Ginn & Company.
- (EN) Horatio S. Carslaw (1921): Introduction to the theory of Fourier's
  series and integrals, Macmillan & co., ltd.
- (EN) E. W. Hobson (1926): The Theory Of Functions Of A Real Variable And
  The Theory Of Fourier's Series Vol. 2, Cambridge University Press.
- (EN) Antoni Zygmund (1935): Trigonometrical series, Subwencji Fundusz
  Kultury Narodowej
- (EN) Yitzhak Katznelson (1976): An introduction to harmonic analysis,
  Second corrected edition. Dover Publications, ISBN 0-486-63331-4

Voci correlate

- Analisi armonica
- Analisi di Fourier
- Base (algebra lineare)
- Calcolo umbrale
- Combinazione lineare
- Convoluzione
- Fenomeno di Gibbs
- Funzione periodica
- Polinomio trigonometrico
- Rappresentazione spettrale dei segnali
- Sinusoide
- Spazio di Hilbert
- Teorema di Parseval
- Teorema di Riesz-Fischer
- Teoria di Sturm-Liouville
- Trasformata di Fourier

Altri progetti

- Wikimedia Commons contiene immagini o altri file su Serie di Fourier

Collegamenti esterni

- (EN) S.A. Telyakovskii, Fourier series, in Encyclopaedia of Mathematics,
  Springer e European Mathematical Society, 2002.
- (EN) Eric W. Weisstein, Fourier Series, in MathWorld, Wolfram Research.
- Java applet che visualizza lo sviluppo in serie di Fourier di una
  qualsiasi funzione
- Serie di Fourier, in Thesaurus del Nuovo soggettario, BNCF, marzo 2013.

Circonferenza unitaria

In matematica, una circonferenza unitaria è una circonferenza di raggio
unitario, cioè una circonferenza il cui raggio è 1. Frequentemente,
specialmente in trigonometria, la circonferenza unitaria è centrata
nell'origine (0,0) in un sistema di coordinate cartesiane nel piano
euclideo.

La circonferenza unitaria è spesso indicata con S¹; la generalizzazione a
più dimensioni è la sfera unitaria.

Se (x,y) è un punto della circonferenza unitaria del primo quadrante,
allora x e y sono le lunghezze dei lati di un triangolo rettangolo la cui
ipotenusa ha lunghezza 1. Quindi, per il teorema di Pitagora, x e y
soddisfano l'equazione

x² ⁺ y² ⁼ ¹.

Poiché x²⁼⁽-x)² per ogni x, e poiché la riflessione di ogni punto della
circonferenza unitaria sull'asse x (o y) appartiene ancora alla
circonferenza unitaria, l'equazione precedente vale per ogni punto (x,y)
della circonferenza unitaria, non solo nel primo quadrante.

Si può anche usare la nozione di "distanza" per definire altre
"circonferenze unitarie".

Ovvero le si può definire come il luogo dei punti che hanno distanza
unitaria (modulo uguale a 1) dall'origine. In coordinate polari l'equazione
sarà

z=1.

Vedere la voce sugli spazi normati per alcuni esempi.

Il cerchio unitario è il luogo dei punti del piano aventi una distanza
minore o uguale all'unità da un punto detto centro del cerchio. In altri
termini il cerchio unitario comprende la circonferenza unitaria e la parte
di piano racchiusa dalla circonferenza stessa. Esso è indicato dalle
disequazioni:

x^2 + y^2 \leq 1
z\leq 1

Funzioni trigonometriche sulla circonferenza unitaria

Le funzioni trigonometriche coseno e seno possono essere definite sulla
circonferenza unitaria come segue. Se (x,y) è un punto della circonferenza
unitaria, e se il raggio dall'origine (0,0) a (x,y) forma un angolo t con
l'asse x positivo, (l'angolo misurato nel verso antiorario), allora

\cos (t) = x
\sin (t) = y

Per definizione delle funzioni seno e coseno, l'equazione x²⁺y²⁼¹ fornisce
la relazione

\cos ^2(t) + \sin ²⁽t) = 1,

che è vera per ogni t reale.

t è definito come un angolo orientato, che cioè assume un segno positivo in
un verso e negativo nell'altro, a seconda della convenzione oraria o
antioraria adottata. Solitamente si adotta la convenzione antioraria, e si
suppone che l'angolo sia positivo spostandosi dall'asse delle ascisse in
senso antiorario. Una circonferenza con tale angolo orientato è detta
circonferenza goniometrica.

La circonferenza trigonometrica è una circonferenza goniometrica di raggio
unitario (ossia goniometrica e unitaria). Essa è detta trigonometrica
perché per definire seno, coseno, e da essi tutte le altre funzioni
trigonometriche, servono un angolo orientato e un raggio unitario. Gli
altri elementi presenti nei disegni sono una costruzione di geometria
euclidea.

La circonferenza unitaria fornisce un modo intuitivo per visualizzare il
seno e il coseno come funzioni periodiche, con le identità

  \cos t = \cos (2πk+t) \sin t = \sin (2πk+t) per ogni k intero.

Queste identità discendono dal fatto che le coordinate x e y di un punto
sulla circonferenza unitaria rimangono le stesse incrementando o
decrementando l'angolo t è di un numero qualsiasi di giri (1 giro = 2π
radianti).

Quando si lavora con triangoli rettangoli, seni, coseni, e altre funzioni
trigonometriche ha senso parlare di misura di angoli maggiore di zero e
minore di π/2. Tuttavia, usando la circonferenza unitaria, queste funzioni
hanno un significato intuitivo per ogni misura di angolo reale.

In effetti, non solo seno e coseno, ma tutte le sei funzioni
trigonometriche standard — seno, coseno, tangente, cotangente, secante, e
cosecante, come anche le funzioni arcaiche come senoverso e exsecante —
possono essere definite geometricamente in termini della circonferenza
unitaria.

Area della circonferenza unitaria

Prendendo in considerazione solo la parte della circonferenza descritta
dall'equazione y=√(undefined){1 - x²} che la rappresenta nel 1° e nel 2º
secondo quadrante, l'area di questa si calcolerà con un integrale
∫_{-1}^{1} √(1 - x²) dx = \frac π{2}. Allo stesso modo prendendo in
considerazione la parte y=-√(1 - x²),che descrive la circonferenza nel 3° e
nel 4° quadrante, l'integrale che ne definisce l'area sarà ∫_{-1}^{1} -√(1
- x²) dx = \frac π{2}. Si può dire pertanto che l'area della circonferenza
unitaria ha come valore π, visto che si può considerare come la somma dei
due integrali

∫_{-1}^{1} √(1 - x²) dx + ∫_{-1}^{1} -√(1 - x²)dx = ∫_{-1}^{1} \pm √(1 -
x²)dx = \frac π{2} + \frac π{2} = π.

Si può inoltre dimostrare la veridicità di questa formula attraverso
l'utilizzo della formula per calcolare l'area è A = r^2·π.

Sapendo che r = 1 otteniamo che A =π C.V.D.

Gruppo circolare

Ogni numero complesso può essere identificato con un punto del piano
euclideo, chiamando il numero complesso a+bi esso è identificato con il
punto (a,b). Con questa relazione la circonferenza unitaria è un gruppo
sotto la moltiplicazione, chiamato anche gruppo circolare. Questo gruppo ha
importanti applicazioni in matematica e nelle scienze.

Voci correlate

- Funzioni trigonometriche
- Angolo
- Quadrato unitario
- Palla unitaria
- Gruppo circolare

Altri progetti

- Wikimedia Commons contiene immagini o altri file su Circonferenza
  unitaria

Combinazione lineare

In matematica, una combinazione lineare è un'operazione principalmente
usata nell'ambito dell'algebra lineare. Una combinazione lineare di alcuni
elementi di uno spazio vettoriale è un'espressione del tipo:¹

a_1v_1+…+aₙvₙ

dove i v_i sono elementi dello spazio vettoriale e gli a_i sono scalari. Il
risultato di questa combinazione è un nuovo elemento dello spazio. Questa
nozione molto generale si applica in vari contesti: si possono scrivere ad
esempio combinazioni lineari di vettori nel piano o nello spazio, di
matrici, di polinomi o di funzioni.

Definizioni

Combinazione lineare

Sia V uno spazio vettoriale su un campo K. Siano v_1,…,vₙ vettori di V .
Una combinazione lineare di questi è il vettore individuato dalla seguente
scrittura:

a_1 v_1 + a_2 v_2 + …+ aₙ vₙ

dove a_1,…,aₙ sono scalari, cioè elementi di K. Gli scalari nella
precedente espressione possono essere scelti ad arbitrio e sono detti
coefficienti della combinazione lineare.

Combinazione affine e convessa

Se il campo K è il campo \R dei numeri reali e i coefficienti sono tutti
non-negativi, cioè:

a_i \geq 0

per ogni i, la combinazione è chiamata positiva.

Quando i coefficienti hanno come somma 1:

a_1 + a_2 + ⋯+ aₙ ₌ ₁

la combinazione è detta affine. Una combinazione lineare sia positiva che
affine è detta combinazione convessa. Entrambe queste nozioni sono utili in
geometria affine, per definire le nozioni di coordinate affini e coordinate
baricentriche.

Proprietà

Unicità della combinazione

In genere, cioè per una generica scelta dei vettori v_i, il vettore:

v = a_1v_1+…aₙvₙ

non determina univocamente la combinazione lineare, cioè la sequenza dei
suoi coefficienti: lo stesso v può essere il risultato di combinazioni
lineari differenti degli stessi vettori v_1,…, vₙ.

Se i vettori sono indipendenti, la combinazione lineare è però unica.

Sottospazio generato

I vettori v che si ottengono come combinazioni lineari di n vettori
fissati, al variare degli scalari a_1,…, aₙ, formano un sottospazio
vettoriale di V, chiamato sottospazio generato. Si indica generalmente con:

\mathrm{Span} ( v_1 ,…, v_n) := {a_1 v_1 + ⋯+ a_n v_n | a_1 ,…, a_n \in K }

Generalizzazioni

Le definizioni di combinazione lineare e span lineare possono essere
generalizzate dagli spazi vettoriali ai moduli o agli anelli. Ad esempio,
si può parlare di combinazione lineare am + bn di due numeri interi m e n ,
dove a e b sono coefficienti interi.

Note

[1] (EN) Eric W. Weisstein, Linear Combination, in MathWorld, Wolfram
  Research.

Bibliografia

- (EN) David C. Lay, Linear Algebra and Its Applications, 3rd,
  Addison–Wesley, 2006, ISBN 0-321-28713-4.
- (EN) Gilbert Strang, Linear Algebra and Its Applications, 4th, Brooks
  Cole, 2006, ISBN 0-03-010567-6.
- (EN) Sheldon Axler, Linear Algebra Done Right, 2nd, Springer, 2002, ISBN
  0-387-98258-2.

Voci correlate

- Sottospazio generato
- Dipendenza lineare
- Dimensione (spazio vettoriale)
- Estrazione di una base
- Combinazione lineare di orbitali atomici
- Combinazione convessa
- Insieme di generatori

Analisi di Fourier

In analisi matematica, l'analisi di Fourier è una branca di ricerca che
prende il suo stimolo dalle ricerche di Jean Baptiste Joseph Fourier che,
nei primi anni dell'Ottocento, riuscì a dimostrare che una qualunque
funzione periodica poteva essere vista come una somma di infinite
"opportune" funzioni sinusoidali (seno e coseno). Grazie a tale scoperta si
è potuto scomporre funzioni complicate in una serie di funzioni che prende
il nome proprio di serie di Fourier, che ne rendono l'analisi più semplice.
Dalla serie di Fourier discende anche la nozione di trasformata di Fourier
ed il concetto di dominio della frequenza. È nota anche come analisi
armonica.

Bibliografia

- (EN) Elias M. Stein, Guido Weiss (1971): Introduction to Fourier Analysis
  on Euclidean Spaces, Princeton University Press, ISBN 069108078X
- (EN) Levan Zhizhiashvili (1996): Trigonometric Fourier Series and their
  Conjugates, Kluwer, ISBN 0-7923-4088-4
- (EN) Audrey Terras (1999): Fourier Analysis on Finite Groups and
  Applications, Cambridge University Press, ISBN 0-521-45108-6
- (EN) George Bachman, Lawrence Narici, Edward Beckenstein (2000): Fourier
  and Wavelet Analysis, Springer, ISBN 0-387-98899-8
- (EN) Yitzhak Katznelson (2004): An introduction to harmonic analysis, 3rd
  ed., Cambridge University Press, ISBN 0-521-83829-0; 0-521-54359-2

Voci correlate

- Trasformata di Fourier
- Serie di Fourier

Altri progetti

- Wikimedia Commons contiene immagini o altri file su Analisi di Fourier

Collegamenti esterni

- Analisi di Fourier, in Thesaurus del Nuovo soggettario, BNCF, marzo 2013.

Analisi armonica

L'analisi armonica è la branca dell'analisi matematica che studia la
rappresentazione delle funzioni o dei segnali come sovrapposizione di onde
fondamentali. Indaga e generalizza la nozione di serie di Fourier e
trasformata di Fourier. Le onde fondamentali sono chiamate "armoniche", da
cui il nome "analisi armonica". Nei precedenti due secoli è diventato un
tema molto vasto con applicazioni in diverse aree come elaborazione
numerica dei segnali, meccanica quantistica e neuroscienze.

La classica trasformata di Fourier su \R ⁿ è ancora oggetto di ricerca, in
particolare la trasformazione di Fourier di oggetti più generali come le
distribuzioni temperate. Ad esempio, se si impongono alcuni requisiti a una
distribuzione f, si può cercare di tradurre questi requisiti in termini
della trasformata di Fourier di f. Il teorema di Paley-Wiener è un esempio
di questo. Il teorema di Paley-Wiener implica immediatamente che se f è una
distribuzione non nulla di supporto compatto (questa definizione include le
funzioni di supporto compatto), allora la sua trasformata di Fourier non ha
mai supporto compatto. Questa è una forma molto elementare di principio di
indeterminazione nell'ambito dell'analisi armonica.

Le serie di Fourier possono essere agevolmente studiate nel contesto degli
spazi di Hilbert, che offre un collegamento fra analisi armonica e analisi
funzionale.

Analisi armonica astratta

Una delle branche più moderne dell'analisi armonica, avente le sue radici
nella metà del XX secolo, è l'analisi matematica sui gruppi topologici. La
motivazione centrale è il fatto che le varie trasformate di Fourier possono
essere generalizzate a una trasformata di funzioni definite su gruppi
localmente compatti.

La teoria per i gruppi abeliani localmente compatti è detta dualità di
Pontryagin.

L'analisi armonica studia le proprietà di questa dualità e della
trasformata di Fourier; e i tentativi di estendere queste caratteristiche
in ambiti differenti, ad esempio al caso dei gruppi di Lie non abeliani.

Nel caso di generici gruppi non abeliani localmente compatti l'analisi
armonica è strettamente legata alla teoria delle rappresentazioni dei
gruppi unitari. Nel caso dei gruppi compatti, il teorema di Peter-Weyl
spiega come si possano ottenere armoniche scegliendo una rappresentazione
irriducibile fra diverse classi di rappresentazioni. Questa scelta di
armoniche gode di alcune delle utili proprietà della trasformata di Fourier
classica, come trasformare le convoluzioni in prodotti puntuali, oppure
mostrare una certa comprensione della struttura di gruppo sottostante.

Se il gruppo non è né abeliano né compatto, non è nota nessuna teoria
soddisfacente. Per "soddisfacente" si intende almeno l'equivalente del
teorema di Plancherel. Comunque sono stati analizzati molti casi
particolari, ad esempio SLₙ. In questo caso, si ha che le rappresentazioni
in infinite dimensioni giocano un ruolo cruciale.

Altre branche

- Lo studio degli autovalori e degli autovettori del laplaciano su domini,
  varietà e (in misura minore) grafi è considerato ancora una branca
  dell'analisi armonica.
- L'analisi armonica sugli spazi euclidei si occupa delle proprietà della
  trasformata di Fourier su \R ⁿ che non hanno analoghi nei gruppi
  generici. Ad esempio, il fatto che la trasformata di Fourier è invariante
  per rotazioni. La decomposizione della trasformata nelle sue componenti
  radiali e sferiche porta a oggetti come le funzioni di Bessel e le
  armoniche sferiche.
- Nel caso di domini a tubo si occupa di generalizzare le proprietà degli
  spazi di Hardy a dimensioni superiori.

Bibliografia

- (EN) Elias M. Stein and Guido Weiss, Introduction to Fourier Analysis on
  Euclidean Spaces, Princeton University Press, 1971. ISBN 0-691-08078-X
- (EN) Yitzhak Katznelson, An introduction to harmonic analysis, Third
  edition. Cambridge University Press, 2004. ISBN 0-521-83829-0; ISBN
  0-521-54359-2
- (EN) Mark Kac, Can one hear the shape of a drum?, in American
  Mathematical Monthly, vol. 73, 4, part 2, 1966, pp. 1-23.
- (EN) Elias Stein with Timothy S. Murphy, Harmonic Analysis: Real-Variable
  Methods, Orthogonality, and Oscillatory Integrals, Princeton University
  Press, 1993.
- (EN) Elias Stein, Topics in Harmonic Analysis Related to the
  Littlewood-Paley Theory, Princeton University Press, 1970.
- Yurii I. Lyubich. Introduction to the Theory of Banach Representations of
  Groups. Translated from the 1985 Russian-language edition (Kharkov,
  Ukraine). Birkhäuser Verlag. 1988.

Voci correlate

- Analisi di Fourier
- Serie di Fourier
- Spazio di Hilbert
- Trasformata di Fourier

Altri progetti

- Wikimedia Commons contiene immagini o altri file su analisi armonica

Collegamenti esterni

- (EN) E. M. Nikishin, Harmonic analysis, in Encyclopaedia of Mathematics,
  Springer e European Mathematical Society, 2002.
- (EN) E. A. Gorin; A. I. Shtern, Harmonic analysis, abstract, in
  Encyclopaedia of Mathematics, Springer e European Mathematical Society,
  2002.
- Analisi armonica, in Thesaurus del Nuovo soggettario, BNCF, marzo 2013.

Radice (matematica)

In matematica, una radice di una funzione f è un elemento x nel dominio di
f tale che f(x)=0. La definizione quindi generalizza la nozione di
radicale, che è in questa chiave la radice delle funzioni della forma:

f(x) = xⁿ - a

Questa definizione è molto importante in algebra quando f è un polinomio,
per cui si parla anche di zero.

In analisi complessa le radici di un polinomio sono dette zeri. Il teorema
fondamentale dell'algebra garantisce l'esistenza di un numero di radici
(contate con molteplicità) uguale al grado del polinomio.

Tra i casi non polinomiali più studiati, l'ipotesi di Riemann è una famosa
congettura riguardante gli zeri della funzione zeta di Riemann.

Definizione

Sia f:X→Y una funzione fra due insiemi, tale che Y contiene un elemento
"zero". Ad esempio, Y può essere l'insieme dei numeri reali, interi, o un
qualsiasi altro gruppo. Un elemento x \in X è una radice di f se

f(x)=0

in altre parole, se l'immagine di x tramite f è zero (vedi la voce nucleo
per una trattazione da un punto di vista algebrico).

Esempi

Denotiamo con \mathbb{R} l'insieme dei numeri reali. Si consideri la
funzione polinomiale f:\mathbb{R} →\mathbb{R} data da:

f(x)=x²-6x+9

Il numero 3 è radice di f, perché f(3)=3^2-(6\times 3)+9 =0. Più in
generale, le radici di una funzione f:\mathbb{R} →\mathbb{R} sono i punti
in cui il grafico di f interseca l'asse x. Tra queste, la funzione
esponenziale non ha radici, mentre la funzione seno ne ha infinite.

Molteplicità di una radice

Si definisce la molteplicità di una radice a di un polinomio p(x) come il
numero naturale n tale che

p(x) = (x-a)ⁿ q(x)

dove q(a) è diverso da zero. In altre parole, per il teorema di Ruffini, n
è il numero di volte in cui possiamo dividere p per (x - a).

Se il polinomio p si "spezza" come

p(x) = (x-a_1)⋯(x-aₙ₎

allora la molteplicità di a è il numero di volte che compare fra i vari
a_i. La molteplicità è però definita in generale, anche nel caso in cui il
polinomio non si possa fattorizzare, perché siamo nel campo dei numeri
reali, o semplicemente perché non riusciamo a farlo: ad esempio si vede
subito che il polinomio

p(x) = x⁷ -14 x⁵ ⁺³ x³ -741 x²

ha la radice zero con molteplicità 2, infatti

p(x) = x^2 q(x), q(x) = x⁵ - 14 x³ ⁺ ³ x - 741

e 0 non è radice di q.

Numero di radici

Usando il teorema di Ruffini si dimostra facilmente per induzione che un
polinomio p(x) di grado n ha al più n radici, nel modo seguente:

- se n = 1 otteniamo una equazione di primo grado, che ha sempre una sola
  soluzione;
- per n > 1: se a è una radice di p, allora il teorema di Ruffini asserisce
  che p(x) = (x - a)q(x), dove q è un altro polinomio di grado n-1. Per
  l'ipotesi induttiva q ha al più n-1 radici distinte. D'altra parte, se
  p(x) = 0 allora (x - a) = 0 oppure q(x) = 0: quindi una radice di p è a
  oppure è radice di q. Quindi p ha al più n radici.

Sempre usando il teorema di Ruffini, si vede che p ha n radici se e solo se
possiamo scrivere

p(x) = (x-a_1)⋯(x-aₙ₎

dove a_1, …, aₙ sono numeri reali distinti (le radici di p).

Radici multiple e valore della derivata
Il teorema di Ruffini permette di osservare facilmente che se a è una
radice con molteplicità superiore a 1, allora la derivata del polinomio si
annulla in a ,cioè p ^{\prime } (a) = 0. Basta osservare che il polinomio
si scompone come p(x) = (x-a)² q(x) e che calcolando la derivata, si
ottiene un polinomio multiplo di (x-a)

Equazione p(x) = b (con p(x) polinomio di grado n)
L'equazione è equivalente a p(x) - b = 0. Poiché p(x) - b è un polinomio di
grado n, l'equazione ammette sempre n radici (tenuto conto delle radici
multiple). È possibile dimostrare che esistono al massimo n-1 valori di b
per cui l'equazione ammette radici multiple (equivalentemente: esistono al
massimo n-1 valori di b per cui la controimmagine p^{-1} (b) ha cardinalità
inferiore a n).

La dimostrazione utilizzando quanto detto sopra rispetto al fatto che se a
è una radice con molteplicità superiore a 1, allora la derivata p ^{\prime
} (a) si annulla.

Radici di polinomi reali

Determinazione completa

Un polinomio in una variabile a coefficienti reali è interpretabile come
una particolare funzione p:\mathbb{R} →\mathbb{R} . Lo studio delle radici
di un dato p è stato sempre un problema centrale nello sviluppo della
matematica, che equivale a risolvere l'equazione p(x) = 0, il cui grado è
pari al grado di p. Il teorema di Niels Henrik Abel e Paolo Ruffini
asserisce che non esistono sempre formule analoghe per le equazioni di
grado maggiore al quarto, per cui è necessario l'ausilio della teoria dei
gruppi. Alcune di queste sono tuttavia riconducibili con la Regola di
Ruffini a equazioni di grado minore o uguale al quarto, per cui la
soluzione sotto forma di radicale esiste sempre.

Determinazione parziale

- Il criterio di Cartesio trova il numero massimo di radici a parte reale
  positiva e/o negativa di un polinomio di grado finito.
- Il criterio di Routh-Hurwitz trova invece il numero di radici a parte
  reale positiva e/o negativa di un polinomio di grado finito.
- Il criterio di Jury stabilisce se un polinomio di grado finito abbia
  radici di modulo minore di uno.

Polinomi semplici notevoli

Un polinomio a coefficienti reali di grado dispari ha sempre una radice
reale, mentre esistono polinomi di grado pari (arbitrariamente alto) che
non ne hanno. In particolare:

- un polinomio di primo grado ha sempre una radice reale;
- un polinomio di secondo grado ha due radici reali se il discriminante è
  strettamente positivo, due coincidenti se è nullo, due complesse
  coniugate se è negativo;
- un polinomio di terzo grado ha 1 o 3 radici reali.

Polinomi e radici complesse

Un polinomio reale può non avere radici: ad esempio p(x) = x² ⁺ ¹ non ne
ha, perché x^2 \ge 0 per ogni x \in \mathbb{R} . Per questo motivo sono
stati introdotti i numeri complessi, che soddisfano molte proprietà
mancanti ai numeri reali. Visto nel campo dei numeri complessi, lo stesso
polinomio p(x) = x² ⁺ ¹ ha due radici: \pm i.

Il teorema fondamentale dell'algebra asserisce infatti che un qualsiasi
polinomio p a coefficienti complessi ha almeno una radice (il campo
complesso è algebricamente chiuso). Usando il teorema di Ruffini come
sopra, si dimostra come conseguenza che p si può sempre scrivere come

p(x) = (x-a_1)⋯(x-aₙ₎

dove a_1, …, aₙ sono numeri complessi non necessariamente distinti.

Determinazione numerica

Viene in aiuto, per calcolare gli zeri di funzioni non polinomiali,
l'analisi numerica, che ha sviluppato vari metodi iterativi che, seppur non
fornendo il valore esatto del punto, vi si avvicinano con approssimazioni
accettabili. I metodi principali sono:

- Metodo della bisezione
- Metodo delle tangenti o di Newton-Rapson
- Metodo delle secanti
- Iterazione di punto fisso

Voci correlate

- Zero (analisi complessa)
- Radice (simbolo)
- Polinomio
- Teorema di Ruffini
- Criterio di Cartesio
- Criterio di Routh-Hurwitz
- Criterio di Jury
- Radicale (matematica)
- Analisi numerica

Teorema fondamentale dell'algebra

Il teorema fondamentale dell'algebra asserisce che ogni polinomio di grado
n \ge 1 (cioè non costante), a coefficienti reali o complessi del tipo:

a_nz^n+ …+a₁z + a₀

ammette almeno una radice complessa o zero. Dal teorema segue che il
polinomio ammette precisamente n radici complesse contate con la loro
molteplicità, mentre ammette al massimo n radici reali.

Storia

Un'enunciazione del teorema in una pubblicazione fu opera del matematico di
origine fiamminga Albert Girard nel 1629 nel libro L'invention en algebre,
per quanto anticipata da una formulazione debole da parte di Peter Roth,
riportata nei suoi Arithmetica Philosophica (1608).¹ Non vi era comunque
alcuna dimostrazione. Nel 1702 Leibniz sostenne di aver trovato un
controesempio con il polinomio x⁴⁺¹. Nel 1742 Nicolas Bernoulli e Christian
Goldbach in una lettera inviata allo stesso Leibniz dimostrarono
l'esistenza di radici complesse del polinomio.²

Il primo tentativo serio di dimostrazione del teorema fu operato da
d'Alembert nel 1746, il quale però utilizzò un teorema non ancora
dimostrato (la dimostrazione fu fatta da Puiseux nel 1751 utilizzando lo
stesso teorema fondamentale dell'algebra). Altri tentativi di dimostrazione
furono portati avanti nel 1749 da Eulero, Lagrange nel 1772, Laplace nel
1795.

Finalmente nel 1799 Gauss riuscì nell'intento sfruttando i tentativi dei
suoi predecessori. Infine, nel 1814 Jean-Robert Argand, un libraio
appassionato di matematica, pubblicò un'altra dimostrazione molto più
semplice rispetto a quella di Gauss.

Esempi

Polinomi a coefficienti reali

Un numero reale è un particolare numero complesso: il teorema è quindi
valido per ogni polinomio a coefficienti reali. Ad esempio, si consideri il
polinomio

p(z) = z²⁺¹

Questo polinomio non ammette nessuna radice reale: i numeri reali non
formano un campo algebricamente chiuso. Per il teorema fondamentale
dell'algebra, il polinomio ha però almeno una radice complessa: questa è
l'unità immaginaria z=i. Infatti:

p(i) = i²⁺¹ ⁼ -1+1 = 0

Questa non è però l'unica radice. Il polinomio ha grado due e ha due radici
complesse i e -i.

Dimostrazioni

Esistono numerose dimostrazioni del teorema fondamentale dell'algebra che
coinvolgono settori molto diversi della matematica come la topologia,
l'analisi complessa e l'algebra.

Dimostrazione basata sullo sviluppo in serie di Taylor

Sia p(z) un polinomio a coefficienti complessi di grado n \geq 1.

Abbiamo \lim _{|z| →+\infty } |p(z)| = +\infty , quindi esiste r > 0 tale
che

|p(z)| > |p(0)| per ogni z \in \mathbb{C} tale che |z| > r.

Il disco chiuso D_r := {z \in \mathbb{C} : |z| \leq r } è compatto, dunque
per il teorema di Weierstrass esiste un punto z_0 \in D_r in cui |p(z)|
assume il suo minimo valore assoluto in D_r.

Proviamo che |p(z₀₎| = 0: sviluppando p(z) in serie di Taylor intorno a z₀
abbiamo

∀z \in \mathbb{C} : p(z) = a_0 + a_k (z - z_0)^k + a_{k+1}(z - z_0)^{k+1} +
⋯+ aₙ ₍z-z₀₎ⁿ

dove a₀ ₌ ₚ₍z₀₎, k \geq 1 è intero e a_k, a_{k+1}, …, a_n \in \mathbb{C}
con a_k \neq 0,

notare che la serie di Taylor è finita poiché f^{(m)}(z₀₎ ₌ ₀ per ogni
intero m > n essendo p(z) un polinomio di grado n. Quindi:

p(z) = a₀ ₊ ₐₖ ₍z-z₀₎^k + R(z)

dove R(z) = o((z-z₀₎^{k}) per z →z₀.

Per ogni ε> 0 possiamo scegliere z \in \mathbb{C} di modo che a_k (z-z_0)^k
= -εa₀, in tal caso quando ε→0⁺ allora z →z₀ quindi per ε sufficientemente
piccolo avremo

|R(z)| = |o((z-z_0) εa_0 / a_k)| < \tfrac 1{2}εa₀

pertanto

|p(z)| \leq |(1-ε)a_0| + |R(z)| < (1-\tfrac 1{2}ε)|a₀| < |p(z₀₎|

ovvero si è trovato un assurdo.

Dimostrazione basata sull'analisi complessa

Sia p(z) un polinomio complesso, tale che p(z)\neq 0 per ogni z complesso.
Allora la funzione

f(z)=\frac{1}{p(z)}

è una funzione intera, cioè è una funzione olomorfa su tutto \mathbb{C} .
D'altra parte

\lim _{|z|→+\infty } |p(z)|=+ \infty

implica

\lim _{|z|→+\infty } |f(z)|=0

e quindi la funzione f(z) è limitata. Per il teorema di Liouville f(z) è
costante, da cui segue che anche p(z) è costante.

Quindi gli unici polinomi senza zeri sono i polinomi costanti.

Dimostrazione topologica

Consideriamo un polinomio a coefficienti complessi non costante

P(z)=a_n z^n+a_{n-1}z^{n-1}+…+a₁ z+a₀

vogliamo dimostrare che esiste un punto α tale che P(α)=0. A tale scopo
possiamo considerare il caso in cui aₙ₌₁.

Supponiamo per assurdo che P non ammetta radici, cioè che l'origine non sia
nella sua immagine. Consideriamo sul piano complesso la circonferenza di
centro l'origine e raggio r parametrizzata da

γ_r(t)=r e^{it}

Il polinomio P rappresenta una funzione continua del piano complesso in sé
stesso e come tale manderà la circonferenza γ_r in una curva piana
parametrizzata P(γ_r). La curva così ottenuta non passerà per l'origine dal
momento che abbiamo assunto che 0 non è nell'immagine di P, e questo
qualunque sia il raggio r. Quindi possiamo considerare l'indice di
avvolgimento di P(γ_r) rispetto all'origine I(P(γ_r),0)

Poniamo

Φ(r)=I(P(γ_r),0), !

Poiché l'indice di avvolgimento non varia per deformazioni della curva tali
che questa non tocchi mai l'origine (è un invariante omotopico) la funzione
Φ(r) sarà continua e poiché l'indice assume solo valori interi dovrà anche
essere una funzione costante.

Ora consideriamo il valore di Φ(r) per due differenti valori di r:

- per r=0 la curva γ_r è costituita da un unico punto (l'origine) e la sua
  immagine sarà quindi anch'essa un unico punto che non può essere
  l'origine. In questo caso evidentemente si ha che I(P(γ_0),0)=Φ(0)=0.
- per r abbastanza grandi affinché si abbia r>1, r>|a_{n-1}|+...+|a₀|
  abbiamo che la curva P(γ_r) può essere deformata con continuità nella
  curva γⁿ_r definita dat ↦rⁿ e^{int}
  immagine di γ_r mediante la funzione polinomiale zⁿ. Poiché l'indice di
  questa curva rispetto all'origine è n e per l'invarianza omotopica
  possiamo dedurre che Φ(r)=n.
  Per dimostrare questo osserviamo che finché z si trova nella
  circonferenza |z|=r vale la seguente catena di
  disuguaglianze:|P(z)-zⁿ|=|a_{n-1}z^{n-1}+...+a₁ z+a₀|
  \leq |a_{n-1}||z|^{n-1}+...+|a₁| |z|+|a₀|
  = |a_{n-1}|r^{n-1}+...+|a₁| r+|a₀|
  < r^{n-1}(|a_{n-1}|+...+|a₁|+|a₀|)
  < r^{n-1}·r =rⁿ⁼|zⁿ|
  questo significa che fintanto che z si trova sulla circonferenza di
  raggio r la distanza che separa il punto P(z) della curva immagine dal
  punto zⁿ è minore di quella che separa il punto zⁿ dall'origine, dunque
  il segmento che congiunge P(z) a zⁿ non tocca l'origine per ogni z in γ_r
  e questo permette di definire una deformazione continua di P(γ_r) in γⁿ_r
  che non faccia passare la curva per l'origine.

Il fatto che Φ(r) assuma valori differenti per differenti raggi contradice
il fatto che deve essere una funzione costante, e siamo quindi giunti a un
assurdo da cui concludiamo che l'ipotesi che P non avesse nessuna radice è
impossibile.

Campi algebricamente chiusi

Si dice che il campo complesso \mathbb{C} è un campo algebricamente chiuso
per indicare il fatto che ogni polinomio di grado maggiore o uguale a 1, a
coefficienti complessi, ha almeno una radice in \mathbb{C} , come
stabilisce il teorema qui esposto. Tale proprietà non è condivisa dai
sottocampi \mathbb{Q} e \mathbb{R} come si può vedere subito considerando i
polinomi

x²-2

che non ha radici nel campo \mathbb{Q} dei razionali, e

x²⁺¹

che non ha radici nel campo \mathbb{R} dei reali.

Note

[1] Il teorema fondamentale dell'algebra (PDF), Università di Pavia. URL
  consultato il 27 ottobre 2013.
[2] Una breve storia del Teorema Fondamentale dell'Algebra (TFA),
  Università di Bari. URL consultato il 27 ottobre 2013.

Collegamenti esterni

- Teorema fondamentale dell'algebra, in Thesaurus del Nuovo soggettario,
  BNCF, marzo 2013.

Ipotesi di Riemann

In teoria analitica dei numeri, l'ipotesi di Riemann è una congettura sulla
distribuzione degli zeri non banali della funzione zeta di Riemann ζ(s),
definita come

ζ(s):=Σ_{n=1}^\infty \frac 1{n^s}

per un numero complesso s con parte reale maggiore di 1 e prolungabile
analiticamente a una funzione meromorfa su tutto il piano complesso.

La congettura fu formulata per la prima volta nel 1859 da Bernhard Riemann,
matematico di Gottinga. Considerata il più importante problema aperto della
matematica,¹ è uno dei ventitré problemi di Hilbert e uno dei sette
Millennium Problems, per la soluzione di ciascuno dei quali il Clay
Mathematics Institute ha offerto un premio da un milione di dollari. La sua
importanza deriva dalle conseguenze che una sua dimostrazione avrebbe sulla
teoria dei numeri primi. Sebbene la maggior parte dei matematici ritenga
l'ipotesi di Riemann vera, vi sono alcune eccezioni, come quelle notevoli
di J. E. Littlewood e Atle Selberg.

Dall'equazione funzionale discende che la funzione zeta di Riemann ζ(s) ha
zeri, detti banali, negli interi pari negativi, s = −2, s = −4, s = −6, ...
La congettura di Riemann riguarda invece gli zeri non banali e afferma che

In altre parole, le radici non banali dovrebbero trovarsi tutte sulla retta
descritta dall'equazione s = 1/2 + it (la cosiddetta "retta critica",
indicata come critical line in Fig. 3) con t numero reale e i unità
immaginaria.

Rapporti con la teoria dei numeri primi

Il primo legame tra la funzione zeta e i numeri primi era già stato
scoperto da Eulero, che notò che per ogni numero reale x > 1 , vale la
formula prodotto di Eulero,

ζ(x) = \prod _{p primo}^\infty \frac{1}{1 - p^{-x}} ,

dove, nella produttoria, p spazia tra tutti i numeri primi.

L'andamento della funzione zeta (e in particolare la distribuzione dei suoi
zeri) risulta quindi legato (attraverso altri passaggi che si omettono)
alla distribuzione dei numeri primi immersi nell'insieme dei numeri
naturali.

È improbabile che Riemann avesse risolto la congettura che porta il suo
nome, non avendo lui mai pubblicato una dimostrazione. È possibile però che
avesse comunque ideato linee di attacco diverse da quelle studiate in
seguito, ma parte delle sue carte fu distrutta dopo la sua morte da una
troppo zelante domestica;² non possiamo quindi sapere per certo se egli
avesse solo impostato o risolto il problema.

Conseguenze

Stabilire una regola matematica che dimostri l'esistenza o meno di una
logica nell'assenza di una cadenza nella distribuzione dei numeri primi,
significherebbe comprendere se vi è un'"aritmia" totale in quest'ultima o
se essa manchi; questo potrebbe avere importanti ricadute sulle
applicazioni informatiche odierne e future, poiché la crittografia utilizza
sovente come chiavi numeri interi la cui fattorizzazione in numeri primi
(molto grandi) non sia calcolabile in tempi accettabili.

L'eventuale conoscenza della distribuzione di tale sequenza potrebbe
permettere quindi di facilitare questa fattorizzazione: si renderebbe
perciò necessario trovare altre tecniche di sicurezza telematica, quali ad
esempio la crittografia con le funzioni ellittiche modulari, però soggette
anch'esse a una congettura pendente (la congettura di Birch e
Swinnerton-Dyer), o la crittografia quantistica, che per il momento sembra
inattaccabile e la cui prima versione Qnet è già disponibile.

Tentativi di dimostrazione

Nel corso degli anni molti matematici hanno affermato di aver dimostrato
l'ipotesi di Riemann. Un caso particolare è costituito da Louis de Branges
de Bourcia, matematico già famoso per aver risolto la congettura di
Bieberbach. Nel 1992, de Branges propose e pubblicò sul suo sito una
dimostrazione basata su argomenti di analisi funzionale, ma i teorici dei
numeri rimasero scettici e otto anni dopo Brian Conrey e Xian-Jin Li
pubblicarono un articolo in cui fornirono controesempi che implicavano la
non correttezza della dimostrazione.³ Negli anni successivi, de Branges ha
modificato spesso la dimostrazione presente sul sito⁴ ⁵ , basandosi
comunque sullo stesso tipo di idee. Tuttavia, sebbene finora nessuno abbia
verificato la correttezza della dimostrazione dopo le modifiche apportate,
anche la nuova versione è ritenuta sbagliata perché gli argomenti
utilizzati sono ritenuti inadeguati ad attaccare il problema.

Note

[1] (EN) Enrico Bombieri, Problems of the Millennium: The Riemann
  Hypothesis (PDF), claymath.org. URL consultato il 13 agosto 2014.
[2] Marcus du Sautoy L'enigma dei numeri primi, Rizzoli, Milano 2004, 186
[3] (EN) http://arxiv.org/abs/math.NT/9812166
[4] (EN) Louis de Branges de Bourcia, Apology For The Proof of The Riemann
  Hypothesis (PDF).
[5] (EN) Louis de Branges de Bourcia, A Proof of The Riemann Hypothesis
  (PDF).

Bibliografia

- Marcus du Sautoy L'enigma dei numeri primi. L'ipotesi di Riemann, il più
  grande mistero della matematica (titolo originale: The Music of the
  Primes - 2003), Milano, Rizzoli, 2004. ISBN 88-17-00098-1 (saggio
  divulgativo).
- John Derbyshire, L'ossessione dei numeri primi, Torino, Bollati
  Boringhieri, 2006. ISBN 88-339-1706-1
- (EN) Brian Conrey, The Riemann Hypothesis (PDF), ams.org. URL consultato
  il 28 febbraio 2009.
- Enrico Bombieri, Problems of the Millennium: The Riemann Hypothesis
  (PDF), claymath.org. URL consultato il 27 dicembre 2014.

Voci correlate

- Ipotesi di Riemann generalizzata
- Problemi irrisolti in matematica

Collegamenti esterni

- Pagina sull'ipotesi di Riemann (sul sito dell'American Institute of
  Mathematics).
- Ipotesi di Riemann, in Thesaurus del Nuovo soggettario, BNCF, marzo 2013.

Teorema del resto

In algebra, il teorema del resto consente di determinare il resto di un
polinomio intero P(x) nella divisione per un binomio della forma (x-a)
senza dover effettuare la divisione. Esso afferma che il resto di tale
divisione è uguale al valore che il polinomio assume per x=a.

Dividendo un polinomio P(x) per un polinomio D(x), si ha una relazione del
tipo:

P(x) = D(x) ·Q(x) + R(x),

dove R(x) è un polinomio di grado minore di quello di D(x). In particolare,
se D(x)=x-a, la relazione diventa:

P(x) = (x - a) ·Q(x) + r,

dove r è una costante numerica. Ponendo x=a si ottiene:

P(a) = (a - a) ·Q(a) + r = r,

quindi : P(a) = r ossia ciò che volevamo dimostrare.

Teorema di Ruffini

Un ovvio corollario del teorema del resto è il teorema di Ruffini:

  Un polinomio P(x) è divisibile per (x-a) se e solo se il resto è nullo e
  quindi P(a)=0.

In questo modo diventa possibile determinare la divisibilità per un binomio
(x-a) senza eseguire la divisione.

Voci correlate

- Algebra elementare
- Divisibilità di binomi notevoli
- Polinomio
- Teorema delle radici razionali
- Teorema di Ruffini

Teorema delle radici razionali

In algebra, il teorema delle radici razionali afferma che ogni soluzione
razionale di un'equazione polinomiale a coefficienti interi:

a_nx^n+a_{n-1}x^{n-1}+...+a_0=0, a_i\in \mathbb Z

è della forma p/q, dove:

- p è un divisore del termine noto a₀
- q è un divisore del coefficiente direttore aₙ.

Il teorema non dà alcuna informazione su eventuali radici irrazionali o
complesse.

Ad esempio, se abbiamo un'equazione della forma

3x³-10x²⁺x-4=0

allora le eventuali radici razionali sono contenute in quest'insieme:

\left {\pm {4\over 3}, \pm {2\over 3}, \pm{1\over 3} , \pm 4, \pm 2, \pm 1
\right }

Se il polinomio è monico, cioè è aₙ₌₁, evidentemente la formula si
semplifica restringendo le opzioni tra i soli divisori del termine noto. La
verifica di ogni singola possibile radice si può ad esempio attuare con il
teorema del resto (oppure con la regola di Ruffini se si vuole avere
direttamente anche direttamente il quoziente). Se nessun valore soddisfa le
richieste, allora tutte le sue radici (che esistono per il teorema
fondamentale dell'algebra) sono irrazionali o complesse. Al contrario, se
sono state trovate n radici razionali, allora il polinomio è completamente
fattorizzabile in polinomi lineari con coefficienti razionali.

Dimostrazione

Il teorema delle radici razionali è una diretta conseguenza del lemma di
Gauss, il quale afferma che se un polinomio (a coefficienti interi) è
fattorizzabile sui razionali, allora lo è anche sugli interi.

Quindi se esiste una radice razionale p/q, questo significa che potremo
scrivere il nostro polinomio iniziale come (qx-p)·(b_{n-1}x^{n-1}+…+b₀₎ con
tutti i b_i interi. Facendo il prodotto (i coefficienti intermedi non ci
interessano) e sfruttando il fatto che due polinomi sono uguali se e solo
se coincidono tutti i coefficienti, avremo a_n=b_{n-1}·q e a_0=b_0·p, da
cui il teorema.

In altro modo, supponiamo che la frazione p / q sia una radice del
polinomio. Possiamo supporre che la frazione sia ridotta ai minimi termini,
ovvero che gli interi p e q siano primi fra loro. Sostituendo si ottiene

a_n(p / q)^n+a_{n-1}(p/q)^{n-1}+…+a₁ ₍ₚ/q)+a₀₌₀,

da cui, moltiplicando per qⁿ,

a_n p^n+a_{n-1} p^{n-1} q+…+a₁ ₚ q^{n-1}+a₀ qⁿ⁼⁰.

Ora p divide i primi n termini, dunque deve dividere anche l'ultimo termine
a₀ qⁿ. Dato che p e q sono primi fra loro, p deve dividere a₀. Con un
ragionamento analogo si vede che q divide aₙ.

Voci correlate

- Regola di Ruffini
- Divisione dei polinomi
- Radice (matematica)
- Teorema fondamentale dell'algebra

Regola di Ruffini

In algebra lineare, la regola di Ruffini permette di dividere velocemente
un qualunque polinomio per un binomio di primo grado della forma x − a. È
stata descritta da Paolo Ruffini nel 1809. La regola di Ruffini è un caso
speciale della divisione polinomiale quando il divisore è un fattore
lineare. La regola di Ruffini è anche nota come divisione sintetica.

L'algoritmo

La regola di Ruffini stabilisce un metodo per dividere il polinomio

P(x)=a_nx^n+a_{n-1}x^{n-1}+⋯+a₁ₓ₊ₐ₀

per il binomio

A(x)=x-r

per ottenere il polinomio quoziente

Q(x)=b_{n-1}x^{n-1}+b_{n-2}x^{n-2}+⋯+b₁ₓ₊b₀

e un resto R che è un termine costante (eventualmente nullo), visto che
deve essere di grado minore rispetto al polinomio divisore.

L'algoritmo non è altro che la divisione polinomiale di P(x) per A(x)
scritto in un'altra forma più economica.

Per dividere P(x) per A(x), infatti:

- Si prendono i coefficienti di P(x) e si scrivono in ordine. Si scrive poi
  r in basso a sinistra, proprio sopra la riga:
\begin{array}{c|c c c c|c} & a_n & a_{n-1} & …& a_1 & a_0 r & & & & &
  \hline & & & & & \end{array}
- Si copia il coefficiente di sinistra (aₙ) in basso, subito sotto la riga:
\begin{array}{c|c c c c|c} & a_n & a_{n-1} & …& a_1 & a_0 r & & & & &
  \hline & a_n & & & & & =b_{n-1} & & & & \end{array}
- Si moltiplica il numero più a sinistra di quelli sotto la riga, per r, e
  il risultato lo si scrive sopra la riga, spostato di un posto a destra:
\begin{array}{c|c c c c|c} & a_n & a_{n-1} & …& a_1 & a_0 r & & b_{n-1} ·r
  & & & \hline & a_n & & & & & =b_{n-1} & & & & \end{array}
- Si somma questo valore con quello sopra di lui nella stessa colonna:
\begin{array}{c|c c c c|c} & a_n & a_{n-1} & …& a_1 & a_0 r & & b_{n-1}·r &
  & & \hline & a_n & b_{n-1}·r+a_{n-1} & & & & =b_{n-1} & =b_{n-2} & & &
  \end{array}
- Si ripetono i passi 3 e 4 fino al termine dei coefficienti
\begin{array}{c|c c c c|c} & a_n & a_{n-1} & …& a_1 & a_0 r & & b_{n-1}·r &
  …& b_1·r & b_0 ·r \hline & a_n & b_{n-1} ·r+a_{n-1} & …& b_1 ·r+a_1 &
  a_0+b_0 ·r & =b_{n-1} & =b_{n-2} & …& =b_0 & =R \end{array}

I valori

b_{n-1}, b_{n-2}, …, b₀

sono i coefficienti del polinomio risultante Q(x), il cui grado sarà
inferiore di uno a quello di P(x), R invece è il resto della divisione.

Un esempio numerico viene fornito più sotto.

Usi della regola

La regola di Ruffini ha varie applicazioni pratiche, molte di esse si
basano sulla divisione semplice (come mostrato sotto) o sulle estensioni
usuali che seguono.

Divisione polinomiale per x − r

Ecco un esempio di divisione polinomiale, con tutti i passaggi evidenziati.

Siano

P(x)=2x³-5x²-x+6
A(x)=x+1

Vogliamo dividere P(x) per A(x) usando la regola di Ruffini. Poiché A(x)
non è della forma x − r, ma piuttosto x + r, è sufficiente riscrivere A(x)
come

A(x)=x+1=x-(-1)

Applichiamo ora l'algoritmo.

- Scriviamo i coefficienti di P(x) e r:
\begin{array}{c| c c c |c} & +2 & -5 & -1 & +6 -1 & & & & \hline & & & &
  \end{array}
- Copiamo il primo coefficiente sotto:
\begin{array}{c| c c c |c} & +2 & -5 & -1 & +6 -1 & & & & \hline & +2 & & &
  \end{array}
- Moltiplichiamo il numero più a sinistra sotto la riga, per r, e
  scriviamolo al posto successivo sopra la riga:
\begin{array}{c| c c c |c} & +2 & -5 & -1 & +6 -1 & & -2 & & \hline & +2 &
  & & \end{array}
- Sommiamo i valori della seconda colonna dopo la riga verticale:
\begin{array}{c| c c c |c} & +2 & -5 & -1 & +6 -1 & & -2 & & \hline & +2 &
  -7 & & \end{array}
- Ripetiamo i passi 3 e 4 fino alla fine:
\begin{array}{c| c c c |c} & +2 & -5 & -1 & +6 -1 & & -2 & 7 & -6 \hline &
  +2 & -7 & +6 & 0 \end{array}

Abbiamo ottenuto, quindi, che:

P(x)=A(x) ·Q(x)+R

dove

Q(x) = 2x²-7x+6
R=0

Divisione polinomiale per ax − k

Applicando una facile trasformazione, la regola di Ruffini si può
generalizzare anche per le divisioni di un polinomio per un binomio
qualsiasi di primo grado A(x)=ax-k. Infatti, considerando la relazione
fondamentale

P(x)=(ax -k) ·Q(x) + R(x)

dividendo tutto per a (sicuramente diverso da 0) otteniamo

\frac{P(x)}{a} =\frac{(ax -k) ·Q(x)}{a} + \frac{R(x)}{a}

Detti P(x)/a = P'(x) e R(x)/a = R'(x) otteniamo

P'(x)=(x -\frac{k}{a} ) ·Q(x) + R'(x)

Dunque il quoziente richiesto Q(x) è anche il quoziente della divisione di
P'(x) per (x-k/a), che si può ottenere con la regola appena esposta. Per
trovare il resto richiesto R(x) basterà moltiplicare il resto ottenuto
R'(x) per a.

Trovare le radici di un polinomio

Il teorema delle radici razionali afferma che se un polinomio

P(x)=a_nx^n+a_{n-1}x^{n-1}+ …+a₁ₓ₊ₐ₀

ha coefficienti interi, le sue radici razionali sono sempre della forma
p/q, dove p e q sono interi coprimi, p è un divisore (non necessariamente
positivo) di a₀ e q un divisore di aₙ. Se il nostro polinomio è quindi

P(x)=x³-4x²⁺⁵x-2

le radici razionali possibili appartengono all'insieme dei divisori interi
di -2/1 che sarà:

\left {+1, -1, +2, -2\right }

Questo è un esempio semplice, perché il polinomio è monico (cioè, aₙ=1);
per i polinomi non monici, l'insieme delle possibili radici comprenderà
alcune frazioni, ma solo in numero finito, dato che aₙ e a₀ hanno ciascuno
un numero finito di divisori interi. In ogni caso per i polinomi monici
ogni radice razionale è un intero, e quindi ogni radice intera dev'essere
un divisore del termine costante. Si può dimostrare che questo resta vero
anche per i polinomi non monici: insomma, per trovare le radici intere di
un polinomio a coefficienti interi, basta verificare i divisori del termine
costante. Infatti, ogni polinomio non monico può essere ricondotto al caso
monico, semplicemente dividendo i coefficienti per aₙ.

Provando pertanto a porre r pari a ciascuna delle radici possibili, si può
provare a dividere il polinomio per (x-r). Se il polinomio quoziente
risultante ha resto 0, abbiamo trovato una radice. Questo metodo però non
permette di trovare radici irrazionali o complesse

Se, per esempio volessimo trovare le radici del precedente polinomio P(x),
dobbiamo dividere P(x) per il binomio (x − a) dove a è una delle radici
possibili. Se il resto è uguale a 0, il numero utilizzato è una radice:

\begin{array}{c|ccc|c} & +1 & -4 & +5 & -2 +1 & & +1 & -3 & +2 \hline & +1
& -3 & +2 & 0 \end{array} \qquad \begin{array}{c|ccc|c} & +1 & -4 & +5 & -2
-1 & & -1 & +5 & -10 \hline & +1 & -5 & +10 & -12 \end{array}
\begin{array}{c|ccc|c} & +1 & -4 & +5 & -2 +2 & & +2 & -4 & +2 \hline & +1
& -2 & +1 & 0 \end{array} \qquad \begin{array}{c|ccc|c} & +1 & -4 & +5 & -2
-2 & & -2 & +12 & -34 \hline & +1 & -6 & +17 & -36 \end{array}

x₁=+1 e x₃=+2 sono radici, mentre x₂=−1 e x₄=−2 non lo sono.

Fattorizzazione polinomiale

Dopo avere usato il metodo "p/q" mostrato sopra (o un qualunque altro modo)
per trovare tutte le radici razionali reali di un certo polinomio, è
semplice sfruttarle per fattorizzare parzialmente il polinomio stesso: a
ogni fattore (x - r) che divide un polinomio dato corrisponde una radice r,
e viceversa.

Quindi, se abbiamo il polinomio:

  P(x)=a_nx^n+a_{n-1}x^{n-1}+⋯+a₁ₓ₊ₐ₀ ;

e abbiamo trovato come sue radici:

  R=\left {\mbox{radici di } P(x)\in \mathbb{Q} \right } ;

consideriamo il prodotto:

Q(x)=a_n{\prod _{r\in R} (x-r)}

Per il teorema fondamentale dell'algebra, Q(x) sarebbe uguale a P(x) se
tutte le radici di P(x) fossero razionali. Ma è assai probabile che Q(x)
non sia uguale a P(x), dato che P(x) potrebbe avere anche radici
irrazionali o complesse. Consideriamo allora il polinomio quoziente

S(x)=\frac{P(x)}{Q(x)}

Se S(x) = 1, allora Q(x) = P(x). Altrimenti, S(x) sarà un polinomio, per la
precisione un altro fattore di P(x) che non ha radici razionali in
\mathbb{R} . Dunque

P(x)=Q(x) * S(x)

è una fattorizzazione completa di P(x) su \mathbb{Q} se S(x) = 1,
altrimenti sarà una fattorizzazione completa su \mathbb{Q} , ma ci saranno
altri fattori su \mathbb{R} o su \mathbb{C} .

Primo esempio: nessun resto

Sia

P(x)=x³⁺²x²-x-2

Con i metodi descritti sopra, troviamo che le radici razionali di P(x)
sono:

R=\left {+1, -1, -2\right }

Pertanto, il prodotto di (x − ciascuna radice) è

Q(x)=1(x-1)(x+1)(x+2)

P(x)/Q(x) dà

S(x)=1

E così il polinomio fattorizzato è P(x) = Q(x) * 1 = Q(x):

P(x)=(x-1)(x+1)(x+2)

Secondo esempio: con resto

Sia

P(x)=2x⁴-3x³⁺x²-2x-8

Con i metodi descritti sopra, troviamo che le radici razionali di P(x)
sono:

R=\left {-1, +2\right }

Pertanto, il prodotto di (x − ciascuna radice) è

Q(x)=(x+1)(x-2)

P(x)/Q(x) dà

S(x)=2x²-x+4

Dato che S(x){\ne }1, il polinomio fattorizzato sui razionali è
P(x)=Q(x)·S(x):

P(x)=(x+1)(x-2)(2x²-x+4)

Voci correlate

- Teorema di Ruffini
- Radice (matematica)
- Criterio di Cartesio
- Criterio di Routh-Hurwitz
- Criterio di Jury

Criterio di Cartesio

Il criterio di Cartesio, descritto nel suo libro La Géométrie, è una regola
algebrica che determina il numero massimo di radici reali positive e
negative di un polinomio a coefficienti reali.

La regola di Cartesio

Sia dato un polinomio a coefficienti reali:

P(x)=a_nx^n+…+a_1x+a_0

con coefficienti a_n,…,a₀ reali e non tutti nulli, avente n radici reali.
La regola di Cartesio stabilisce che:

Il massimo numero di radici reali positive di un polinomio ¹ è dato dal
numero di variazioni di segno fra coefficienti consecutivi, trascurando
eventuali coefficienti nulli; in generale il numero effettivo può essere
diminuito rispetto al massimo soltanto di un numero pari. Inoltre, le
radici sono ordinate in modulo decrescente da quella corrispondente alla
coppia di coefficienti ai gradi massimo e subito precedente fino a quella
corrispondente alla coppia di coefficienti lineare e di grado nullo.

L'informazione relativa al numero di radici negative si deduce applicando
la stessa regola al polinomio trasformato a radici opposte, ossia al
polinomio P(-x). Esso ha infatti radici opposte a quelle di P(x). Perciò:
le variazioni relative ai coefficienti del polinomio P(-x) danno
informazioni circa le sue radici positive e, di conseguenza, circa le
radici negative di P(x).

Se il polinomio ha tutte le radici non immaginarie, il numero di radici
positive è quello massimo. Il criterio di Routh-Hurwitz raffina
determinando il numero effettivo delle radici a parte reale positiva e
negativa.

Esempio

Il polinomioP(x)=x⁵-13x³⁺³⁶xpresenta due variazioni di segno fra
coefficienti di grado 5 e 3 e tra i coefficienti di grado 3 e 1. Questo
indica che ci possono essere 2 o nessuna radice positiva.

Il polinomio trasformato a radici opposte è:

P(-x)=-x⁵⁺¹³x³-36x

che presenta due variazioni di segno. Questo indica che il polinomio P(-x)
può avere due o nessuna radice positiva e quindi il polinomio iniziale può
avere due o nessuna radice negativa.

Le radici del polinomio P(x) sono 0, -2,+2,-3,+3.

Si noti come l'assenza di permanenze di segno nel polinomio iniziale (0
permanenze) non fornisce assolutamente alcuna informazione circa il numero
di radici negative (che infatti risulta essere pari a 2).

Note

[1] per la loro molteplicità

Voci correlate

- Polinomio caratteristico
- Criterio di stabilità di Routh

Polinomio caratteristico

In algebra lineare il polinomio caratteristico di una matrice quadrata su
un campo è un polinomio definito a partire dalla matrice che ne descrive
molte proprietà essenziali.

Il polinomio caratteristico è un oggetto che dipende solo dalla classe di
similitudine di una matrice, e pertanto fornisce molte informazioni sulla
natura intrinseca delle trasformazioni lineari, caratterizzate attraverso
la traccia e il determinante. In particolare, le radici del polinomio sono
gli autovalori della trasformazione lineare associata alla matrice. I
coefficienti del polinomio sono pertanto detti invarianti della matrice e
dell'applicazione ad essa associata.

Il polinomio è anche utilizzato per determinare la forma canonica di luoghi
geometrici esprimibili mediante matrici, come coniche e quadriche.

Definizione

Sia A una matrice quadrata a valori in un campo K. Il polinomio
caratteristico di A nella variabile x è il polinomio definito nel modo
seguente:¹

p_A(x) = \det (A - xI)

cioè è il determinante della matrice A -xI , ottenuta sommando A e -xI .
Qui I denota la matrice identità, avente la stessa dimensione di A , e
quindi -xI è la matrice diagonale avente il valore -x su ciascuna delle n
caselle della diagonale principale.

In particolare, x è autovalore di A se e solo se è radice del suo polinomio
caratteristico.²

Grado e coefficienti del polinomio

Sia A una matrice quadrata di ordine n . Il polinomio caratteristico di A
ha grado n . Alcuni dei suoi coefficienti sono (a meno di segno) quantità
notevoli per la matrice, come la traccia ed il determinante:

p_A(x) = (-1)^nx^n +(-1)^{n-1} \textrm{tr} (A) x^{n-1}+ …+ \det A

Il coefficiente di x^k del polinomio è la somma moltiplicata per (-1)^k dei
{n\choose k} determinanti dei minori (n-k)\times (n-k) "centrati" sulla
diagonale.

Ad esempio, se A è una matrice 2 per 2 si ha:

p_A(x) = x^2 - \textrm{tr} (A)x + \det A

Autovalori

Le radici in K del polinomio caratteristico sono gli autovalori di A.²

Questo si dimostra formalmente ponendo v autovettore di A. Si ha allora Av
= λv , ed in particolare:

(A - λI)v = 0

Si ha quindi che il nucleo dell'applicazione (A-λI) è non nullo se λ è
autovalore, e tale condizione è soddisfatta se e solo se:

\det (A-λI) = 0

Se A è una matrice triangolare (superiore o inferiore) avente i valori
a_{1,1},…, a_{n,n} sulla diagonale principale, allora:

p_A(x) = (a_{1,1}-x)⋯(a_{n,n}-x)

Quindi il polinomio caratteristico di una matrice triangolare ha n radici
nel campo, date dai valori nella diagonale principale. In particolare,
questo fatto è vero per le matrici diagonali.

Invarianza per similitudine e diagonalizzabilità

Due matrici simili hanno lo stesso polinomio caratteristico.³ Infatti, se:

A=M^{-1}BM

per qualche matrice invertibile M, si ottiene:

  p_A(x) = \det (A-xI) = \det (M^{-1}BM - xI) = \det (M^{-1}BM-xM^{-1}M) =
  \det (M^{-1}BM - M^{-1}(xI)M) = \det (M^{-1}(B-xI)M)
  = \det (M^{-1})\det (B-xI)\det M = (\det M)^{-1}p_B(x)\det M = p_B(x)

In tale catena di uguaglianze si fa uso del fatto che la matrice della
forma xI commuta con qualsiasi altra e del teorema di Binet.

Poiché due matrici che rappresentano un endomorfismo T di uno spazio
vettoriale V a dimensione finita sono simili, il polinomio caratteristico è
una grandezza intrinseca di T che riassume molte delle caratteristiche
dell'endomorfismo considerato, come traccia, determinante ed autovalori.
Come conseguenza di questo fatto si ha che T è diagonalizzabile se esiste
una base di V rispetto alla quale la matrice che rappresenta T è diagonale,
e gli elementi della diagonale sono gli autovalori.⁴ In particolare, la
base che diagonalizza T è composta da suoi autovettori.

Il teorema di diagonalizzabilità fornisce, inoltre, un criterio necessario
e sufficiente che permette di stabilire se un'applicazione lineare è
diagonalizzabile. Una matrice quadrata A con n righe è diagonalizzabile se
e solo se valgono entrambi i fatti seguenti:

- La somma delle molteplicità algebriche dei suoi autovalori è n, ovvero il
  polinomio caratteristico può essere fattorizzato nel campo attraverso
  polinomi di primo grado.
- Le molteplicità algebriche e geometriche di ogni autovalore sono
  coincidenti, ovvero la dimensione degli autospazi è pari alla
  molteplicità con la quale il relativo autovalore è radice del polinomio
  caratteristico. Poiché la molteplicità geometrica è sempre minore o
  uguale di quella algebrica, se l'applicazione ha n autovalori distinti
  nel campo allora è diagonalizzabile.

Invarianza per trasposizione

La matrice trasposta A^t ha lo stesso polinomio caratteristico di A.
Infatti

p_{A^t}(x) = \det (A^t-xI)=\det (A^t-xI^t) = \det ((A-xI)^t) =\det (A-xI)
=p_A(x).

Qui si fa uso del fatto che il determinante è invariante per trasposizione.

Esempi

- Data:
A = \begin{pmatrix} 1 & 3 0 & 4 \end{pmatrix}
  allora:
A - xI = \begin{pmatrix} 1 & 3 0 & 4 \end{pmatrix} - x \begin{pmatrix} 1 &
0 0 & 1 \end{pmatrix} = \begin{pmatrix} 1 - x & 3 0 & 4 -x \end{pmatrix}
  e quindi:
p_A(x)=\det (A - xI) = (1 - x)(4 - x)
A
- Data:
B =\begin{pmatrix} 2 & π& 0 -1 & -3 & 5 0 & 4 & 3 \end{pmatrix}
  in modo analogo si trova:
p_B(x) = -x^3 +2x^2 +(29 - π)x -(58-3π)

Note

[1] S. Lang, Pag. 227
[2] S. Lang, Pag. 228
[3] S. Lang, Pag. 229
[4] S. Lang, Pag. 114

Bibliografia

- Serge Lang, Algebra lineare, Torino, Bollati Boringhieri, 1992, ISBN
  88-339-5035-2.
- (EN) T.S. Blyth & E.F. Robertson (1998) Basic Linear Algebra, p 149,
  Springer ISBN 3-540-76122-5.
- (EN) John B. Fraleigh & Raymond A. Beauregard (1990) Linear Algebra 2nd
  edition, p 246, Addison-Wesley ISBN 0-201-11949-8.
- (EN) Werner Greub (1974) Linear Algebra 4th edition, pp 120–5, Springer,
  ISBN 0-387-90110-8.
- (EN) Paul C. Shields (1980) Elementary Linear Algebra 3rd edition, p 274,
  Worth Publishers ISBN 0-87901-121-1.
- (EN) Gilbert Strang (1988) Linear Algebra and Its Applications 3rd
  edition, p 246, Brooks/Cole ISBN 0-15-551005-3.

Voci correlate

- Autovettore e autovalore
- Determinante
- Polinomio minimo
- Teorema di Hamilton-Cayley

Altri progetti

Aliasing

In elettronica l'aliasing (letteralmente impersonazione), o distorsione da
campionamento lento, da sottocampionamento o equivocazione,
nell'elaborazione numerica dei segnali è il fenomeno per il quale due
segnali analogici diversi possono diventare indistinguibili una volta
campionati: questo costituisce un serio problema che si riflette
direttamente sull'uscita del sistema in esame, alterandone la veridicità.
L'aliasing può verificarsi sia nel tempo (aliasing temporale) sia nello
spazio (aliasing spaziale).

Descrizione

I segnali analogici vengono spesso convertiti in digitale per essere
successivamente elaborati o archiviati. Durante questa conversione
analogico-digitale il segnale viene sottoposto a due distinte
discretizzazioni: la discretizzazione dei tempi, detta campionamento, e la
discretizzazione delle ampiezze, detta quantizzazione.
Al contrario nella conversione digitale-analogica il segnale digitale viene
trasformato nuovamente in un segnale analogico operando una interpolazione.

Campionamento di un segnale sinusoidale

Campionando un segnale sinusoidale con una certa frequenza l'insieme dei
punti che si acquisiscono non permette di identificare univocamente una
sola sinusoide. Dato che, tramite l'analisi di Fourier, ogni segnale
continuo può essere visto come sovrapposizione di seni e coseni risulta
importante in teoria dei segnali riuscire a limitare questa ambiguità.

Il teorema del campionamento di Nyquist-Shannon

Un importante risultato matematico in questo ambito è dato dal teorema del
campionamento di Nyquist-Shannon. Questo afferma che, per campionare un
segnale a banda finita senza perdita di informazione, bisogna campionarlo
con frequenza almeno maggiore del doppio rispetto alla frequenza della
massima componente spettrale del segnale informativo (detta anche frequenza
di Nyquist).

Aliasing

Se non viene rispettato tale teorema, cioè si ha un sottocampionamento del
segnale analogico nel dominio del tempo, nel dominio delle frequenze si ha
la produzione di frequenze non proprie del segnale originario (alias) e
viceversa dal dominio della frequenza al dominio del tempo producendo cioè
una distorsione del segnale originario divenuto ora non più fedele.

Diagnostica per immagini

Ecografia

Nell'ecografia Doppler si può incorrere nell'artefatto dell'aliasing. È
tipico del Doppler pulsato e del Color Doppler, mentre non si verifica col
Doppler continuo e nel Power Doppler.
Si verifica quando la frequenza campionata è più alta della metà della
frequenza di emissione degli impulsi. Per tal motivo l'immagine viene
rappresentata come diretta in senso inverso rispetto alla direzione reale.
Per esempio il flusso sanguigno verrà codificato con un colore contrario
alla direzione del flusso rispetto alla sonda: per convenzione infatti il
rosso è utilizzato per indicare un flusso verso la sonda, mentre il blu un
flusso che si allontana. A causa dell'aliasing il colore sarà invertito.

Risonanza magnetica

Quando l'oggetto è di dimensioni superiori al campo di vista, l'immagine
viene ricostruita con le strutture esterne ripiegate sullo strato
esaminato.

Voci correlate

- Antialiasing
- Filtro anti-alias
- Teorema del campionamento di Nyquist-Shannon

Altri progetti

- Wikimedia Commons contiene immagini o altri file su Aliasing

Filtro anti-alias

Il filtro anti-alias è un filtro analogico utilizzato prima del
campionamento di un segnale, al fine di restringere la banda del segnale
stesso per soddisfare approssimativamente il teorema del campionamento di
Nyquist-Shannon. Dal momento che il teorema dice che un'interpretazione non
ambigua del segnale, a partire dal campionamento, è possibile solo quando
la potenza delle frequenze all'esterno della banda di Nyquist è zero, il
filtro anti-aliasing potrebbe soddisfare il teorema. Ogni possibile filtro
anti-alias permetterà la presenza di qualche alias; l'ammontare dell'alias
presente nel risultato dipende dalla qualità del filtro.

I filtri anti-alias vengono solitamente usati nei sistemi di elaborazione
numerica dei segnali, ad esempio in operazioni di audio digitale o
fotografia digitale; filtri simili vengono utilizzati anche nella
ricostruzione dell'output nei lettori musicali. Infine, il filtro evita
l'alias durante la conversione di un campionamento in un segnale continuo,
dove la stop-band rejection è richiesta per garantire l'azzeramento
dell'alias.

L'impossibilità teorica di costruire un filtro perfetto non è, in pratica,
un grande ostacolo, visto che le considerazioni pratiche portano a scelte
implementative quali il sovracampionamento per creare filtri
"sufficientemente buoni".

Filtri anti-alias ottici

In caso di campionamento ottico di un'immagine, ad esempio per i sensori
delle fotocamere digitali, il filtro si chiama anche filtro passa basso
ottico, filtro di blur o AA filter. La matematica del campionamento in due
dimensioni è simile a quella del campionamento a dominio di tempo, ma le
tecniche implementative del filtro sono diverse. L'implementazione tipica
delle fotocamere digitali si basa su un materiale bi-rifrangente a due
strati come il litio niobato, che rilancia ogni punto ottico in un gruppo
di quattro altri punti.¹ La scelta di un particolare filtro obbliga ad una
mediazione tra precisione, aliasing e fattore di riempimento. In una camera
monocromatica, three-CCD o Foveon X3 il fattore di riempimento da solo, se
vicino al 100% con microlenti, è in grado di fornire un buon effetto
anti-alias, mentre nelle camere a colori (CFA, e.g. filtro Bayer) di solito
serve un ulteriore filtro per ridurre l'aliasing a un livello accettabile.²

Applicabilità del sovracampionamento

Una tecnica nota con il nome di sovracampionamento (oversampling) viene
solitamente usata nelle conversioni audio, specialmente nell'output. L'idea
consiste nell'usare una frequenza di campionamento superiore, in modo che
un filtro digitale quasi-ideale possa abbassare l'alias fino alla frequenza
di Nyquist, mentre un filtro analogico più semplice può bloccare le
frequenza superiori ad una nuova più alta frequenza di Nyquist.

L'obiettivo del sovracampionamento è quello di abbassare i requisiti del
filtro anti-alias, o ridurre l'aliasing stesso. Dal momento che il filtro
finale è analogico, il sovracampionamento permette al filtro di essere più
economico visto che i requisiti non sono così rigidi, ed allo stesso tempo
permette al filtro di avere una frequenza di risposta più dolce, e quindi
una risposta con una fase meno complessa.

Sull'input si usa un filtro iniziale analogico, il segnale viene campionato
ad alte frequenze, per poi venire sottocampionato utilizzando un filtro
digitale quasi-ideale.

Forma dello spettro di frequenza

Spesso un filtro anti-aliasing è un filtro passa basso. In ogni caso questo
non è necessario. Il teorema del campionamento di Nyquist-Shannon dice che
la frequenza di campionamento deve essere superiore al doppio della
larghezza della banda, non della frequenza massima, del segnale. Per i tipi
di segnali limitati dalla larghezza di banda, ma non centrati sullo zero,
si potrebbe usare un filtro passa banda come anti-alias. Ad esempio si
potrebbe fare con un Single-sideband modulation o con un segnale a
modulazione di frequenza. Se si volesse campionare un segnale radio FM sul
canale 200, un filtro appropriato sarebbe centrato su 87.9 MHz con una
banda di 200 kHz (o una banda passante da 87.8 MHz a 88.0 MHz), e la
frequenza di campionamento non dovrebbe essere inferiore a 400 kHz. In
questo caso non è l'audio ad essere campionato, ma lo stesso segnale
trasmesso, il che non è comune.

Sovraccarico del segnale

È molto importante evitare un sovraccarico del segnale durante
l'applicazione di un filtro anti-alias. Se il segnale è abbastanza forte,
può utilizzare il clipping di un convertitore analogico-digitale, anche
dopo il filtraggio. Dal momento che la distorsione del segnale creata dal
clipping dell'onda filtrata ha luogo dopo l'applicazione del filtro, i suoi
componenti saranno sparsi su tutto lo spettro di frequenza, comprese quelle
parti di banda che causano l'aliasing. Nell'audio digitale il segnale
"clippato" distorto ha un suono caratteristico che può facilmente essere
riconosciuto.

Note

[1] Adrian Davies, Phil Fennessy, Digital imaging for photographers, Quarta
  edizione, Focal Press, 2001, ISBN 0-240-51590-0.
[2] Brian W. Keelan, Handbook of Image Quality: Characterization and
  Prediction, Marcel–Dekker, 2004, ISBN 0-8247-0770-2.

Voci correlate

- Aliasing
- Anti-aliasing
- Frequenza di campionamento

Conversione analogico-digitale

In elettronica la conversione analogico-digitale è un procedimento che
associa a un segnale analogico (a tempo continuo e a valori continui) un
segnale numerico (tempo discreto e a valori discreti). Questo procedimento
oggi è effettuato esclusivamente tramite circuiti integrati dedicati, o
circuiti ibridi.

Descrizione

Nonostante la teoria fosse pronta da molto tempo, la "rivoluzione digitale"
che ha modificato in qualche misura il modo di vivere delle persone,
consentendo una vera e propria "tecnologicizzazione" di massa, inizia nei
primi anni ottanta. Si trattava, sostanzialmente, di risolvere due problemi
di carattere prettamente tecnologico: aumentare la velocità di elaborazione
dei circuiti e diminuirne l'ingombro; più tardi si cominciò a scontrarsi
anche con problematiche legate al consumo energetico. Tutto si è risolto
con l'integrazione sempre più spinta dei circuiti, permessa anche dal
miglioramento delle prestazioni dei transistori MOSFET.

L'idea che sta alla base della digitalizzazione è la seguente: qualsiasi
grandezza fisica di interesse (tensione, corrente, pressione, velocità...)
viene misurata e il valore della sua misura codificato come numero binario;
se la grandezza assume diversi valori nel tempo, essa sarà misurata a
intervalli regolari, dando luogo ad una sequenza di numeri.

Lo schema rappresenta il procedimento completo.

La conversione analogico-digitale si può suddividere in quattro parti
principali:

- filtraggio del segnale
- campionamento del segnale
- quantizzazione dei campioni
- codifica dei campioni quantizzati

Voci correlate

- Convertitore analogico-digitale
- Convertitore digitale-analogico
- Pulse-code modulation
- G.711

Teoria dei segnali

La teoria dei segnali studia le proprietà matematiche e statistiche dei
segnali, definiti come funzioni matematiche del tempo. In generale, un
segnale è una variazione temporale dello stato fisico di un sistema o di
una grandezza fisica (potenziale o corrente elettrica per segnali
elettrici, parametri di campo elettromagnetico per segnali radio) che serve
per rappresentare e trasmettere messaggi ovvero informazione a distanza; il
sistema in questione può essere il più disparato. In elettronica un segnale
viene dunque studiato attraverso un modello matematico o funzione in cui il
tempo (o il suo inverso, la frequenza) è considerato variabile
indipendente.

Descrizione

In generale esistono diversi tipi di segnali, ma tutti sono accomunati
dall'essere in natura segnali casuali e continui e quasi mai
deterministici. La teoria dei segnali studia la rappresentazione dei
segnali in modo da poter poi manipolarli e trattarli matematicamente.
Questa rappresentazione richiede l'uso di matematica astratta e, nel caso
di segnali stocastici, della teoria della probabilità.

La teoria si suddivide in due grandi branche a seconda del tipo di segnale
in esame: i "segnali determinati" o deterministici, di cui è possibile
predire il valore in un qualunque istante a piacere, e i "segnali
stocastici" o aleatori, il cui valore non è prevedibile, ma su cui è
possibile ottenere soltanto delle proprietà statistiche e che rientrano
nella più vasta tematica dei processi aleatori o stocastici.

Nella trasmissione di informazione a distanza (telecomunicazione) i segnali
determinati vengono utilizzati per la modulazione tramite portante, mentre
i segnali contenenti l'informazione sono invece segnali aleatori, quindi
processi stocastici, dal momento che l'informazione viaggia sotto forma di
"innovazione" ovvero varia in maniera aleatoria nel tempo.

I segnali periodici possono essere trattati mediante l'astrazione in uno
spazio vettoriale lineare quale lo spazio di Hilbert e quindi con
l'utilizzo della serie di Fourier. Per quanto riguarda i segnali non
periodici, questi necessitano della trasformata di Fourier.

Altra suddivisione è quella in "segnali continui" e "segnali discreti". Ad
essi si associano rispettivamente le comunicazioni analogiche e le
comunicazioni digitali.

Parte della teoria dei segnali è intimamente connessa con la teoria dei
sistemi giacché molti segnali transitano come input in sistemi che
elaborano ovvero trasformano il segnale in ingresso restituendo in uscita
un certo output. Centrale è anche l'analisi di Fourier ovvero l'analisi
spettrale.

Classificazione

I segnali vengono classificati in varie categorie, a seconda delle loro
proprietà.

In riferimento al tempo si definisce:

- segnale a tempo continuo: l'asse dei tempi può assumere un qualsiasi
  valore reale,
- segnale a tempo discreto: l'asse dei tempi assume solo valori discreti,
  ad esempio 1, 2, 3...

In riferimento alla variabile dipendente si distinguono:

- segnale ad ampiezza continua: i valori assunti dall'ampiezza del segnale
  sono numeri reali appartenenti ad un intervallo, cioè possono assumere
  uno qualsiasi degli infiniti valori compresi tra un minimo ed un massimo;
- segnale ad ampiezza quantizzata: i valori assunti dall'ampiezza del
  segnale sono numeri naturali [con segno], cioè appartengono ad un insieme
  finito di valori precisi.
- segnale bipolare o bidirezionale: assume nel tempo sia valori di tensione
  negativi che valori positivi.
- segnale unipolare o monodirezionale: assume nel tempo solo valori di
  tensione negativi o positivi.

Da queste distinzioni si definiscono:

- segnale analogico: segnale a tempo continuo e ad ampiezza continua
- segnale digitale o numerico: segnale a tempo discreto e ad ampiezza
  quantizzata.

Inoltre, in base alla possibilità di prevedere l'ampiezza futura, i segnali
si distinguono in:

- segnale deterministico: segnale di cui si conosce esattamente l'andamento
  dell'ampiezza in funzione del tempo;
- Segnale stocastico o aleatorio: l'andamento dell'ampiezza è
  caratterizzabile solo in termini statistici;

Un segnale può anche essere periodico o non periodico, si dice periodico
quando una parte di questo si ripete nel tempo ugualmente. La parte che si
ripete viene detta periodo.

Nelle telecomunicazioni, dal punto di vista del tipo di informazione
trasportata fino all'utente si può distinguere essenzialmente tra:

- segnale audio;
- segnale video;
- segnale dati.

ciascuno con caratteristiche diverse in termine di banda di trasmissione
richiesta.

Dal punto di vista della tipologia fisica del segnale si ha:

- segnale elettrico;
- segnale elettromagnetico;
- segnale acustico.

In generale un segnale è caratterizzabile da una velocità di propagazione
nel mezzo considerato e, nelle telecomunicazioni, dalla quantità di
informazione trasportata a mezzo del teorema di Shannon-Hartley.

Segnali e mezzi trasmissivi

Un segnale, una volta trasmesso, si propaga sempre attraverso un mezzo
trasmissivo. Per segnali elettrici il mezzo trasmissivo è sempre un
portante fisico cablato che esibisca un comportamento da conduttore
elettrico per il segnale stesso (linea di trasmissione o cavo elettrico).

Per segnali elettromagnetici il mezzo trasmissivo può essere sia un
portante fisico sia un portante radio ovvero nel primo caso una guida
d'onda metallica, una guida dielettrica (es. fibra ottica), un cavo
coassiale, nel secondo l'etere o lo spazio libero.

Segnali e informazione

Un segnale portante per trasportare informazione deve essere modulato dal
segnale contenente l'informazione da trasmettere attraverso varie possibili
tecniche di modulazione.

Effetti indesiderati

Effetti indesiderati sulla propagazione e ricezione del segnale sono:

- attenuazione;
- rumore;
- interferenza;
- dispersione;
- distorsione.

Rapporto segnale/rumore

Nell'ambito di una trasmissione dati reale attraverso un sistema di
telecomunicazioni o un qualsiasi sistema elettronico al segnale si associa
sempre del rumore, almeno quello di tipo termico, così che acquista
importanza ai fini della rilevazione del segnale informativo il rapporto
segnale/rumore: tanto maggiore è tale rapporto tanto più il segnale
informativo trasmesso è puro e facilmente decodificabile, tanto più è basso
tale rapporto tanto più il segnale informativo è corrotto dal rumore e più
facilmente si commettono errori in fase di decodifica.

Tale concetto è estendibile anche ai segnali rilevati nei fenomeni naturali
giacché anche in tali circostanze è rilevabile tipicamente un rumore di
fondo per la particolare grandezza fisica di interesse.

In aggiunta a ciò risulta importante anche il rapporto
segnale/interferenza.

Operazioni su segnali

Su segnali analogici informativi

- Moltiplicazione di due segnali tramite mixer;
- Sfasamento di fase tramite sfasatore;
- Ritardo aggiuntivo tramite linea di ritardo;
- Amplificazione/attenuazione tramite amplificatore/attenuatore;
- Raddrizzamento di segnale oscillante tramite diodo;
- Rigenerazione tramite rigeneratore;
- Filtraggio componenti in frequenza tramite filtro elettronico;
- Equalizzazione/disequalizzazione in ampiezza nel dominio delle frequenze
  tramite equalizzatori/disequalizzatori;
- Autocorrelazione/intercorrelazione;
- Modulazione/demodulazione, analogica o digitale tramite
  modulatore/demodulatore;
- Conversione di dominio (es. da dominio del tempo a dominio della
  frequenza o spettro e viceversa tramite Trasformata/Antitrasformata di
  Fourier proprie dell'Analisi armonica o Analisi di Fourier);
- Conversione di frequenza della portante tramite convertitore down
  converter o up converter.
- Conversione analogico-digitale tramite convertitore analogico-digitale;
- Conversione digitale-analogico tramite convertitore digitale-analogico;
- Multiplazione/demultiplazione di più tributari tramite
  multiplatori/demultiplatori;
- Selezione tra due o più segnali in ingresso tramite selettore;
- Splittaggio tramite splitter di un segnale.
- Compressione dati;
- Cifratura.

Su segnali discreti binari

Elaborazione digitale o operazioni booleane su onde quadre;

- OR
- AND
- NOT
- XOR
- NAND

Vedi anche elaborazione numerica dei segnali.

Su segnali elettrici di potenza (correnti elettriche)

- Amplificazione/riduzione di voltaggio tramite trasformatore;
- Riduzione/moltiplicazione di frequenza (per correnti alternate);
- Conversione continua-alternata (DC-AC) tramite inverter;
- Conversione alternata-continua (AC-DC) ovvero raddrizzamento tramite
  diodo.

Applicazioni

La teoria trova ampia applicazione in tutti i settori della trasmissione,
dell'elaborazione e dell'automatizzazione dell'informazione, ovvero nelle
telecomunicazioni, in elettronica e in informatica.

In fisica un segnale rappresenta una qualsiasi grandezza fisica che varia
nel tempo in maniera deterministica o aleatoria (se trasporta
informazione), descrivibile quindi in termini di funzione nota del tempo
oppure di processo aleatorio. Tipicamente può essere un segnale acustico o
più in generale un'onda di pressione, un segnale elettrico o un'onda
elettromagnetica. Una volta trasmesso si propaga tipicamente in un mezzo
trasmissivo che ne costituisce il canale di propagazione o comunicazione.

Esso rappresenta dunque il mezzo attraverso i quali sono veicolate le
informazioni tra un'entità tramittente ed una ricevente. Le proprietà
matematiche di un segnale sono oggetto di studio della teoria dei segnali.

Bibliografia

- Marco Luise, Giorgio M. Vitetta (2003): Teoria dei segnali, Mc Graw -
  Hill

Voci correlate

- Rappresentazione spettrale dei segnali
- Trasformata di Fourier
- Serie di Fourier
- Banda passante
- Campionamento (teoria dei segnali)
- Codifica
- Distorsione (fisica)
- Informazione
- Modulazione
- Coppia di Poiret
- Rumore (elettronica)
- Rumore bianco
- Rumore rosa
- Segnale (fisica)
- Segnale analitico
- Sottocampionamento
- Compressed sensing

Altri progetti

- Wikibooks contiene testi o manuali sulla teoria dei segnali
- Wikiversità contiene lezioni sulla teoria dei segnali
- Wikimedia Commons contiene immagini o altri file sulla teoria dei segnali

Collegamenti esterni

- Teoria dei segnali, in Thesaurus del Nuovo soggettario, BNCF, marzo 2013.

Segnale elettrico

In elettrotecnica, e specialmente in radiotecnica e nell'elettronica, un
segnale elettrico è un particolare tipo di segnale caratterizzato da una
variazione di corrente elettrica o di tensione all'interno di un conduttore
o in un punto di un circuito elettrico o elettronico.

Descrizione

Caratteristica di un segnale elettrico è la possibilità di veicolare
un'informazione: se all'interno di un filo elettrico scorre sempre una
corrente costante di, ad esempio, 1 mA, la prima volta che andremo a
misurare questa corrente riceveremo l'informazione che il valore della
corrente è appunto di 1 mA; ma se eseguiremo ulteriori misurazioni (sapendo
già a priori che la corrente non sta variando), otterremo sempre lo stesso
valore, e non otterremo quindi nessuna informazione aggiuntiva. Se però la
corrente che scorre nel filo viene fatta variare, ad esempio, da una
persona che si trova nella stanza accanto, non potremo sapere a priori
quale sarà il valore della corrente ad ogni successiva misurazione; ognuna
di esse, quindi, ci fornirà ogni volta una nuova informazione sul livello
di corrente nel filo. Se la persona che varia la corrente nel filo lo fa
seguendo certe regole di cui siamo a conoscenza, sarà possibile per quella
persona comunicare a noi informazione utile.

Ad esempio, la persona potrebbe utilizzare il codice binario, ossia far
passare o meno la corrente nel filo, secondo un piano prestabilito:
potrebbe cioè far passare la corrente per un secondo, poi non farla passare
per un altro secondo, poi non farla passare per un altro secondo, poi farla
passare per un secondo, e così via.

Se questa persona identifica con "1" un periodo di tempo di un secondo in
cui la corrente passa, e con "0" un secondo in cui la corrente invece non
passa, e decide che un carattere alfabetico è identificato da una sequenza
di 8 secondi di accensione/spegnimento della fonte di corrente, potrà
descrivere questa sequenza di "accensione/spegnimento" con una sequenza di
"1" e "0", ad esempio 1001011.

La persona potrebbe poi, sempre per esempio, decidere che alla sequenza
1001011 corrisponde la lettera K, alla sequenza 1000001 la lettera A e così
via (vedi tabella ASCII).

Se questa persona ci ha precedentemente informato di queste sue decisioni
sul significato da attribuire al passaggio/non passaggio di corrente, noi
saremo in grado di ricevere da essa informazioni tramite i segnali
elettrici da essa fatti passare nel filo: ci basterà misurare continuamente
la corrente che scorre nel filo, confrontarla con le tabelle e convenzioni
che la persona ci ha precedentemente comunicato, e potremo facilmente
ricostruire l'informazione originaria posseduta dalla persona nell'altra
stanza: avremo così utilizzato un segnale elettrico per far passare
informazioni da un luogo ad un altro.

Il tipo di segnale visto è digitale, ma esistono anche segnali di tipo
analogico. Brevemente, prendendo sempre l'esempio della corrente, potremmo
far sì che la corrente stessa non venga semplicemente fatta o non fatta
passare, ma regolata in modo continuo, così ad esempio da far passare prima
1 mA, poi 2 mA, poi aumentare fino a 5, scendere fino a 0.5 e così via.
Potremmo poi associare, ad esempio, il livello di corrente alla temperatura
presente in una stanza, ad esempio inserendo nel nostro circuito un sensore
che appunto inserisce nel circuito una corrente proporzionale alla
temperatura misurata; se sappiamo che il sensore è tarato in modo da far
passare 1 mA quando misura 10 gradi, 2 mA quando ne misura 20 e così via,
misurando il segnale analogico di corrente presente nel filo saremo in
grado di conoscere la temperatura nella stanza.

Definizione

Si considera segnale una grandezza fisica la cui variazione nel tempo
trasmette un'informazione.

Classificazione

I segnali vengono classificati in varie categorie, a seconda delle loro
proprietà.

In riferimento al tempo si definisce:

- segnale continuo: la grandezza, può assumere un qualsiasi valore reale,
  compreso tra il minimo ed il massimo del periodo in esame
- segnale discreto: la grandezza, può assumere solo valori discreti (solo
  un certo numero finito di valori),

In riferimento alla variabile dipendente si distinguono:

- segnale ad ampiezza continua: i valori assunti dall'ampiezza del segnale
  sono numeri reali appartenenti ad un intervallo, cioè possono assumere
  uno qualsiasi degli infiniti valori compresi tra un minimo ed un massimo;
- segnale ad ampiezza quantizzata: i valori assunti dall'ampiezza del
  segnale sono numeri naturali [con segno], cioè appartengono ad un insieme
  finito di valori precisi.
- segnale bipolare o bidirezionale: assume nel tempo sia valori di tensione
  negativi che valori positivi.
- segnale unipolare o monodirezionale: assume nel tempo solo valori di
  tensione negativi o positivi.

Da queste distinzioni si definiscono:

- segnale analogico: segnale a tempo continuo e ad ampiezza continua
- segnale digitale o numerico: segnale a tempo discreto e ad ampiezza
  quantizzata.

Inoltre, in base alla possibilità di prevedere l'ampiezza futura, i segnali
si distinguono in:

- segnale deterministico: segnale di cui si conosce esattamente l'andamento
  dell'ampiezza in funzione del tempo;
- segnale aleatorio o stocastico: l'andamento dell'ampiezza è
  caratterizzabile solo in termini statistici, cioè l'ampiezza del segnale
  è una variabile aleatoria;

Un segnale può anche essere periodico o non periodico, si dice periodico
quando una parte di questo si ripete nel tempo ugualmente. La parte che si
ripete viene detta periodo.

Rapporto segnale/rumore

Nell'ambito di una trasmissione dati reale attraverso un sistema di
telecomunicazione o un qualsiasi sistema elettronico al segnale si associa
sempre del rumore, almeno quello di tipo termico, così che acquista
importanza ai fini della rilevazione del segnale informativo il rapporto
segnale/rumore: tanto maggiore è tale rapporto tanto più il segnale
informativo trasmesso è puro e facilmente decodificabile, tanto più è basso
tale rapporto tanto più il segnale informativo è corrotto dal rumore e più
facilmente si commettono errori in fase di decodifica.

Applicazioni

Dal punto di vista applicativo per segnale elettrico si può intendere:

- un segnale che scorre in un circuito elettronico (es. in una scheda
  elettronica);
- un segnale che scorre in un circuito o collegamento elettrico (es. rete
  di accesso in rame);
- un segnale che scorre nella rete elettrica di trasmissione;
- un segnale che scorre nella rete elettrica di distribuzione;
- un segnale che scorre in un impianto elettrico.

Tipicamente nei primi due casi si tratta di segnali contenenti informazione
e di bassa potenza elettrica, negli altri tre casi si tratta invece di
segnali che non contengono informazione, ma che trasportano potenza
elettrica sotto forma di correnti elettriche fino agli utilizzatori finali
alimentando carichi elettrici.

Altri progetti

- Wikimedia Commons contiene immagini o altri file su segnale elettrico

Collegamenti esterni

- Segnale elettrico, in Thesaurus del Nuovo soggettario, BNCF, marzo 2013.

Analogico

In generale con il termine analogico si intende un segnale che è la
rappresentazione o trasformazione di una grandezza fisica tramite una sua
analoga.

Descrizione

La rappresentazione numerica di una grandezza analogica è quasi sempre data
da un numero reale (con precisione teoricamente infinita) o da una loro
combinazione. Nella pratica, però, il segnale televisivo o delle schiere di
sensori è rappresentato mediante numeri complessi, intesi come coppie di
reali.

Esempi:

- secondi (tempo) ↔ angolo della lancetta dell'orologio
- segnale acustico → segnale elettrico (microfono)
- segnale elettrico → segnale acustico (altoparlante)
- temperatura ↔ altezza in mm del termometro a mercurio

Elettronica

In elettronica, per analogico si intende il modo di rappresentare il
segnale elettrico all'interno di una data apparecchiatura (che lavora sotto
potenziale elettrico); il segnale è detto analogico quando i valori utili
che lo rappresentano sono continui (infiniti). Cioè se prendessimo in esame
un intervallo spazio temporale A - B (tipo quello rappresentato da un
potenziometro ed i suoi relativi valori Min(A) e MAX(B)) si passerebbe da
Min a MAX per una infinità di mutazioni elettriche, non numerabili in R
(dal latino continuum = congiunto, unito insieme). Analogico si contrappone
a digitale (=discreto). Analogico significa "continuo", "non discreto".

In parole povere, se considerassimo il semplice ed unico potenziometro
(quello del volume) presente su di un amplificatore di un impianto hi-fi,
non saremo mai in grado, una volta mutata la posizione fisica del
potenziometro, di riportarlo una seconda volta sulla stessa posizione (cioè
sul medesimo valore di resistenza elettrica) o, più volgarmente, allo
stesso e medesimo volume.

Voci correlate

- Digitale (informatica)
- Segnale discreto
- Computer analogico

Digitale (informatica)

In informatica ed elettronica con digitale ci si riferisce a tutto ciò che
viene rappresentato con numeri o che opera manipolando numeri. Il termine
deriva dall'inglese digit, che significa cifra (che in questo caso si
tratta del codice binario, ovvero un sistema numerico che contiene solo i
numeri 0 ed 1), che a sua volta deriva dal latino digitus, che significa
dito ¹ .

Aspetti generali

Un determinato insieme di informazioni viene rappresentato in forma
digitale come sequenza di numeri presi da un insieme di valori discreti,
ovvero appartenenti a uno stesso insieme ben definito e circoscritto.
Attualmente "digitale" può essere considerato come sinonimo di "numerico" o
"cifrato", e si contrappone invece alla forma di rappresentazione
dell'informazione detta analogica, che non è analizzabile entro un insieme
finito di elementi.

Conversione analogico-digitale

Ciò che è digitale è contrapposto a ciò che invece è analogico, cioè non
numerabile, non analizzabile entro un insieme discreto di elementi.
Digitale è riferito dunque alla matematica del discreto che lavora con un
insieme finito di elementi, mentre ciò che è analogico viene modellizzato
con la matematica del continuo che tratta un'infinità (numerabile o non
numerabile) di elementi.

È possibile convertire un segnale analogico in uno equivalente digitale,
costituito da una serie di numeri; questo processo è chiamato conversione
analogico-digitale. A seconda degli scopi a cui è destinata la conversione,
questa può essere effettuata in modo grossolano e approssimativo oppure in
modo molto accurato e preciso. In ogni caso, il segnale digitalizzato perde
sempre qualcosa rispetto all'originale analogico, quindi non sarà mai
identico.

Un tipico esempio è la conversione di un'onda sinusoidale (più o meno
regolare), se il circuito di conversione usa un numero di bit
insufficienti, risulta visibile geometricamente, una notevole differenza
fra il segnale analogico e il segnale digitalizzato, costituito da un
insieme di spezzate (tratti costanti ai valori dell'insieme discreto, 0 e
1) del segnale digitale.

L'uso attuale più comune del digitale è nel campo audio, in cui un segnale
analogico può venire approssimato sufficientemente bene. In alcune
applicazioni la qualità del segnale digitale riprodotto risulta
indistinguibile dall'originale analogico. Tale conversione è frequente
quanto la discretizzazione di variabili continue in matematica o statistica
(aspetto più generale di un problema soprattutto pratico).

Per esempio, un orologio con le lancette è analogico, perché la posizione
di ognuna delle sue 3 lancette (ore, minuti e secondi) può indicare uno
qualsiasi degli infiniti punti che formano la circonferenza del quadrante
dell'orologio stesso, punti che quindi non sono numerabili. Al contrario in
un orologio digitale le cifre che compongono l'ora, i minuti e i secondi
indicano solo e soltanto gli 86.400 possibili momenti in cui può essere
suddiviso, in secondi, un giorno (24 ore x 60 minuti x 60 secondi).

Un oggetto viene digitalizzato, cioè reso digitale, se il suo stato
originario (analogico) viene "tradotto" e rappresentato mediante un insieme
numerabile di elementi. Per esempio una foto, normalmente formata da un
infinito numero di punti ognuno dei quali formato di un'infinita gamma di
colori, viene digitalizzata, e quindi tradotta in foto digitale, allorché
la sua superficie la si rappresenti divisa in un numero discreto di "punti"
(in genere piccoli quadrati o rettangoli detti pixel) ognuno dei quali
formato di un colore tra i 16 777 216 possibili (se codificati in RGB, e
cioè in una combinazione di 256 sfumature di rosso, 256 di verde e 256 di
blu), ovvero 8 bit per colore.

Molte tecnologie ricorrono al digitale per ottenere la riproduzione di
un'onda (sonora o luminosa) che è analogica; il modem converte appunto un
segnale analogico inviabile attraverso i doppini telefonici in un segnale
richiesto dal pc o altro dispositivo elettronico che funziona tramite bit
(0/1) e richiede un segnale digitale. I moderni televisori LCD funzionano
principalmente con segnali digitali, mentre i televisori della precedente
generazione CRT avevano un funzionamento basato primariamente su segnali
analogici.

Note

[1] Con le dita si contano i numeri.

Voci correlate

- Analogico
- Comunicazioni

Segnale discreto

Per segnale discreto o segnale discreto nel tempo si intende una
successione di valori di una certa grandezza dati in corrispondenza di una
serie di valori discreti nel tempo. In altri termini, è una funzione, o un
segnale, con valori forniti in corrispondenza ad una serie di tempi scelti
nel dominio dei numeri interi. Ciascun valore della successione è chiamato
campionamento. A differenza dei segnali continui, un segnale discreto non è
funzione di una variabile continua, pur potendo essere ottenuto campionando
un segnale continuo. Quando un segnale discreto è composto da una serie di
valori ottenuti in corrispondenza di istanti spaziati uniformemente nel
tempo, si dice che è associato ad una particolare frequenza di
campionamento; la frequenza di campionamento non è direttamente desumibile
nella sequenza dei valori campionati, ma può essere fornita come dato
separato.

Acquisizione

I segnali discreti possono avere diverse origini, ma in linea di massima le
tecniche di acquisizione rientrano in uno dei due seguenti gruppi:

- Campionamento a frequenza costante o variabile di un segnale analogico.
- Totalizzando i valori assunti da una variabile entro dati intervalli di
  tempo. Ad esempio: il numero di persone che usano ogni giorno un certo
  ascensore.

Segnali digitali

Un segnale digitale è un segnale discreto che può assumere soltanto valori
appartenenti ad un insieme discreto. Il procedimento di conversione di un
segnale continuo campionato in valori di tempo discreti in un segnale
digitale è detta quantizzazione. Questo procedimento, noto anche come
conversione analogico-digitale, provoca perdita di informazione in quanto i
valori effettivamente assunti dal segnale sono troncati o arrotondati.
Quindi i segnali digitali sono sempre un'approssimazione dei segnali a
valore continuo da cui originano. Esempi di segnali digitali sono quelli ad
8-bit (256 livelli, cioè valori), 16-bit (65,536 livelli), 32-bit (4,3
miliardi di livelli), e così via. Anche se spesso il numero di livelli di
un segnale digitale viene espresso da potenze di due, la definizione vale
anche per un qualsiasi altro numero di quantizzazioni.

Voci correlate

- Campionamento (teoria dei segnali)

Codice (teoria dell'informazione)

Nella teoria dell'informazione, e conseguentemente nelle telecomunicazioni,
nell'elettronica e nell'informatica, un codice è una rappresentazione di un
insieme di simboli in grado di rappresentare l'informazione che viene così
codificata.

Significati

Il termine codice viene usato con due significati:

- procedimento di codifica, riguarda la modalità seguita per assegnare
  univocamente ad ogni elemento dell'insieme da rappresentare una stringa
  che lo rappresenta;
- insieme delle codifiche, denota l'insieme delle stringhe rappresentative
  (questo è il significato utilizzato nel capitolo della matematica
  chiamato teoria dei codici (v. 94-XX).

Un codice si dice efficiente quando utilizza un numero di simboli
strettamente necessario per codificare l'informazione, mentre all'opposto
si dice ridondante quando usa un numero di simboli abbondanti, e quindi più
di quelli necessari, ma utili per semplificare la generazione e la
interpretazione delle informazioni.

Definizione formale

Sia S un insieme finito di elementi detto alfabeto del codice, come ad
esempio le due facce con una moneta (T, C). Un insieme A di sequenze
costruite giustapponendo uno o più elementi di S è un codice. Ogni elemento
di A è una parola del codice e il numero di elementi dell'alfabeto usati
per costruirla ne indica la lunghezza. Perché un codice abbia utilità e
senso, tuttavia, dev'essere associato con qualche meccanismo controllabile
(formula, algoritmo, elenco ben definito, ...) a un insieme di possibili
dati che deve rappresentare fedelmente e dunque averne la stessa
cardinalità. Per esempio, l'insieme {T, C, TC, TT} è un codice e può essere
usato come codifica dei numeri 0, 1, 2, 3.

Proprietà

Giustapponendo più parole del codice si ha un messaggio costruito su tal
codice, come ad esempio TTC o TCTC. Dipendentemente dal fatto che un
qualsiasi messaggio possa essere scomposto in modo che esista un'unica
serie di parole del codice che la compongano il codice si dice univocamente
decodificabile o meno. Il codice di cui sopra non è univocamente
decodificabile poiché il messaggio TT potrebbe essere scomposto come la
ripetizione 2 volte della parola T o la parola stessa del codice TT. Al
contrario, {C, TC, TTC, TTTC} è un codice univocamente decodificabile. Un
codice in cui tutte le parole hanno la stessa lunghezza si dice codice a
blocchi o in caso contrario codice a lunghezza variabile.

Altre proprietà di un codice sono la capacità di correggere errori,
comprimere i messaggi, essere lineari o meno, essere utilizzabili in
crittografia o essere istantanei.

Lo studio dei codici in maniera sistematica come elementi fondamentali per
la teoria dell'informazione e della trasmissione è nato nel 1948 con il
lavoro di Claude Shannon.

Esempi

Un esempio tradizionale di codice è il Morse, appartenente alla codifica di
caratteri ed utilizzato nei primi tempi della telegrafia (1840): in cui ad
ogni lettera dell'alfabeto inglese (l'insieme di informazioni da
rappresentare) viene assegnata una sequenza di punti e linee (gli elementi
dell'alfabeto usato per la codifica).

Altre esempi di codifica sono la codifica digitale di un segnale analogico
ovvero la conversione analogico-digitale, la codifica di sorgente e la
codifica di canale.

Utilità

L'univocità della rappresentazione gioca un ruolo cruciale in tutte le
applicazioni della codifica (il procedimento di trasportare gli elementi
dalla rappresentazione di partenza a quella definita dal codice) e di
decodifica (l'inverso). I codici risultano utili quando la comunicazione
verbale normale non è sufficiente o non è praticabile. Con un'opportuna
codifica è possibile descrivere realtà ben più complesse del lessico del
linguaggio naturale, come ad esempio un'immagine o una serie di suoni.

Con l'avvento dell'informatica e delle telecomunicazioni i codici hanno
preso ulteriore piede per la trasmissione affidabile e la compressione
dati, anche se già all'epoca del telegrafo venivano usate delle parole in
codice per trasmettere frasi di uso particolarmente frequente, ad esempio:

- BYOXO (Are you trying to weasel out of our deal? - Stai cercando di
  uscire dal nostro accordo?)
- LIOUY (Why do you not answer my question? - Come mai non rispondi alla
  mia domanda?)
- AYYLU (Not clearly coded, repeat more clearly. - Codificato male, per
  favore ripetere più chiaramente).

Codice di Gödel

In matematica, un codice di Gödel è alla base della dimostrazione del
Teorema di incompletezza di Gödel. In tal caso, l'idea consiste nel
trasformare notazione matematica in un numero naturale (numero di Gödel).

Voci correlate

- Codifica di caratteri
- Codice sorgente
- Informazione
- Comunicazione

Altri progetti

- Wikizionario contiene il lemma di dizionario «codice»
- Wikimedia Commons contiene immagini o altri file su codice

Collegamenti esterni

- Codice, in Thesaurus del Nuovo soggettario, BNCF, marzo 2013.

Segnale continuo

Per segnale conptinuo o segnale continuo nel tempo si intende una grandezza
fisica variabile nel tempo in modo continuo. A differenza dei segnali
discreti, un segnale continuo non è funzione di una variabile discreta ma
il valore della grandezza può essere misurato in qualsiasi istante. La
quantità di informazione trasportata da un segnale continuo di una certa
durata è maggiore rispetto a quella trasportata da un segnale discreto di
uguale durata. Un segnale continuo può essere studiato sia nel dominio del
tempo che nel dominio della frequenza. Per passare dal dominio del tempo al
dominio della frequenza si utilizza la trasformata di Fourier. Per passare
dal dominio della frequenza al dominio dell tempo si utilizza
l'antitrasformata di Fourier.

Rumore (elettronica)

In elettronica il rumore (o noise) è l'insieme di segnali in tensione o
corrente elettrica indesiderati che si sovrappongono al segnale utile
trasmesso o da elaborare, tipicamente presente sul canale di comunicazione
tra utenti o apparati elettronici e sui dispositivi di
ricezione/elaborazione.

Descrizione

Si distingue tra rumore e disturbo: per rumore solitamente si intendono
segnali di origine aleatoria provenienti dall'interno e vengono descritti
in termini probabilistici, mentre i disturbi sono segnali che provengono
dall'esterno e possono pertanto essere descritti in termini deterministici
ovvero interferenze.

Il rumore consiste di "fluttuazioni" dovute a proprietà fondamentali della
materia e in quanto tali di origine interna e non eliminabili. Queste
fluttuazioni che si osservano a livello macroscopico derivano da
fluttuazioni a livello microscopico. Si manifestano nella forma di segnali
casuali il cui andamento nel tempo non è descrivibile analiticamente, ma
solo in termini statistici.

L'effetto indesiderato consiste dunque in un'alterazione o distorsione del
segnale utile contenente informazione tale da poter inficiare il corretto
processo di rilevazione/elaborazione a valle della trasmissione.

Tipi di rumore

La sorgente di rumore più comune negli apparati e dispositivi elettronici è
il rumore termico, esso è infatti intrinseco di ogni elemento dissipativo
(es. resistori) che si trovi ad una temperatura diversa dallo zero
assoluto. Poiché il rumore termico è la principale sorgente del rumore
interno è solito intendere, per convenzione, come rumore interno solo
quello termico.

Scoperto da Johnson e teorizzato analiticamente da Nyquist, questo rumore è
conseguenza dell'agitazione termica dei portatori di carica in un
conduttore. Infatti, poiché la distribuzione degli elettroni all'interno di
un conduttore in funzione del tempo non è uniforme, in un certo istante si
può manifestare un eccesso di cariche a una estremità, mentre nell'istante
successivo questo eccesso può trasferirsi all'altra. Il loro movimento
caotico è tale da creare ai capi di un resistore una differenza di
potenziale che mediamente vale 0 Volt (si dice che il valore medio del
processo rumore bianco è nullo) perché il numero degli elettroni che
fluiscono verso un'estremità del conduttore è uguale al numero di quelli
che fluiscono verso l'altra. Tale tensione se misurata con uno strumento
che non carichi il resistore è altamente variabile e descrivibile solo in
termini statistici: il valore quadratico medio (quadrato del valore
efficace) dipende dalla temperatura ed è pari a

Vₙ²⁼⁴KTBₙR

dove:

- k= 1,38*10^-23 W/Hz*K è la costante di Boltzmann;
- R è la resistenza elettrica del conduttore;
- Bₙ è la banda equivalente di rumore;
- T è la temperatura in kelvin (K)

Si può quindi affermare che un qualsiasi resistore rumoroso avente
resistenza R, detto resistore caldo, può essere rappresentato con un
resistore avente lo stesso valore di resistenza R di quello rumoroso, detto
resistore freddo, in serie ad un generatore di tensione di rumore il cui
valore efficace è dato dall'equazione sopra citata.

Altri rumori elettronici (oltre al rumore termico):

- rumore shot
- rumore 1/f (o rumore Flicker)
- rumore Burst
- rumore valanga
- rumore ottico cioè fotoni indesiderati prodotti negli apparati
  optoelettronici in conseguenza del fenomeno dell'emissione spontanea.

Tra i disturbi:

- Segnali armonici prodotti da rapide variazioni di corrente in sistemi
  oscillanti
- Disturbi elettrici di provenienza esterna (vedi compatibilità
  elettromagnetica)
- Il clutter (nei sistemi Radar)

Trattazione matematica

In genere il rumore, essendo intrinsecamente stocastico, viene analizzato
usando la teoria dei processi stocastici: si assume perciò che il rumore
sia stazionario, cioè ha proprietà invarianti nel tempo, e sia ergodico
cioè tutte le proprietà d'insieme del processo sono estraibili da una
singola osservazione. Perché sia possibile trattare il rumore bisogna che
se ne possa associare una qualche distribuzione di probabilità. In genere
se la distribuzione è gaussiana, come nella maggior parte dei casi, allora
la sua distribuzione è nota:

f_x (x) = \frac{1}{√(2 π) σ} e^{- \frac{(x - η)²}{2 σ²} }

dove η rappresenta il suo valore medio e σ la sua deviazione standard
entrambi costanti nel tempo se il processo è stazionario. Inoltre è
necessario conoscere la funzione di autocorrelazione:

R_{xx}(τ) = \lim _{T →\infty } \frac{1}{2T} ∫_{-T}^{T} x(t + τ) ·x(t) dt

che rappresenta la correlazione fra due campioni del processo a distanza
temporale τ. la correlazione è massima per τ= 0, cioè quando la
correlazione è R_{xx}(0) = \overline{x²} (t) = η^2 + σ² il valore
quadratico medio del processo.

Per τ\neq 0, la funzione di autocorrelazione rappresenta il grado di
prevedibilità di una realizzazione al tempo t + τ una volta nota al tempo
t.

Dunque lo studio del rumore passa per la definizione di una appropriata
distribuzione di probabilità e come funzione di correlazione nel caso dei
segnali che ci interessa si usa lo spettro di potenza e si utilizzano le
relazioni di Wiener-Khinchin:

S_{xx}(ω) = F [R_{xx}(τ)]
R_{xx}(τ) = F^{-1} [S_{xx}(ω)]

cioè della trasformata e antitrasformata di Fourier della funzione di
autocorrelazione. Lo spettro ottenuto è (-\infty , \infty ), ma in genere
essendo simmetrico si utilizza lo spettro di potenza unilatero positivo. Le
relazioni di Wiener-Khinchin possono allora scriversi esplicitamente:

S_{xx}(ω) = 2 ∫_{0}^{\infty } R_{xx}(τ) e^{-j ωτ} dτ
R_{xx}(τ) = 2 ∫_{0}^{\infty } S_{xx}(ω) e^{j ωτ} dω

A seconda dei casi le grandezze possono essere misurate in tensione allora
l'unità di misura degli spettri è V²/Hz o in corrente allora A² / Hz. Dagli
spettri di potenza dei segnali si possono anche ricavare gli spettri di
ampiezza di rumore:

V_n(ω) = √(S_{vv}(ω)) [V/ √(Hz)]
I_n(ω) = √(S_{ii}(ω)) [A/ √(Hz)]

Per calcolare il valore efficace della tensione o della corrente in un
intervallo di banda si applica semplicemente:

V_{n_{eff}} = V_n (f) * {√(Δf)}

Voci correlate

- Rumore bianco
- Rumore rosa
- Rumore termico
- Rumore gaussiano
- Radiofrequenza
- Cifra di rumore
- Temperatura equivalente di rumore
- Rapporto segnale-rumore

Altri progetti

- Wikimedia Commons contiene immagini o altri file su Rumore

Collegamenti esterni

- Direttiva 89/336/CEE sui disturbi di radiofrequenza (PDF), italtec.it.

Rapporto segnale/rumore

In telecomunicazioni ed elettronica il rapporto segnale/rumore, spesso
abbreviato con la sigla inglese SNR (Signal to Noise Ratio) o S/N anche
nell'uso italiano, è una grandezza numerica che mette in relazione la
potenza del segnale utile rispetto a quella del rumore in un qualsiasi
sistema di acquisizione, elaborazione o trasmissione dell'informazione.

Definizione

Il rapporto segnale/rumore è un numero puro o adimensionale dato dal
rapporto fra due grandezze omogenee che esprime quanto il segnale sia più
potente del rumore nel sistema considerato. È formalmente espresso dalla
relazione:

SNR={P_{segnale}\over P_{rumore}} con 0 \leq{SNR} < {\infty }

dove P_{segnale} è la potenza del segnale utile e P_{rumore} la potenza
totale del rumore presente nel sistema, grandezze queste solitamente
espresse in watt o dBm.

Applicazione e importanza

Può essere applicato indifferentemente a sistemi di natura ottica,
elettronica, ecc. e si tratta di una grandezza fondamentale nell'ambito del
trattamento dei segnali e della teoria dell'informazione. Un qualsiasi
sistema che debba trasportare o trattare informazioni è infatti affetto da
rumore, primo fra tutti il rumore termico, che è un fattore non ideale
della trasmissione ovvero del tutto indesiderato che corrompe il segnale
utile spesso sommandovisi in maniera additiva: tanto maggiore è la potenza
di rumore rispetto alla potenza del segnale utile tanto minore è la qualità
della comunicazione. È logico dunque aspettarsi che l'SNR sia un parametro
di qualità che si cerca o si tenda in qualche modo a massimizzare o
preservare il più possibile.

Esso è dunque un parametro di merito molto importante per il
dimensionamento e il corretto funzionamento del sistemi di
telecomunicazioni in quanto strettamente collegato alla capacità del
sistema ricevente di rilevare il flusso informativo originario senza
incorrere in alterazioni dovute a distorsione ed errori dovuti
essenzialmente all'azione disturbante del rumore. Più basso è l'SNR, più
sarà difficoltosa la decodifica del segnale ovvero più alta sarà la
probabilità di errore e quindi anche il BER nelle trasmissioni digitali.

Nel caso di trasmissioni analogiche una diminuzione di SNR determina un
deperimento graduale della qualità del segnale ricevuto (si pensi ad
esempio a una radio FM che riceve male o a un televisore in cui compaiono
audio o video disturbati: tipici casi di SNR basso); per le trasmissioni
analogiche tuttavia è l'utente finale a stabilire una soglia di fruibilità
del sistema.

Nel caso di trasmissioni digitali, invece, esiste una soglia minima di SNR
sotto la quale il sistema non è in grado di funzionare (si pensi alla
televisione digitale satellitare: o si vede bene o non si vede del tutto);
l'errore di decisione/decodifica può essere tale da far decidere per un
simbolo piuttosto che un altro; tuttavia grazie alle moderne tecniche di
modulazione e di protezione dei dati tramite codifica di canale tale soglia
è piuttosto bassa, al di sotto di quella che servirebbe per ottenere
prestazioni analoghe su sistemi analogici.

La soglia minima di SNR è determinata dalla tecnologia dell'apparato
ricevente; in fase di progetto di un sistema di telecomunicazioni il primo
obiettivo è quindi quello di far pervenire al ricevitore un SNR
sufficientemente elevato.

In Alta Fedeltà il rapporto segnale/rumore è uno dei parametri di merito
fondamentali, anche se non l'unico, per la valutazione delle prestazioni di
un impianto per quello che concerne la pulizia del suono prodotto, tanto
che i preamplificatori di fascia alta sono realizzati in due distinti
telai, uno contenente il circuito amplificatore, l'altro il circuito
alimentatore.

Tale rapporto è legato inoltre alla velocità di trasmissione sul canale
tramite il Teorema di Shannon-Hartley.

Il rapporto segnale/rumore decade con la distanza percorsa dal segnale sul
canale o mezzo trasmissivo in virtù dell'attenuazione della potenza del
segnale utile così che a una certa distanza dal trasmettitore rimane solo
rumore. Tale decadimento fa decadere a sua volta la velocità di
trasmissione con la distanza sul canale stesso.

Esiste inoltre un parametro, il SINAD, concettualmente molto simile al SNR,
e che insieme al rumore include anche la distorsione generata dal circuito:
esso dà una valutazione più precisa della degradazione assunta da un
segnale per effetto delle non idealità delle apparecchiature che
attraversa, in particolare degli ADC e dei DAC, che possono in alcuni casi
essere parecchio distorcenti.

In molti sistemi elettronici e di telecomunicazioni per ottenere una
massimizzazione del rapporto segnale-rumore si usa comunemente un filtro
adattato.

Voci correlate

- Cifra di rumore
- Temperatura equivalente di rumore
- Intervallo dinamico
- PSNR
- Bit Error Ratio
- SINAD

Altri progetti

- Wikimedia Commons contiene immagini o altri file su Rapporto
  segnale/rumore

Dithering

Il dithering, nella elaborazione numerica di segnali, è una forma di rumore
con una opportuna distribuzione, che viene volontariamente aggiunto ai
campioni con l'obiettivo di minimizzare la distorsione introdotta dal
troncamento nel caso in cui si riquantizzino i campioni stessi. Il
dithering viene usato abitualmente nell'elaborazione di segnali video e
audio campionati e quantizzati. Il dithering non ha nulla a che vedere col
jitter.

Storia

I primi studi teorici sulla quantizzazione delle ampiezze risalgono alla
fine degli anni '50 del secolo scorso. Bernard Widrow, all'epoca al MIT e
attualmente professore alla Stanford University, ha mostrato infatti che il
processo di quantizzazione, dal punto di vista teorico, ha proprietà
analoghe al campionamento del segnale, per cui è possibile estendere il
teorema di Nyquist alla quantizzazione dei segnali.¹

Di fondamentale importanza per lo sviluppo delle teorie legate al dithering
è un secondo lavoro in cui vengono dimostrati due teoremi che illustrano
come la somma di rumore con una certa distribuzione al segnale quantizzato
possa essere considerata in modo analogo al filtro antialiasing usato nel
processo di campionamento temporale dei segnali.²

Il concetto di dithering viene ulteriormente approfondito da Lawrence G.
Roberts nella sua tesi di dottorato nel 1961, presso il MIT,⁴ nonostante
egli non abbia usato il termine dither.

Origine del termine "dither"

Il dither nel processo digitale e nell'analisi delle forme d'onda

Il dithering viene spesso usato nei campi dell'audio e video digitali, dove
serve per stimare le conversioni e (di solito in modo facoltativo) le
trasformazioni di profondità di colore; viene utilizzato in molti settori
differenti in cui il processo e l'analisi digitale sono necessari -
specialmente nell'analisi delle forme d'onda. Questi usi includono sistemi
digitali quali audio digitale, video digitale, fotografia digitale,
sismologia, radar, meteorologia ed altri ancora.

La premessa è che la quantizzazione e la ri-quantizzazione dei dati
digitali genera errori. Se questo errore si ripete ed è correlato al
segnale se ne ottiene uno ciclico e matematicamente deterministico. In
alcuni campi, specialmente dove i recettori sono sensibili agli errori, il
comportamento ciclico porta ad artefatti indesiderati. In questi ambiti il
dithering permette di avere artefatti non deterministici che quindi perdono
la loro ciclicità. Il campo sonoro è un esempio primario: l'orecchio umano
funziona allo stesso modo di una trasformata di Fourier, in cui individua
singole frequenze. L'orecchio è particolarmente sensibile alla distorsione
ovvero a frequenze addizionali che modificano il colore del suono. Questa
sensibilità si può ridurre rendendo casuale il rumore su tutte le
frequenze.

Audio digitale

La versione finale di un brano audio che viene scritto digitalmente su di
un compact disc, è tipicamente quantizzata a 16 bit per campione ma, grazie
al processo di editing audio, i dati crescono in profondità quanto occorre.
Più calcoli matematici svolgiamo, più il campione cresce in profondità:
come se si trattasse di aggiungere, moltiplicare o dividere numeri
decimali. Alla fine i dati digitali vengono riportati alla profondità
iniziale (16 bit) per poter essere memorizzati su di un CD e distribuiti.

Esistono molti metodi che permettono di tornare ai canonici 16 bit. Ad
esempio, si possono semplicemente troncare i bit in eccesso (troncamento).
È anche possibile arrotondare i bit in eccesso al valore più prossimo.
Ognuno di questi algoritmi, comunque, produce un imprevedibile errore nel
risultato. Consideriamo, ad esempio, una forma d'onda composta dai seguenti
valori:

1   2   3   4   5   6   7   8

Se la riduciamo del 20% otteniamo questa sequenza:

0.8 1.6 2.4 3.2 4.0 4.8 5.6 6.4

Troncando i valori otteniamo:

0   1   2   3   4   4   5   6

Se invece li arrotondassimo avremmo:

1   2   2   3   4   5   6   6

Se qualsiasi sequenza, compresa quella iniziale, viene processata
moltiplicando i valori per 0.8 il risultato conterrà errori che saranno
ovviamente ripetibili. Un'onda rappresentante la funzione di seno
quantizzata al valore originario, ad esempio, comporterà lo stesso errore
ogni volta che il suo valore sarà "3.4" visto che il risultato verrebbe
abbassato di 0,4. Ogni volta che il valore è "5", l'errore dopo il processo
sarà 0. In ogni caso, l'ammontare dell'errore cambierà continuamente al
modificarsi dei valori. Il risultato ha un comportamento ciclico
nell'errore, che mostra la sua frequenza addizionale sulla forma d'onda
(distorsione armonica). L'orecchio è in grado di percepire questo errore
sotto forma di frequenza addizionale.

Non possiamo evitare il riprodursi degli errori in questo procedimento.
Prendere un numero a due cifre (4.8) e trasformarlo in uno ad una cifra (5)
produce un errore, e questo è inevitabile. Quello che vogliamo fare è
creare un sistema in cui l'errore non si ripeta al ripetersi dei valori.

Una plausibile soluzione potrebbe essere di prendere un numero a due cifre
(4.8) ed arrotondarlo in una delle due direzioni. Ad esempio, lo
arrotondiamo la prima volta a 5, la seconda a 4, e così via. In questo modo
la media a lungo termine sarà 4.5, invece di 4, ed il valore sarà più
simile a quello di partenza, 4.8. Questo metodo produce ancora un errore
deterministico (nonostante sia più complicato). Ogni volta che troviamo il
valore 4.8 l'errore sarà 0.2 o -0.8. Quindi il problema non è risolto.

Un'altra soluzione consiste nell'arrotondare il 4.8 in modo che quattro
volte su cinque diventi 5, e l'altra diventi 4. In questo caso la media è
esattamente 4.8 ma, sfortunatamente, l'errore è ancora deterministico, ed
ancora l'orecchio lo percepisce (nonostante il sovracampionamento possa
limitare il disturbo).

Questo ragionamento porta al dithering. Invece di arrotondare con una
ciclicità predicibile, che succederebbe se lavorassimo in modo casuale?
Possiamo arrotondare casualmente vincolando il totale in modo che l'80%
delle volte venga arrotondato a 5, lasciando così la media a 4.8 ma
generando un errore irriproducibile. Proprio questo è il cuore del
dithering.

Calcoliamo una serie di numeri casuali compresi tra 0 e 0.9 (ad esempio:
0.6, 0.4, 0.5, 0.3, 0.7, etc.) e li aggiungiamo al risultato della nostra
equazione. Due volte su dieci il risultato verrà troncato a 4 (se 0 o 0.1
vengono aggiunti a 4.8), mentre nei restanti casi il valore diverrà 5;
ognuna di queste situazioni ha una possibilità del 20% di diventare 4 e
dell'80% di diventare 5. A lungo andare la media sarà 4.8 e la
quantizzazione dell'errore diverrà casuale. Il rumore così ottenuto è
percepito meno dall'orecchio.

Per far comprendere al meglio la funzione del dithering, vengono messi a
disposizione i seguenti file audio:

-
-
-

Quando aggiungere il dithering

Il dithering va aggiunto prima di qualsiasi quantizzazione o
ri-quantizzazione al fine di prevenire comportamenti non lineari
(distorsione); più bassa è la profondità di bit, più grande deve essere il
dither. Il risultato sarà ancora distorto, ma la distorsione, essendo di
natura casuale, viene ridotta a rumore. Qualsiasi processo di riduzione di
bit dovrebbe aggiungere il dither alla forma d'onda prima di applicare la
riduzione.

Differenti tipi di dithering

RPDF sta per "Rectangular Probability Density Function" (Funzione
rettangolare di densità della probabilità), ed è equivalente al lancio di
un dado. Ogni numero ha la stessa probabilità di uscire.

TPDF sta per "Triangular Probability Density Function" (Funzione
triangolare di densità della probabilità), equivalente al lancio di due
dadi. La somma dei dadi ha differenti probabilità d'uscita:

  1/1 = 21/2 2/1 = 31/3 2/2 3/1 = 41/4 2/3 3/2 4/1 = 51/5 2/4 3/3 4/2 5/1 =
  61/6 2/5 3/4 4/3 5/2 6/1 = 72/6 3/5 4/4 5/3 6/2 = 83/6 4/5 5/4 6/3 = 94/6
  5/5 6/4 = 105/6 6/5 = 116/6 = 12

il 7 uscirà molto più spesso del 2 o del 12, e la relazione tra queste
probabilità viene detta triangolare.

La PDF Gaussiana è equivalente al lancio di infiniti dadi. La relazione tra
le probabilità dei risultati ha una forma a campana detta curva Gaussiana.
Il dithering prodotto dalla PDF Gaussiana è quasi coincidente al rumore
atmosferico naturale, il fruscio delle musicassette, ecc.

Il dithering colorato viene a volte descritto come quel dithering che è
stato filtrato per differenziarsi dal rumore bianco. Alcuni algoritmi di
dithering usano un rumore che possiede più energia nelle alte frequenze, e
meno nella banda audio critica.

Il noise shaping non è in realtà un dithering, poiché consiste nel
"modellare" il rumore, come dice il suo nome, spostandolo in zone dello
spettro audio in cui è meno udibile. Normalmente viene associato al
dithering, e quindi sposta appunto questo rumore. È tuttavia possibile
anche usarlo senza dithering. In tal caso il rumore di ri-quantizzazione
rimane distorto, ma viene spostato in zone dello spettro audio in cui è
meno udibile.

Quale dithering usare

Se il segnale da processare deve subire un ulteriore lavoro, dovrebbe
essere usato il TPDF che ha l'ampiezza di due passi di quantizzazione (in
modo che i valori calcolati varino tra -1 e +1 o, se vogliamo, tra 0 e 2).
Se il dithering colorato viene usato come processo intermedio, la gamma di
frequenze può sfumarsi in un'altra e diventare vagamente udibile.

Se il segnale da lavorare non deve essere ulteriormente processato (ovvero
accettiamo direttamente il risultato del dithering) è conveniente usare il
dithering colorato o il noise shaping, in grado di diminuire enormemente il
livello del rumore udibile spostandone buona parte nell'area non critica.

Fotografia digitale e image processing

Il dithering viene usato in computer grafica per creare l'illusione della
profondità di colore in immagini dotate di una tavolozza limitata
(quantizzazione del colore). In un'immagine sottoposta a dithering, i
colori non disponibili vengono approssimati dalla distribuzione dei pixel
colorati con le tinte disponibili. L'occhio umano percepisce la diffusione
come un amalgama dei colori.⁶ Il dithering è simile alla tecnica chiamata
halftone nella stampa in cui si usava un retino stocastico. Le immagini
trattate con il dithering, particolarmente quelle in cui vengono usati
pochi colori, possono spesso apparire granulari, o composte da puntini.

Esempi di dithering

Ridurre la profondità del colore di un'immagine spesso causa effetti
collaterali indesiderati. Se l'immagine originale è una fotografia,
probabilmente i colori saranno migliaia, o addirittura milioni. Limitarne
il numero fa, ovviamente, perdere qualità all'immagine.

Molti fattori possono modificare la qualità risultante, probabilmente il
più significativo di questi è la "larghezza" della tavolozza usata. Ad
esempio, un'immagine di alta qualità (Figura 1) può essere ridotta con una
tavolozza a 256 colori (Web-safe colors). Se i colori dei pixel originali
venissero semplicemente spostati nel colore "più vicino" tra quelli
disponibili, non avremmo applicazione del dithering (Figura 2).
Normalmente, questo approccio causa aree di colore uniforme e perdita di
dettaglio, generando macchie di colore molto diverse dall'originale. Le
aree sfumate appaiono a strisce (effetto banding). L'applicazione del
dithering può aiutare a limitare questi artefatti visivi e, di solito, crea
un'immagine più simile all'originale (Figura 3). Il dithering permette di
ridurre il banding e la "piattezza" dei colori.

Uno dei problemi legati all'uso di tavolozze preimpostate è dato dal fatto
che molti dei colori necessari non sono presenti, e molti di quelli
presenti non sono necessari; una tavolozza che contenga molte sfumature di
verde è controindicata se non usiamo il verde nell'immagine, ad esempio. In
questi casi è indicato l'uso di tavolozze ottimizzate. In queste tavolozze
i colori vengono scelti basandosi sulla loro frequenza nell'immagine
originale. L'immagine ottenuta presenta ulteriori miglioramenti rispetto
alla precedente (Figura 4).

Il numero di colori disponibili nella tavolozza è un dato importante. Se,
ad esempio, è composta di soli 16 colori, l'immagine perderà altri
dettagli, oltre ad un incremento dell'effetto banding (Figura 5). Ancora
una volta, il dithering ci aiuta ad aggirare il problema (Figura 6).

Utilizzi del dithering

Tutti i display hardware, comprese le vecchie schede video dei primi
computer o i moderni schermi LCD fino alle fotocamere digitali, sono in
grado di mostrare un limitato numero di colori rispetto alle periferiche
più avanzate. Uno degli usi del dithering permette di mostrare immagini di
qualità su schermi che non lo sono. Ad esempio, possiamo visualizzare
immagini in truecolor su schermi in grado di mostrare solo 256 colori alla
volta. I colori disponibili verranno usati per generare un'
"approssimazione" dell'immagine originale. Il dithering sfrutta i vantaggi
dell'occhio umano, che tende a miscelare due colori se sono posti troppo
vicini (acutezza visiva).

Questo uso del dithering, in cui gli schermi dei computer sono la
principale limitazione, viene fatto nel campo del software come i web
browser. Dal momento che il browser raccoglie immagini da fonti esterne,
può essere necessario operare il dithering su quelle troppo "profonde". A
causa di questo problema, venne definita una tavolozza standard chiamata
Web-safe palette, che raggruppa i colori visualizzabili su tutti gli
schermi, a prescindere dal sistema operativo o dal browser utilizzati.

Un altro utile impiego del dithering è in quelle situazioni in cui il
formato dei file grafici è il fattore limitante. In particolare, il
comunissimo GIF utilizza al massimo 256 colori in molti software di
editing. Le immagini in altri formati, come il PNG, possono avere
restrizioni imposte dalla volontà di limitare la dimensione del file.
Questo genere di immagini ha una tavolozza predefinita contenente i colori
utilizzabili all'interno dell'immagine. In questi casi, i programmi di
editing possono sobbarcarsi il compito di applicare il dithering prima di
salvare le immagini nel loro formato.

Algoritmi di dithering

Esistono molti algoritmi creati per l'applicazione del dithering. Uno dei
primi, ed ancora tra i più popolari, è l'algoritmo di Floyd-Steinberg,
sviluppato nel 1975. Uno dei punti di forza di questo algoritmo è la sua
capacità di minimizzare gli artefatti visivi attraverso un processo di
diffusione dell'errore; solitamente produce immagini più simili
all'originale rispetto a quanto fatto da altri algoritmi similari.

Gli altri metodi comprendono:

- Dithering ponderato (Average dithering): una delle tecniche più semplici,
  è basata sulla selezione di un colore "medio" e sull'assegnazione di
  colore ai pixel in base a quanto sono "distanti" da lui
- Dithering ordinato (Ordered dithering): produce un risultato simile a
  quello ottenuto nella stampa delle riviste attraverso l'uso dell'halftone
- Dithering casuale (Random dithering): aggiunge un elemento casuale ad
  ogni pixel, creando l'immagine
- Dithering di Albie (Albie dithering): metodo simile al Floyd-Steinberg,
  ma ottimizzato per la visualizzazione su schermi interlacciati
- Dithering di Jarvis (Jarvis dithering): vedi l'immagine a lato per un
  esempio

Il dithering nei sistemi in fibra ottica

Lo Stimulated Brillouin Scattering (SBS) è un effetto ottico non lineare
che limita la potenza ottica utilizzata nei sistemi in fibra ottica. Il
segnale trasmesso può essere manipolato con il dithering al fine di
limitare il "rumore" trasmesso.

Note

[1] B.Widrow, "A study of rough amplitude quantization by means of Nyquist
  sampling theory", IRE Trans. Circuit Theory, Vol. 3, no. 4, pp. 266-276,
  Dec. 1956
[2] B. Widrow, "Statistical analysis of amplitude quantized sampled-data
  systems" Trans. AIEE, Part. II, Vol.79, no. 52, pp.555-568, Jan. 1961
[3] tratta da The Rural Economy of Yorkshire: Comprizing the Management of
  Landed Estates, and the Present Practice of Husbandry in the Agricultural
  Districts of that County, scritto da Mr. Marshall (William), Vol. II,
  Londra: T. Cadell, 1788.
[4] Lawrence G. Roberts, Picture Coding Using Pseudo-Random Noise, MIT,
  tesi di dottorato, 1961 online
[5] Thomas Blount, Glossographia Anglicana Nova: Or, A Dictionary,
  Interpreting Such Hard Words of whatever Language, as are at present used
  in the English Tongue, with their Etymologies, Definitions, &c. Also, The
  Terms of Divinity, Law, Physick, Mathematics, History, Agriculture,
  Logick, Metaphysicks, Grammar, Poetry, Musick, Heraldry, Architecture,
  Painting, War, and all other Arts and Sciences are herein explain'd, from
  the best Modern Authors, as, Sir Isaac Newton, Dr. Harris, Dr. Gregory,
  Mr. Lock, Mr. Evelyn, Mr. Dryden, Mr. Blunt, &c., Londra, 1707.
[6] Per approfondire, vedi anche percezione del colore

Fonti

- (EN) Aldrich, Nika. "Dither Explained (pdf)"
- (EN) Aldrich, Nika. "Digital Audio Explained"
- (EN) Katz, Bob. The Secrets of Dither"
- (EN) Katz, Bob. "Mastering Audio"

Voci correlate

- Audio digitale
- Video digitale
- Algoritmo di Floyd-Steinberg
- Comando di valvole proporzionali in Pulse-width modulation

Altri progetti

- Wikimedia Commons contiene immagini o altri file su Dithering

Collegamenti esterni

- (EN) DHALF.TXT (1991) analizza vari filtri basati sul Floyd-Steinberg.
- (EN) Cos'è il Dither? Articolo pubblicato su Australian HI-FI contenente
  esempi grafici di come il dithering audio riduca le distorsioni.

Digitalizzazione

La digitalizzazione è il processo di conversione che, applicato alla
misurazione di un fenomeno fisico, ne determina il passaggio dal campo dei
valori continui a quello dei valori discreti. Tale processo viene oggi
comunemente sintetizzato nei termini di passaggio dall'analogico al
digitale.

La misurazione della temperatura tramite un termometro o la
rappresentazione di un suono tramite il tracciamento di onde sono esempi di
grandezze di tipo analogico, in quanto i valori che possono essere assunti
sono infiniti.

In effetti l'operazione comporta una perdita di informazioni, che però in
alcuni casi è accettabile in quanto si guadagna in semplicità di
rappresentazione o in altri casi non è comunque percepita.

Nel campo dell'informatica e dell'elettronica, con digitalizzazione si
intende il processo di trasformazione di un'immagine, di un suono, di un
documento in un formato digitale, interpretabile da un computer, dove per
formato digitale si intende un codice binario in cui tutto è rappresentato
da combinazioni di zero o uno, quindi da stati del tipo acceso/spento. Un
disco in vinile su cui è registrata una canzone rappresenta un esempio di
riproduzione analogica di un suono; la stessa canzone riprodotta tramite un
computer ne rappresenta il formato digitale.

Analogico e digitale

Per analogico si intende un sistema in cui una quantità fisica
continuamente variabile (ad esempio, l'intensità di un'onda audio) viene
rappresentata da un'altra (ad esempio, la tensione di un segnale elettrico)
nel modo più fedele possibile. È il sistema dell'approssimazione,
dell'opposizione originale/falso, dell'imprecisione. È digitale invece un
sistema o dispositivo che sfrutta segnali discreti per rappresentare e
riprodurre segnali continui sotto forma di numeri o altri caratteri. È
l'universo nel quale le informazioni vengono rappresentate da stringhe di 0
e 1, attivo/inattivo, alto/basso, vero/falso. L'analogico che, come spiega
la parola stessa, tende ad evidenziare il legame che esiste tra i fenomeni,
secondo grandezze continue che subiscono progressive trasformazioni, è
custode e testimone del tempo, della tradizione; il digitale è invece il
regno dei caratteri discreti, discontinui, un mondo dove le cose non
avranno sfumature. Saranno 0 o 1, dentro o fuori, bit o non-bit.

Nella parabola della sofisticazione di ciò che si ha intorno, non si
inscrive solo un processo di miglioramento tecnologico, ma trovano spazio i
geni nuovi di un cambiamento e di un ripensamento dell'intero modo di
concepire il reale, le sue cose e gli usi che ne facciamo. Il passaggio
dall'analogico al digitale non riguarda solo ed esclusivamente il mondo
della tecnologia ed i suoi fruitori, non solo i massmedia e quanti, in
questi anni, si sono occupati di vecchi e nuovi media. Parlare di analogico
e digitale, in fondo, significa oggi parlare delle due esclusive modalità
di produzione e fruizione del flusso comunicativo (o forse, delle più
importanti categorie di gestione e comprensione della realtà).

Il termine digitalizzazione deriva dalla parola digitale; essa indica la
trasformazione o la realizzazione di uno strumento di misura di una
grandezza fisica, o di un'apparecchiatura di elaborazione dei dati, oppure
di un sistema di comunicazione in modo tale che la grandezza di uscita sia
espressa in forma numerica e non in forma analogica. Il termine è anche
riferito alla grandezza fisica stessa.

Livelli di analisi e pertinenza

È a questo proposito, dunque, che sarà opportuno scindere le coordinate di
una riflessione sull'argomento in 3 livelli di analisi e pertinenza:

un primo livello attinente alle dinamiche del sistema produttivo più
generale; un secondo livello relativo ai percorsi di integrazione e
differenziazione del sistema mediale; infine, un'ultima dimensione, attenta
alle ripercussioni verificatesi nel sistema sociale e culturale delle
comunità investite dall'avvento delle ICT's. Per quanto attiene la sfera
produttiva, va detto che la rivoluzione digitale parte da molto lontano,
trovando prodromi in tempi insospettabili. Essa va letta come un processo
che non ha trovato una sua realizzazione fulminea con l'avvento del bit, ma
attraverso un decennale percorso, alimentato dalle necessità che il sistema
produttivo via via esprimeva. Già il telegrafo e le prime macchine
computistiche funzionavano secondo una logica digitale, pur non possedendo
la tecnologia del bit. Esisteva, insomma, già una prima esigenza nella
catena produttiva.

Storia della digitalizzazione

L'obiettivo di fondo, identificato da alcune avanguardie della ricerca fin
dagli anni trenta del secolo trascorso, è quello di riorganizzare la
conoscenza in modo sempre più efficiente, semplificando la selezione delle
notizie in un mondo sommerso dalle informazioni. In una estrema opera di
semplificazione del processo, si potrebbe affermare che quell'obiettivo
utopistico ha generato gli ipertesti, il pc, Internet.

Si è dovuto attendere l'invenzione del chip, dei primi computer e della
rete Internet perché il bit diventasse davvero una rivoluzione. Rivoluzione
spinta e alimentata dagli interessi congiunti dell'industria militare
(negli anni cinquanta) e dei mondializzati commerci contemporanei. Il bit è
stato allo stesso tempo causa e conseguenza del fenomeno della
mondializzazione. Da una parte il progresso tecnologico ha dischiuso
potenzialità impensabili sia dal punto di vista dell'accrescersi
dell'intelligenza delle macchine, sia dal punto di vista della
trasformazione, elaborazione e trasmissione delle informazioni. Dall'altra
le esigenze dei governi e delle grandi aziende hanno liberato fondi ingenti
per la ricerca e la sperimentazione di queste tecnologie.

Fino a ieri (finché c'era la guerra fredda) erano i militari a finanziare
le ricerche di punta: caschi per la realtà virtuale o sistemi avanzati per
l'addestramento dei piloti. Oggi è cambiato tutto: è l'industria
dell'entertainment a finanziare i settori più avanzati. Le ragioni di
questa tendenza sono evidenti. L'industria del divertimento può
sperimentare in tempi rapidi sempre nuove applicazioni su una platea di
giovanissimi, che sono certamente i più adatti ad apprendere tecniche
avanzate. I videogiochi diventano così uno strumento di sperimentazione di
massa di tecniche di interazione uomo-macchina, che poi possono essere
riutilizzate in altri settori: dall'istruzione a distanza al commercio
elettronico, per esempio.

La rivoluzione delle comunicazioni segue quella industriale e modifica il
corpo stesso del suo essere: negli anni ottanta e novanta, si assiste così
al passaggio da un'interfaccia statica ad un'interfaccia multimediale
dell'informazione.

Il sistema mediale ingloba e subisce, al tempo stesso, le nuove
acquisizioni digitali, ridefinendo sé stesso in virtù delle incredibili
potenzialità tecniche dischiuse. In effetti, quelli introdotti dalle ICT's,
solo latamente possono essere considerati "nuovi" media: fatta eccezione
per Internet, si è in presenza di un'evoluzione e di una ridefinizione dei
vecchi mezzi di comunicazione, in parte digitalizzati. I media "primitivi"
come la stampa, la radio, la TV potevano solo "essere visti". Il
broadcasting non consente interazione con i contenuti né tanto meno con la
loro fonte, quindi può solo offrire una fruizione passiva dell'atto
comunicativo. Resta impossibile produrre informazioni, essere all'interno
del media, interagire, essere visti. L'architettura logico-tecnica many to
many di Internet, consente all'utente di avere pieno controllo sulla
comunicazione telematica, trasformandolo da spettatore a produttore di
informazione. Internet viene incontro al bisogno di visibilità delle
persone perché conferisce ad essi la piena autonomia della fruizione del
mezzo stesso. Le nuove tecnologie dell'informazione e della comunicazione
stanno modificando radicalmente anche il rapporto di interazione tra
producer e consumer. Esse non si configurano più solo come strumenti per
rendere più efficienti attività definite e quasi immutabili (le procedure,
i flussi di lavoro) ma rappresentano prima di tutto delle opportunità, dei
fattori abilitanti che rendono possibili il cambiamento dei tradizionali
modi di produrre, di distribuire di organizzarsi, di scambiare e
condividere il sapere, di cooperare: ciò che Levy ha chiamato intelligenza
collettiva nel 1996.

La cultura della comunicazione, sconvolta dall'apparire di Internet, si
ristruttura sulla base di tre elementi fondamentali che informano l'agire
sociale e la trasmissione della conoscenza: multimedialità, ipertestualità
e interattività. Il link diviene la metafora del nostro quotidiano rapporto
con la realtà. L'avvento delle ICT's fa registrare fenomeni di cambiamento
nei processi comunicativi e nell'industria culturale. La digitalizzazione
si è imposta come sistema dominante perché da un lato rende più economica
la produzione industriale delle informazioni e, allo stesso tempo, espande
i mercati e i confini della loro fruizione. L'era analogica era
caratterizzata da spazi confinati all'interno dei limiti imposti dai
singoli mezzi di comunicazione e dai costi di produzione e di trasmissione.
Quella digitale scopre i mercati globali e li raggiunge attraverso percorsi
rizomatici. Le vecchie agenzie dell'informazione si trasformano anche in
versioni digitali, entrando per di più in competizione con il consumer
della Rete. Si scontrano globalizzazione e segmentazione estrema
dell'informazione: le reti satellitari consentono una fruizione planetaria
dello stesso segnale trasmesso, ma se guardiamo ad esempio alla TV digitale
ci si rende subito conto dell'estrema tematizzazione dei contenuti
veicolati: continuità e discontinuità, unificazione e targettizzazione,
comunità virtuali e pay-per-view isolazionista. Come afferma Thompson
(1998), pur non riferendosi esplicitamente alle nuove tecnologie, si è in
presenza di un duplice fenomeno: da una parte, si assiste ad una
globalizzazione delle telecomunicazioni, dall'altra ad una localizzazione
ed individualizzazione della fruizione dei contenuti. Solo la discontinuità
del digitale rende possibile la creazione di mondi collegati: la continuità
della cultura contemporanea nasce dalla trasmissione discreta delle
sequenze informatiche binarie. Con la nascita delle grandi rete di fibre
ottiche l'informazione di massa diventa il suo opposto, cioè informazione
personalizzata.

L'estensione della interattività e l'unificazione del medium (il pc-tv e la
tv-pc), ovvero ciò che da più parti viene definita come "convergenza",
completano il quadro e insieme fanno saltare in aria il tradizionale
sistema dei media. All'interno della società della connessione, l'uomo
digitale riesce a far convivere codici e linguaggi diversi all'interno
della stessa macchina. Sempre la stessa, ma di volta in volta capace di
implementare funzioni e utilità differenti. L'etica della discontinuità
viene a configurarsi come causa e conseguenza del linkage quotidiano che
l'uomo ha adottato come suo schema di pensiero. La traduzione di questa
nuova struttura cognitiva è la convergenza di informazioni diverse sullo
stesso supporto nonché l'alimentazione di diversi supporti attraverso le
medesime informazioni. E così ritroviamo il frigorifero nel computer e
quest'ultimo nella lavatrice, così come, l'industria del telefono in quella
delle canzonette: il sogno fatto carne di Negroponte.

Stiamo infatti già assistendo all'estensione della interattività e
all'unificazione del medium: processi che completano il quadro e insieme
ridefiniscono il tradizionale sistema dei media e delle reciproche
relazioni che la storia delle comunicazioni ha ciclicamente attraversato.
Siamo dunque di fronte a un vero e proprio rimescolamento, molto più
rilevante in quanto investe simultaneamente molti aspetti: le forme di
comunicazione, i linguaggi, la mentalità corrente. Un unico mezzo per
infinite funzioni, il concetto di multimedialità o meglio ipermedialità si
estende anche agli oggetti fisici, non più solo al diverso approccio verso
l'organizzazione dei contenuti. Con le modalità di trasmissione analogiche,
diversi tipi d'informazione non potevano viaggiare insieme sullo stesso
supporto ed essere decodificati dal medesimo terminale. Il segnale radio di
un televisore era infatti totalmente diverso da quello di un telefono
mobile e, per essere tradotto in immagini, aveva bisogno di circuiti
dedicati assenti in un telefono.

L'adozione di una rappresentazione digitale in luogo di quella analogica,
nel video, nella musica, nella stampa e nelle telecomunicazioni in
generale, potenzialmente trasforma qualunque forma di attività umana di
tipo simbolico in software, e cioè in istruzioni modificabili per
descrivere e controllare il comportamento di una macchina. L'utente di fine
secolo, la cosiddetta generazione Napster, trova la cifra della propria
formazione culturale e della propria interazione con la realtà circostante
nell'interfaccia e nell'ipertesto. Si tratta di due elementi che hanno
cambiato radicalmente il nostro modo di rapportarci all'informazione
generando un coinvolgimento continuo da parte dello spettatore, tanto da
rendere questa parola desueta. Chi utilizza Internet è un utente che
modifica l'enorme flusso d'informazione, secondo le sue esigenze, per il
semplice fatto che se le costruisce attingendo da un archivio comune e
spesso gratuito.

Questo è il risultato dell'incontro tra arte e scienza, della formazione di
una nuova cultura che ha carattere popolare e si basa sulle conseguenze di
una tecnologia che ha invaso il nostro ambiente culturale e promuove un
processo di sviluppo automatico sostenuto dalle stesse innovazioni
tecnologiche e da un permanente desiderio di cambiamento. La tecno-cultura
realizza in parte la globalizzazione di una nuova generazione a cui è
permesso l'accesso alle merci tecnologiche high-tech, e la conseguente
familiarità con gli strumenti utilizzati, ma anche un dialogo con le derive
culturali che contribuiscono a sviluppare nuove dinamiche all'interno del
pubblico discorso. L'epoca digitale comporta, dunque, una diversa
percezione delle cose, una percezione non-analogica che è molto più vicina
al sentire tipico delle arti. Nel paesaggio mediale, nel villaggio globale,
ogni comunità produce segni e significati, ogni cultura che si rispetti si
fonda su un insieme di esperienze e di valori condivisi. Attraverso l'uso
delle nuove tecnologie si va sempre di più verso una società sintetica,
sintetica in diverse accezioni; innanzitutto si intende per comunicazione
sintetica la velocità, l'accelerazione degli scambi comunicativi. Ma per
sintetica intendiamo anche la sintesi di apparecchiature diverse che fino a
poco tempo fa erano considerate assolutamente non reciprocamente
interferenti e che con l'avvento delle nuove tecnologie possono, in realtà,
interagire. E, ancora, sintetica anche nel senso di ricreazione di
immagini, di oggetti fondamentalmente molto vicini all'originale: il
sintetico si contrappone al reale o all'oggetto vero, all'oggetto-punto e
alla riproduzione dell'oggetto in rapporto alla vecchia riproduzione delle
tecnologie tradizionali (Bettetini, 1998).

La digitalizzazione crea un testo di dimensioni planetarie, che si sviluppa
senza soluzione di continuità (De Carli, 1997), un ipertesto che nasce dai
legami che si instaurano tra i vari testi immessi nella rete. Internet è la
nuova "semiosfera" (Lotman, 1997), che come una pellicola, una sottile
patina di segni e codici linguistici avvolge la biosfera, il pianeta-terra,
"interamente fasciato di reti telematiche". A dispetto di quanti
individuano una degenerazione della "società dell'immagine", Internet vive
prevalentemente di comunicazione scritta. Ma la comunicazione a stampa, la
"galassia Gutenberg", è fatta di carta, inchiostro, di fisicità, è immersa
nel mondo materiale di cui subisce le leggi della creazione come dell'usura
del tempo. Internet non sarà certamente un'intelligenza artificiale che ha
acquisito una propria personalità; ma se è vero che il bit, come scrive
Pancini, tende a divenire "quasi una nuova Weltanschauung dell'uomo
prossimo venturo", sta nascendo progressivamente un altro mondo, fatto di
quelli che Augé chiama "non-luoghi" (1993), che nondimeno vengono avvertiti
nella loro surrealtà dai nostri sensi: sullo schermo dei computer c'è un
mondo che non esiste e che comunque noi percepiamo come reale.

La commistione tra reale e virtuale non deve però trarre in inganno: fin
quando si è immersi nel Cyberspazio, è percepibile un abbattimento netto
della distinzione centro-periferia, ma non appena oltrepassata la sua
soglia, re-immessi nel mondo reale, ci si accorge delle distanze abissali
(e ancora analogiche) che separano dai luoghi materiali e immateriali.

L'equivoco contemporaneo risiede proprio nella confusione tra due mondi
ancora distanti: quello della conoscenza e quello della programmazione. Il
digitale si configura come una possibilità di rappresentazione del reale,
ma pur sempre come una modalità di semplice trasmissione dei contenuti.
Fornire i contenuti è (e resterà sempre) compito dell'homo analogicus.

Nel suono

Negli ultimi anni, di pari passo con l'avvento della digitalizzazione, le
applicazioni multimediali si sono diffuse sempre più sino a diventare d'uso
comune. Una delle caratteristiche della multimedialità è certamente
l'utilizzo di audio digitale vocale e sonoro. Il più grande ostacolo legato
alla digitalizzazione dell'audio è l'elevata dimensione dei file che si
vengono a produrre, il che pone agli operatori del settore (in particolar
modo quelli legati ad internet) il problema di ridurre lo spazio occupato
dai dati per ottenere il duplice vantaggio di:

- risparmiare in termini di occupazione di memoria;
- risparmiare in termini di tempo di trasferimento sulla rete.

Per questa ragione, quando parliamo di digitalizzazione dell'audio,
dobbiamo parlare anche di tecniche di compressione dei dati. Le tecniche di
compressione dei dati, di qualsiasi natura essi siano, si dividono in:

- lossy: comprimono i dati attraverso un processo con perdita
  d'informazione che sfrutta le ridondanze nell'utilizzo dei dati
- lossless: comprimono i dati attraverso un processo senza perdita
  d'informazione che sfrutta le ridondanze nella codifica del dato

A seconda della tecnica di compressione utilizzata sono stati creati vari
formati. L'MPEG è uno standard comune per la codifica audio-video.

Parametri fondamentali

Il suono è un segnale continuo, per essere memorizzato deve essere
campionato ottenendo così un segnale digitale. Tre sono i parametri che
caratterizzano il campionamento, tali parametri influenzano sia lo spazio
occupato sia la qualità del suono:

- numero di canali
- risoluzione
- frequenza di campionamento

Il numero di canali

Esistono due modi di ripartizione dei canali audio: Mono e Stereo. La
modalità Mono ha un solo canale mentre quella Stereo ne ha due separati
(sinistro e destro). Ovviamente un segnale Stereo occupa, in termini di
spazio, il doppio di uno segnale Mono. Nelle applicazioni più recenti il
numero di canali è notevolmente aumentato, si pensi al surround, ma come
sempre nell'informatica il problema sorge nel passaggio da uno a molti, e
non interessa se questi molti siano due, dieci o più.

La risoluzione

Rappresenta il numero di bit utilizzati per rappresentare i campioni;
solitamente si utilizzano 8 o 16 bit per campione: nel primo caso si hanno
256 valori possibili, relativamente pochi, infatti offrono una qualità del
suono inferiore a quella di un nastro, nel secondo si hanno circa 65000
valori.

La frequenza di campionamento

È il numero di campioni al secondo; può variare da 11 kHz adatta alla
registrazione della voce, a 22 kHz adatta alla registrazione di un nastro
fino a 44 kHz per una registrazione a qualità cd. Questo parametro merita
una maggiore attenzione rispetto ai precedenti, infatti segnali analogici
diversi possono dare luogo allo stesso segnale campionato.
Per questo motivo è possibile che segnali analogici diversi, se campionati
con una frequenza troppo bassa, diano luogo alla stesso audio digitale.

La teoria del campionamento, in particolare il teorema del Campionamento di
Nyquist-Shannon, ci fornisce la soluzione a tale problema, infatti per
avere una relazione univoca fra il segnale originale e quello campionato è
sufficiente che la frequenza di campionamento sia il doppio della massima
frequenza del segnale originale. Sinteticamente può essere spiegato così:
"Se si prendono dei campioni molto stretti fra di loro (frequenza di
campionamento alta), ed il segnale varia lentamente nel tempo (la banda del
segnale è sufficientemente stretta) si possono ricongiungere i vari punti
individuati dai campioni senza intaccare la qualità del suono originale."
Il famoso bitrate, non è altro che il prodotto dei tre fattori appena
citati (numero di canali, frequenza e risoluzione), ovvero non è altro che
il numero di bit necessari per riprodurre un secondo di suono e si misura
in bit/s. Esempio: Un minuto d'audio stereo con qualità CD occupa circa 10
Mb (2 canali *2 byte per campione *44.1 kHz *60 s) mentre la riproduzione
richiede una bitrate di 1,4 Mbit/s (2 canali *16 bit per campione *44.1
kHz).

Le tecniche di rappresentazione

Attualmente esistono diversi metodi per rappresentare dati audio; di
seguito sono descritti brevemente alcuni formati.

WAV, AIFF
Sono i formati più semplici creati rispettivamente da Microsoft-IBM e
Apple. Si basano sulla tecnica di modulazione a codifica numerica d'impulsi
(Pulse-Code Modulation o PCM), sono cioè, una registrazione fedele dei
suoni in formato digitale. Entrambi occupano una notevole quantità di
memoria, circa 10 MB per minuto, e sono utilizzati a livello professionale.

Midi
Questo formato nasce come standard per strumenti musicali digitali. Un file
.midi può essere visto come uno spartito interpretato da un sequencer,
infatti al suo interno contiene una sequenza di comandi che indicano quale
nota far suonare, da quale strumento, con quale intensità e per quanto
tempo. Questo comporta un notevole risparmio di spazio: un intero brano
musicale, della durata di svariati minuti, può occupare qualche decina di
kbyte, infatti ogni singolo evento MIDI occupa soltanto 11 byte.

Streaming audio: RAM, RM, ASF, ASX
Lo streaming è il trasferimento in rete dei dati audiovisivi in tempo
reale; tutto questo senza tempi d'attesa derivanti dal download completo
del file sull'disco rigido del computer. Con lo streaming, infatti, non
viene scaricato l'intero file audio prima di consentirne l'ascolto, ma la
riproduzione inizia per ogni blocco di due secondi d'ascolto; nel frattempo
viene scaricato il successivo. Si possono verificare momentanee
interruzioni nella riproduzione, nel caso in cui il traffico nella rete
risulti congestionato. Le due principali tecnologie d'audio streaming
utilizzate sono Real (attraverso Real Player), e Windows Media (attraverso
Windows Media Player). La tecnologia dello streaming audio ha permesso, per
esempio, alle principali emittenti radiofoniche di presentare sui propri
siti web i loro programmi trasmessi via etere.

DAB: Digital Audio Broadcasting
È un sistema di trasmissione di segnali radio digitali via etere. Il DAB si
basa su un algoritmo di compressione audio simile a MP3 ma evoluto per la
trasmissione di bouquet di pacchetti che permettono all'emittente di
presentare più di una versione dei suoi programmi. La qualità della
trasmissione è variabile secondo la banda occupata. Durante la trasmissione
sono usati i codici cyclic redundancy check (CRC) per correggere errori e
mantenere la trasmissione ad un elevato livello qualitativo anche in
condizione di ricezioni non ottimali.

Nelle immagini fisse

Un'immagine digitale è un insieme ordinato di numeri interi, ottenuti dalla
scansione di un'immagine analogica (sorgente), utilizzando
un'apparecchiatura speciale detta scanner (digitalizzazione di un'immagine
analogica) o tramite l'utilizzo di fotocamere digitali che producono
direttamente l'immagine digitale dalla scena ripresa.

Ogni numero dell'insieme ordinato rappresenta l'intensità luminosa media
(livelli di grigio) di un'areola corrispondente nell'immagine sorgente,
detta pixel (PICture ELement). L'areola è rettangolare e caratterizzata da
due dimensioni dX (orizzontale) e dY (verticale), dette passi di
campionamento della digitalizzazione, mentre i reciproci (1/dX e 1/dY)
vengono detti frequenze di campionamento.

L'insieme ordinato di campioni assume l'aspetto di una matrice o tabella
numerica composta da un certo numero di righe (M) e di colonne (N). Ogni
campione o elemento di tabella è localizzato tramite il suo numero di riga
e di colonna, supponendo che il primo pixel in alto a sinistra costituisca
l'origine.

La capacità di ogni sistema di digitalizzazione di eseguire misurazioni più
o meno fini viene detta risoluzione. Questa si divide in radiometrica e
geometrica: Risoluzione radiometrica: è la minima differenza di luminosità
rilevabile e viene anche detta profondità del colore in bit (da 0 -> nero,
a L-1 -> bianco) e ogni sistema d'acquisizione utilizza una diversa
risoluzione tra:

- in bianco e nero
  + 1 bit: 2 valori possibili (0,1)
- a livelli di grigio
  + 8 bit: valore standard (256 livelli di grigio possibili)
  + 10, 11, 12, 16... bit: per applicazioni sofisticate
- a colori
  + 24 bit
  + 30 bit
  + 36 bit
  + 48 bit

Risoluzione geometrica: è legata all'ampiezza delle areole, minori sono i
passi di campionamento (dX e dY), maggiore è la risoluzione geometrica del
dispositivo. La risoluzione geometrica viene misurata in punti per pollice
o DPI (dots per inch).

Le immagini digitali possono essere:

- Raster o bitmap (matrici di pixel)
  + Immagini binarie
  + Immagini a livelli di grigio
  + Immagini a colori dotate di palette (o CLUT, Color Look-Up Table)
  + Immagini RGB (True color, ogni matrice R, G o B è un'immagine a livelli
    di grigio)
- Vettoriali
  + Immagini definite da moduli grafici (punti, segmenti, poligoni,
    poliedri...)
- Miste bitmap + vettoriale

Per ogni tipo di immagine occorre fare un discorso a parte sulla
memorizzazione e sulla qualità/spazio occupato; per esempio in un file
bitmap sono contenute informazioni quali: tipo di immagine, numero di righe
e di colonne, profondità dei pixel (risoluzione radiometrica), palette del
colore (se presente), valori dei pixel e informazioni aggiuntive come la
data di creazione, le coordinate dell'origine, risoluzioni geometriche,
etc.

Tecniche di memorizzazione dei valori dei pixel:

- Senza compressione (il numero dei valori memorizzati è M x N e non c'è
  nessun risparmio di spazio)
- Con compressione (il numero dei valori memorizzati è inferiore a M x N
  con un risparmio proporzionale al grado di compressione Y = byte
  originali / byte dopo la compressione)
  + senza perdita di informazione (lossless)
  + con perdita di informazione (lossy)

I principali metodi di compressione lossless sono:

- Run-length encoding (RLE): compressione delle sequenze di pixel
  consecutivi uguali
- Lempel-Ziv-Welch (LZW): ogni sequenza significativa di pixel viene
  isolata e immessa in un dizionario dei dati (inserito nel file) e
  sostituita dal suo numero nel dizionario

Il più usato e diffuso metodo di compressione a perdita di informazione,
anche se non è il più efficiente è il JPEG (Joint Photographic Expert
Group) che comprime separatamente i dati di luminanza e quelli di
cromaticità con rapporto di compressione controllabile dall'utente tramite
la percentuale di perdita di informazioni.

Ad ogni formato di file e a ogni metodo di compressione usato per le
immagini, corrisponde un'estensione diversa del nome del file come: BMP
(BitMaP), GIF (Graphics Interchange Format), JPEG, MAC (Mac Paint), PCD
http://www.r4-dsi.it (KODAK Photo CD), PCX (PC Paintbrush File Format), PNG
(Portable Network Graphic), PSD (Adobe Photoshop image format), TARGA
(Targa Image File), TIFF (Tag Image File Format), RAW format (semplice
memorizzazione della matrice dei pixel riga per riga).

Nelle immagini in movimento

Un video o filmato è costituito da una serie di immagini, chiamate
fotogrammi, che si susseguono in rapida sequenza.

- I-Frames (fotogrammi di tipo I, chiamati anche Intra-Frames o Key-Frames
  ): vengono codificati utilizzando le informazioni contenute nel
  fotogramma stesso, non contengono nessun riferimento o informazione sui
  fotogrammi adiacenti e sono compressi identicamente ad un'immagine
  singola (per es. JPEG); essi vengono inseriti in genere quando c'è un
  repentino cambiamento tra due immagini successive, ma sono comunque
  spesso vincolati da un intervallo massimo tra loro (Maximum I-Frame
  Interval) che corrisponde solitamente a 10/12 secondi (circa 250/300
  fotogrammi), utili per le ricerche di una particolare scena.
- P-Frames (fotogrammi di tipo P, Predicted Frames, chiamati anche
  Delta-Frames o Inter-Frames): vengono codificati utilizzando informazioni
  acquisite in base al fotogramma precedente, sia questo di tipo I o P e,
  quindi, utilizzando le somiglianze tra fotogrammi successivi, risultano
  più piccoli degli I-Frames; partendo dalla considerazione che per ogni
  secondo di video si susseguono 25 fotogrammi, risulta molto più
  efficiente memorizzare non i singoli fotogrammi in modo indipendente, ma
  esclusivamente le minime differenze tra loro, operazione resa semplice
  utilizzando questo tipo di fotogrammi, con il risultato di memorizzare un
  numero significativamente più basso di bit. Tali fotogrammi quindi
  contengono le informazioni della posizione (X',Y') nel fotogramma
  corrente in cui si è spostato un blocco che aveva coordinate (X,Y) in
  quello precedente (Motion Estimation / Compensation).
- B-Frames (Bi-directional encoding): con questo tipo di fotogrammi la
  ricerca del moto (Motion Estimation / Compensation) è effettuata sia sul
  fotogramma precedente sia su quello successivo, alterando l'ordine con
  cui i fotogrammi vengono archiviati all'interno del file video compresso
  del fotogramma corrente con quello successivo (per es. I B B P -> I P B
  B);

Un concetto importante è quello di bitrate. Il bit-rate (velocità dei bit)
è la quantità di bit che vengono trasmessi in ogni secondo e viene misurata
in bps (bit per secondo); più alto è il bitrate, più alta è la quantità di
bit riservata ad ogni fotogramma e conseguentemente maggiore sarà il numero
di informazioni che possono essere memorizzate, quindi la qualità del
singolo fotogramma.

Per quanto riguarda la compressione video, ci si comporta analogamente alla
compressione di una singola immagine, moltiplicata per il numero di
fotogrammi che si susseguono, utilizzando propriamente i tre tipi di frames
e le regole di encoding/decoding.

Per effettuare la compressione vengono utilizzati elementi detti Codec
video (Coder/Decoder), programmi composti da un encoder, il cui scopo è
comprimere una sequenza di immagini (video) per archiviarla in un file e un
Decoder, necessario per decomprimere la sequenza e poterla nuovamente
visualizzare.

Le tecniche di compressione video possono essere suddivise in due grandi
categorie:

- Lossless: la compressione è un processo perfettamente reversibile che
  avviene senza perdita di informazione e dove video originale e video
  decompresso sono identici in tutti i dettagli
- Lossy: tecniche di compressione non reversibile, nelle quali video
  compresso e decompresso non sono più identici in quanto al momento della
  compressione sono state volutamente eliminate alcune informazioni con lo
  scopo di occupare spazi ridotti; tali tecniche sono le più diffuse e
  conosciute, come le codifiche MPEG (1, 2 e 4), DivX, Xvid, etc..

Nell'olfatto

Gli ultimi studi nell'ambito della misurazione degli odori hanno portato
alla digitalizzazione e alla creazione di un naso elettronico. Si parla di
sistema olfattivo artificiale (SOA).

Voci correlate

- Acquisizione dati
- Digitale (informatica)
- Distribuzione digitale

Altri progetti

- Wikizionario contiene il lemma di dizionario «digitalizzazione»
- Wikimedia Commons contiene immagini o altri file su digitalizzazione

Collegamenti esterni

- Digitalizzazione, in Thesaurus del Nuovo soggettario, BNCF, marzo 2013.

LabVIEW

LabVIEW (abbreviazione di Laboratory Virtual Instrumentation Engineering
Workbench) è l'ambiente di sviluppo integrato per il linguaggio di
programmazione visuale di National Instruments. Tale linguaggio grafico
viene chiamato Linguaggio G.

Realizzato originariamente per Apple Macintosh nel 1986, LabVIEW viene
utilizzato per principalmente programmi di acquisizione e analisi dati,
controllo di processi, generazione di rapporti, o più generalmente per
tutto ciò che concerne l'automazione industriale, su diverse piattaforme
come Windows, Linux, Mac OS e controllori National Instruments.

Programmazione G

Il linguaggio di programmazione usato in LabVIEW si distingue dai linguaggi
tradizionali perché la sua sintassi non è scritta ma grafica, e per questa
ragione viene chiamato G-Language (Graphic Language). Un programma o
sottoprogramma G, denominato VI (Virtual Instrument), non esiste sotto
forma di testo, ma può essere salvato solo come un file binario che può
essere aperto e compilato solo da LabVIEW.

La definizione di strutture dati ed algoritmi avviene con icone e altri
oggetti grafici, ognuno dei quali incapsula funzioni diverse, uniti da
linee di collegamento (wire), in modo da formare una sorta di diagramma di
flusso. Questo tipo di linguaggio viene definito dataflow (flusso di dati)
in quanto la sequenza di esecuzione è definita e rappresentata dal flusso
dei dati stessi attraverso i fili monodirezionali che collegano i blocchi
funzionali. Poiché i dati possono anche scorrere in parallelo attraverso
blocchi e fili non consecutivi, il linguaggio può realizzare spontaneamente
il multithreading senza bisogno di esplicita gestione da parte del
programmatore.

Collegamento con l'hardware

Interessante è la modalità di realizzazione del software, che si limita
spesso al semplice collegamento di blocchi già pronti, grazie alla vasta
libreria di funzioni predefinite e driver per la gestione dell'hardware.
LabVIEW è predisposto per la comunicazione con l'hardware di tipo IEEE 488,
VXI, PXI, RS-232, RS-485 e dispositivi DAQ plug-in. I programmi LabVIEW
sono compatibili con molti modelli di strumenti programmabili e schede di
acquisizione.

Dettagli dei VI

Nell'ambiente di sviluppo, i VI sono composti da tre parti principali:

- il pannello frontale
- lo schema a blocchi
- il riquadro connettori

Pannello frontale

Il pannello frontale è l'interfaccia utente del VI. Si realizza con
controlli e indicatori, che costituiscono i terminali interattivi
d'ingresso e d'uscita, rispettivamente. Essi sono ben più numerosi e
complessi dei widget normalmente forniti dal sistema operativo. I controlli
sono matrici, manopole, potenziometri, pulsanti, quadranti e molti altri;
simulano i dispositivi d'ingresso degli strumenti e forniscono dati allo
schema a blocchi del VI. Gli indicatori sono grafici, tabelle, LED,
termometri e molti altri; simulano i dispositivi d'uscita degli strumenti e
visualizzano i dati che lo schema a blocchi acquisisce o genera.

Schema a blocchi

Lo schema a blocchi è il diagramma di flusso che rappresenta il codice
sorgente, in formato grafico. Gli oggetti del pannello frontale appaiono
come terminali di ingresso o uscita nello schema a blocchi. Gli oggetti
dello schema a blocchi comprendono:

- terminali
- funzioni
- costanti
- strutture
- chiamate ad altri VI (subVI)
- fili di collegamento
- commenti testuali

Le funzioni sono esse stesse dei VI, anche se non hanno un loro pannello
frontale e un loro schema a blocchi. Possono avere un numero indefinito di
ingressi e di uscite come ogni VI.

Le strutture eseguono il controllo di flusso di base. Ad esempio il ciclo
FOR è rappresentato da un rettangolo che ripete N volte la porzione di
schema a blocchi che viene inserita al suo interno.

I fili di collegamento possono trasportare teoricamente qualunque mole di
dati di qualunque tipo, anche aggregati (bundle) definiti dal
programmatore. I fili possono essere di diverso spessore e colore per
permettere una facile identificazione dei dati che vi scorrono: ad esempio
i numeri interi scorrono su fili blu, i numeri decimali su fili arancioni
le stringhe su fili rosa.

Lo schema a blocchi può essere reso visibile anche durante l'esecuzione,
cosa molto utile in fase di debug, in quanto esiste la possibilità di
visualizzare con un'animazione al rallentatore il movimento dei dati lungo
i fili e il loro valore momentaneo.

Riquadro connettori

Ogni VI può essere a sua volta utilizzato come subVI (o sottoVI) e
comparire all'interno dello schema a blocchi di altri VI come una qualsiasi
funzione, e come tale può avere ingressi e uscite a cui collegare le linee
di flusso. Il riquadro connettori serve appunto a definire qual è l'aspetto
del VI quando appare come subVI in uno schema a blocchi di un VI più ampio:
che facciata ha l'icona, ma soprattutto come e dove vanno collegate le
linee per permettere il passaggio dei dati. In genere, con pochi click,
ogni controllo può essere associato a un ingresso e ogni indicatore può
essere associato a un'uscita.

Eseguibili

A partire dai VI si possono anche creare eseguibili a sé stanti e librerie
condivise (DLL), perché LabVIEW è un vero compilatore a 32 bit. Per
utilizzare tali eseguibili e DLL non occorre un'installazione di LabVIEW,
ma è necessario che sul computer di destinazione sia installato almeno il
run-time engine di LabVIEW, peraltro distribuito gratuitamente.

Storia

Il progetto LabVIEW nasce nel 1983 dalla necessità della National
Instruments di disporre di un software di programmazione grafica, con il
quale testare rapidamente gli apparati hardware prodotti da tale industria
statunitense.

Già nel 1986 è resa pubblica la versione 1 del software compatibile con i
sistemi Macintosh. Nel gennaio del 1990 viene pubblicata la versione 2, le
migliorie sul software rendono la velocità di esecuzione del VI
paragonabile ai programmi compilati in Ansi C. Il mese successivo in virtù
dell'innovatività dell'approccio grafico alla programmazione, viene
pubblicato il brevetto dal US Patent Office. Infine nel settembre 1992 ne
viene sviluppata una versione multipiattaforma, cioè per Microsoft Windows,
Mac OS e SunOS. In seguito venne supportato anche Linux.

La versione 8.0, pubblicata nel 2005, introduce per la prima volta anche il
supporto per la programmazione a oggetti. Il 4 agosto 2009 è stata
pubblicata la versione LabVIEW 2009, a 32 o 64-bit, che succede alla
versione 8.6. L'ultima versione distribuita è LabVIEW 2016.

Note

Altri progetti

- Wikimedia Commons contiene immagini o altri file su LabVIEW

Collegamenti esterni

- Sito ufficiale National Instruments, ni.com.
- ILVG, comunità italiana di utenti LabVIEW, ilvg.it.

MATLAB

MATLAB (abbreviazione di Matrix Laboratory) è un ambiente per il calcolo
numerico e l'analisi statistica scritto in C, che comprende anche l'omonimo
linguaggio di programmazione creato dalla MathWorks. MATLAB consente di
manipolare matrici, visualizzare funzioni e dati, implementare algoritmi,
creare interfacce utente, e interfacciarsi con altri programmi. Nonostante
sia specializzato nel calcolo numerico, uno strumentario opzionale
interfaccia MATLAB con il motore di calcolo simbolico di Maple. MATLAB è
usato da milioni di persone nell'industria e nelle università per via dei
suoi numerosi strumenti a supporto dei più disparati campi di studio
applicati e funziona su diversi sistemi operativi, tra cui Windows, Mac OS,
GNU/Linux e Unix.

Cenni storici

Abbreviazione di "MATrix LABoratory", MATLAB fu creato alla fine degli anni
settanta da Cleve Moler, il presidente del dipartimento di scienze
informatiche dell'Università del Nuovo Messico. Egli creò MATLAB per dare
ai suoi studenti accesso a LINPACK e ad EISPACK senza che essi dovessero
conoscere il Fortran. Presto si diffuse nelle altre università e trovò un
grande pubblico tra la comunità dei matematici applicati. Jack Little, un
ingegnere, conobbe il programma durante una visita a Moler all'Università
di Stanford nel 1983. Riconoscendo il suo potenziale commerciale, si unì
con Moler e Steve Bangert. Essi riscrissero MATLAB in linguaggio C e
fondarono la The MathWorks nel 1984 per continuare il suo sviluppo.

Interfaccia

L'interfaccia principale di MATLAB è composta da diverse finestre che è
possibile affiancare, spostare, ridurre a icona, ridimensionare e così via.
Le finestre principali, più usate, sono quattro:

- Command Window
- Workspace
- Current directory
- Command history

Prompt dei comandi (Command Window)

La Command Window è una finestra dell'interfaccia principale di MATLAB,
nella quale è possibile digitare comandi supportati, e visualizzare a video
in tempo reale i risultati. Ad esempio è possibile utilizzare Matlab come
una potente calcolatrice:

2+3
ans=5

La variabile ans è una variabile standard. In essa viene caricato l'ultimo
risultato generato. Con il comando quit, si esce dal programma:

quit

È presente anche un help off-line sintetico richiamabile tramite il
comando:

help <nome_comando>

Dove ovviamente <nome_comando> si riferisce al comando sul quale abbiamo
bisogno di aiuto. Esempio

help sqrt
help det

Le operazioni standard sono:

+ (somma)
- (sottrazione)
* (moltiplicazione)
/ (divisione)
^ (elevamento a potenza)

Se si scrivono più comandi su una stessa linea è necessario separarli con
una virgola ',' . Se un comando è terminato con un punto e virgola (;), i
risultati ottenuti non verranno visualizzati immediatamente in Command
Window, ma verranno solo salvati in workspace (cfr paragrafo successivo).
Con la freccia in su, tasto ↑, si scorrono i comandi precedentemente
eseguiti. Si possono utilizzare le parentesi () per modificare la priorità
tra le varie operazioni.

Workspace

Il Workspace è lo spazio di lavoro (o spazio di memoria) contenente le
variabili dichiarate. Per visualizzare tutte le variabili utilizzate si
utilizza il comando who, mentre con il comando whos si visualizzano tutte
le variabili utilizzate, ma in forma estesa, cioè ci viene data la loro
descrizione: nome, dimensione, memoria occupata, classe e attributi.

La finestra Workspace elenca tutte le variabili allocate in workspace in
questo momento, e dà la possibilità di allocare nuove variabili o di
importare dall'esterno un elenco di variabili (ad esempio da un file di
testo). È inoltre possibile stampare l'elenco delle variabili attuali od
eliminarne una direttamente dalla finestra (senza scrivere nessun comando
insomma).

Per visualizzare in Command Window il valore di una variabile memorizzata
in workspace in questo momento, è sufficiente scrivere il nome della
variabile stessa.

Current Directory

La finestra Current Directory permette, come si può intuire, di esplorare
il contenuto delle cartelle sul proprio hard disk. Da questa finestra è
possibile aprire direttamente file compatibili con MATLAB con un semplice
doppio click. Inoltre è possibile esplorare cartelle utilizzando, in
Command Window, comandi tipici dei moderni sistemi operativi basati su
tecnologia UNIX (come linux e MAC)., come "cd nomecartella", "cd . .", "cd
/indirizzocartella", e così via.

Command History

Nella finestra Command History sono elencati tutti i comandi digitati di
recente, divisi per ora e data. È possibile rilanciare direttamente da
Command History, un comando digitato in Command Windows in precedenza,
semplicemente con un doppio click.

Programmare in MATLAB

Variabili

Variabili predefinite

In MATLAB ci sono delle variabili il cui valore è predefinito e non
modificabile. Esse sono:

- i, j: unità immaginaria in un numero complesso
- pi: approssimazione di pi greco, π
- eps: precisione di macchina del computer che si sta utilizzando
- realmax: è il massimo numero reale positivo rappresentabile
- realmin: è il minimo numero reale positivo rappresentabile
- inf: è un numero maggiore di realmax, ∞, infinito
- version: il numero della versione di MATLAB utilizzata
- computer: una sigla che indica il tipo di computer utilizzato. Esempio:
  PCWIN
- ans: ultimo risultato dell'ultima operazione eseguita
- NaN: "Not a number" , indica il risultato di una forma matematica
  indeterminata (es. ∞/∞ )

Dichiarazione variabili

Contrariamente ad altri linguaggi, che necessitano di una dichiarazione
esplicita del "tipo" di ogni variabile, per dichiarare una variabile in
MATLAB è sufficiente scrivere il nome della variabile seguito
dall'operatore "=" e dal valore numerico o alfabetico che si vuole
assegnare alla variabile. Nel caso in cui si tratti di testo è necessario
inserirlo tra gli apici:

var1=1
var2='abc'

Se in fase di esecuzione non si vuole visualizzare il valore della
variabile si deve terminare l'assegnamento con un punto e virgola:

var3=1234;
var4='abcdef';

Quando si assegna una variabile numerica, sia essa una costante, un
vettore, o una matrice, MATLAB la interpreta sempre e comunque come una
matrice; ad esempio una costante è una matrice 1x1, un vettore è una
matrice 1xl, cioè una riga di l elementi.

È importante notare che il Matlab è case sensitive, per esempio:

v=1
V=1

risultano due variabili distinte.

Per definire un numero complesso, esso va dichiarato scrivendolo in forma
algebrica:

c=4+9*i

Per resettare, cancellare, il contenuto di una variabile si utilizza il
comando

clear <nome_variabile>

per le variabili predefinite questo comando ripristina il valore di
default, altrimenti se sono altre variabili esse vengono eliminate dalla
workspace. Omettendo il nome dalla variabile,

clear

viene effettuata la pulizia di tutta la workspace.

N.B.: di default le variabili dichiarate sono tutte di tipo double
(floating point in doppia precisione).

Vettori

Definizione vettori

I vettori possono essere di due tipi:

- Vettori riga
- Vettori colonna

Il vettore riga è una matrice del tipo (1xn), dove n \in \mathbb{N} .
Esempio:

vr=[ 2 8 10 7]

Il vettore colonna invece è una matrice del tipo (mx1), dove m \in
\mathbb{N} . Esempio:

vc=[ 3; 1; 6; 8]

Spesso è utile definire i vettori con intervalli. Ad esempio un vettore che
contiene i primi dieci numeri interi. In generale:

v=[inizio:incremento:fine]|[inizio:fine]

Esempi:

v1=[1:10]
v2=[-1:0.2:1]

che generano:

v1=[1 2 3 4 5 6 7 8 9 10]
v2=[-1 -0.8 -0.6 -0.4 -0.2 0 0.2 0.4 0.6 0.8 1]

se non si scrive l'incremento, per default è 1.

Bisogna stare attenti a non assegnare all'incremento e alla destinazione
numeri relativi discordi, fatto che produrrà il seguente risultato in fase
di esecuzione:

vet=10:1:-10
  vet =
 Empty matrix: 1-by-0

Indicizzazione di vettori

Per selezionare un elemento del vettore, sia riga che colonna, si utilizza
la seguente istruzione:

v(posizione_indice)
v(k), dove k \in  \mathbb{N} , seleziona l'elemento in posizione k-esima

Importante: a differenza di quanto avviene in molti altri linguaggi, gli
indici dei vettori si contano a partire da 1. Esempio di indicizzazione:

v=[7 3 0 5 2 6]
k=1
v(k)=7

Matrici

Definizione matrici

Per creare una matrice si procede in modo simile alle variabili, per quanto
riguarda l'assegnamento, racchiudendo la matrice tra patentesi quadre,
separando gli elementi di una stessa riga con una virgola o con uno spazio
e le righe con un punto e virgola.

M1=[1 2 3 4;5 6 7 8;9 10 11 12]
M2=[13,14,15;16,17,18]
M3=['a',19,'b';20,'c',21]

In una matrice possiamo anche racchiudere variabili dichiarate in
precedenza

M4=[var1 var2;var3 var4]

ed è inoltre possibile definirle per parti, ad esempio in una matrice M 3 x
3, i comandi

M(1,1:3)=[a1 b1 c1];
M(2,1:3)=[a2 b2 c2];
M(3,1:3)=[a3 b3 c3];

consentono di assegnare alla prima riga i valori (precedentemente definiti)
a1, b1 e c1, alla seconda a2, b2 e c2 e così via.

Un altro modo per una dichiarazione veloce di matrici è la seguente:

Sintassi: M=[inizio:incremento:fine]|[inizio|fine]

anche in questo caso se si omette l'incremento, per default è 1. Esempio:

M=[1:2:7;4:2:10;7:2:13]
M=  1     3     5     7
    4     6     8    10
    7     9    11    13

Indicizzazione di matrici

Per selezionare un elemento di una matrice, utilizziamo la seguente
istruzione:

M(indice_riga, indice_colonna)
M(l,k) dove l,k \in  \mathbb{N} , selezionano l'elemento che si trova in riga l-esima e colonna k-esima

È possibile estrarre anche intere colonne o righe. Supponiamo di avere una
matrice M del tipo nxm, in generale:

M(l,:) , estrae l'intera riga l-esima in un vettore riga di dimensione m
M(:,k) , estrae l'intera colonna k-esima in un vettore colonna di dimensione n
M(:) , estrae l'intera matrice in un vettore colonna di dimensione nxm

Per eliminare la colonna di una matrice M:

M(:,k)=[] ,elimina la colonna k-esima, la matrice M diventa nx(m-1)

Operazioni con le matrici

Si elenca ora una serie di operazioni molto utili per lavorare con le
matrici in ambiente Matlab.

Sia A una generica matrice mxn, con il comando

size(A)

Si ottiene un vettore composto dal numero di righe e dal numero di colonne
della matrice A (ovviamente questo è estendibile anche a dimensioni
maggiori di 2)

Con l'operatore ' (apostrofo), si ottiene la matrice trasposta di A:

A'

questo comando è utile per trasformare un vettore riga in un vettore
colonna e viceversa.

Con il comando:

sum(A)

si ottiene un vettore riga composto dalla somma di ogni colonna di A.

Con il comando:

det(A)

si ottiene il determinante della matrice A.

Con il comando:

poly(A)

si ottiene un vettore contenente i coefficienti del polinomio
caratteristico di A.

Se A è una matrice quadrata, con il comando:

eig(A)

si ottiene un vettore colonna composto dagli autovalori di A.

Con il comando:

diag(A)

si ottiene un vettore colonna composto da tutti gli elementi della
diagonale principale di A. Se A fosse un vettore, si otterrebbe invece una
matrice diagonale con gli elementi di tale vettore.

Con il comando:

trace(A)

si ottiene la somma degli elementi della diagonale principale.

Con il comando:

fliplr(A)

si ottiene una nuova matrice, ma con l'ordine delle colonne invertito.

Con il comando:

inv(A)

si ottiene la matrice inversa di A.

Realizzazione di grafici 2D

Uno strumento molto potente che l'ambiente MATLAB offre per rappresentare
dati numerici è la rappresentazione tramite grafico di una funzione. In
particolare, dati due vettori x e y delle stesse dimensioni, è possibile
rappresentarne il grafico y=f(x) con il comando

 plot(x,y)

si fa notare che il comando plot non solo disegna y in funzione di x ma
crea automaticamente anche un'interpolazione lineare dei valori assunti
dalla funzione (dato che ovviamente nessuna funzione memorizzata in un
calcolatore è continua).

È possibile includere opzioni aggiuntive come il colore o il tipo di linea
seguendo la seguente sintassi:

 plot(x,y,'marcatore stile colore')

dove il marcatore sta ad indicare in che modo i punti della funzione
saranno rappresentati (ad esempio: +, *, o, x), lo stile è lo stile della
linea (è possibile scegliere tra linea continua, tratteggiata, tratto punto
ed altri ancora: -, - -, :, -.) e il colore del grafico, contrassegnabile
con l'iniziale in inglese del colore scelto. È da notare che se si assegna
un marcatore al comando plot, questo non effettuerà più l'interpolazione
lineare automatica tra i punti della funzione.

Allo stesso modo, con il comando plot, è possibile disegnare una matrice
quadrata:

plot(A)

Per disegnare grafici multipli nello stesso quadro è possibile seguire la
seguente sintassi:

plot(x1,y1,'msc',x2,y2,'msc',...)

dove y1=f(x1), y2=f(x2), e così via, rappresentano le funzioni da
rappresentare, oppure utilizzare il comando

hold on

che fa sì che se c'è un grafico attivo, questo non venga chiuso e il
successivo plot si sovrapponga ad esso.

Con il comando:

title('testo')

è possibile assegnare un titolo al grafico, mentre con i comandi

xlabel('testo')
ylabel('testo')

è possibile invece assegnare un nome ai valori dell'asse delle ascisse e
delle ordinate.

Il comando

grid

aggiunge una griglia al grafico corrente.

È possibile, in modo molto semplice disegnare diversi grafici nella stessa
finestra. Per fare ciò si usa il comando

subplot(m,n,p)

Con tale comando si disegnano in una finestra mxn grafici. Il comando
subplot va inserito subito prima del comando plot, e la variabile p
rappresenta il numero del grafico da disegnare, contando lungo le righe. Ad
esempio se si sta disegnando una finestra con 3 righe e 4 colonne di
grafici, e si vuole disegnare ora il secondo grafico della seconda riga, si
scrive:

subplot(3,4,6)

Con il comando

axis([xi xf yi yf])

è possibile impostare a priori la porzione di grafico da visualizzare,
indicando con xi l'ascissa iniziale, xf l'ascissa finale, yi l'ordinata
iniziale e ovviamente yf l'ordinata finale. Si fa notare che vanno inseriti
fra parentesi quadre perché la funzione axis ha bisogno di un vettore in
ingresso, quindi è ovviamente possibile dichiarare all'esterno tale vettore
e fornirglielo come argomento:

axis(V)

Analisi e simulazione di sistemi dinamici con MATLAB

MATLAB è un potentissimo strumento per l'analisi numerica di sistemi anche
con molti ingressi e uscite. MATLAB permette di dichiarare facilmente degli
oggetti sistema, grazie ad alcuni comandi già pronti all'uso. Dato un
sistema dinamico è possibile quindi dichiararlo come

Sistema in forma esplicita (comando ss, cioè state-space)

sys=ss(A,B,C,D,t0)

dove A,B,C,D, sono ovviamente le matrici dei coefficienti, mentre t0 è il
periodo di campionamento di un sistema a tempo discreto, se omesso si
dichiara un sistema a tempo continuo

Sistema in forma zeri-poli-guadagno (comando zpk, zero-pole-gain)

sys=zpk([z1 z2 ··· zm],[p1 p2 ··· pn],K)

È da notare che K non è il guadagno statico del sistema, ma è semplicemente
la costante fuori dalla funzione di trasferimento quando è nella forma
K*Π(s-z_i)/Π(s-p_i).

Funzione di trasferimento (comando tf, transfer function)

sys=tf(NUM,DEN)

dove num e den sono vettori riga contenenti i coefficienti dei polinomi al
numeratore e al denominatore della funzione di trasferimento desiderata,
presi dal grado maggiore a quello minore. per esempio il polinomio:
s^3-4s^2+0.23s-1.9, equivale al vettore riga:

[1 -4 +.23 -1.9]

Con il comando

lsim(sys,u,t,x0)

si ottiene l'andamento del sistema sys forzato dall'ingresso u, durante il
tempo t, con stato iniziale x0. u deve essere in pratica, un segnale
campionato in tutti gli istanti contenuti nel vettore t. È evidente quindi
che u e t devono avere la stessa dimensione, cioè lo stesso numero di
elementi.

Un semplice esempio di simulazione

si vuole calcolare la risposta ad un gradino unitario del seguente sistema:

\begin{cases}  \dot x = \left ( \begin{matrix}  -1 & π
-π& -1 \end{matrix}  \right ) x + \left ( \begin{matrix}  0 
1 \end{matrix}  \right ) u 
y = \left ( \begin{matrix}  π& 1 \end{matrix}  \right ) x \end{cases} 

con condizioni iniziali nulle.

In realtà esiste un comando specifico per calcolare la risposta al gradino,
come mostreremo in seguito, ma ci serviamo di questo semplice caso per
mostrare l'utilizzo di lsim. Cominciamo subito definendo il sistema con il
comando ss:

sys=ss([-1 pi;-pi -1],[0;1],[pi 1],0)

ci verrà restituito il seguente testo:

a = 
          x1      x2
  x1      -1   3.142
  x2  -3.142      -1
b = 
      u1
  x1   0
  x2   1
c = 
         x1     x2
  y1  3.142      1
d = 
      u1
  y1   0
Continuous-time model.

e nella workspace vedremo apparire il nostro oggetto sys. Supponiamo di
voler calcolare l'andamento del sistema da quando parte, con condizioni
iniziali nulle, fino a che non si esaurisce completamente il transitorio.
Per questo semplice sistema si ricava facilmente che ciò avviene a circa
5-6 secondi. Quindi possiamo passare a definire il tempo di esecuzione:

t=0:.01:7;

a questo punto possiamo definire il nostro segnale d'ingresso (il gradino),
in questo modo:

u=1
for i=.01:.01:7 u=[u 1]; end

in parole semplici, si è impostato un ciclo for di durata pari alla
dimensione di t, aggiungendo ad ogni ciclo un 1 in coda ad u, ottenendo
così un vettore u composto da tutti 1 delle stesse dimensioni di t. Abbiamo
ora tutti gli elementi per far partire la simulazione:

lsim(sys,u,t,[0 0]')

lo stesso risultato si poteva ottenere con il comando step:

step(sys)

il tempo in questo caso è calcolato automaticamente, ma può anche essere
specificato:

step(sys,tfinal);

Esempio di linguaggio MATLAB

Questo codice, preso dalla function magic.m, crea un quadrato magico M per
valori dispari di n.

[J,I] = meshgrid(1:n);
A = mod(I+J-(n+3)/2,n);
B = mod(I+2*J-2,n);
M = n*A + B + 1;

ad esempio, per n=3 si ottiene:

M =

    8     1     6
    3     5     7
    4     9     2

Note

[1] (EN) Mike Croucher, What langauge is MATLAB written in?,
  walkingrandomly.com, 9 giugno 2012. URL consultato il 1º dicembre 2012.

Voci correlate

- Analisi numerica
- FreeMat
- GNU Octave
- Scilab
- Sysquake
- JMathLib
- Simulink

Altri progetti

- Wikimedia Commons contiene immagini o altri file su MATLAB

Collegamenti esterni

- Sito ufficiale, mathworks.com.

GNU Octave

GNU Octave è un'applicazione software per l'analisi numerica in gran parte¹
compatibile con MATLAB.

Ha un insieme di funzionalità fornite per il calcolo matriciale come rango
e determinante o specialistiche come decomposizione ai valori singolari
(SVD), fattorizzazione LU; sebbene consenta di trovare la soluzione
numerica di sistemi lineari non svolge calcolo simbolico o altre attività
tipiche di un sistema di algebra computazionale.

Storia

Il progetto fu concepito nel 1988 da John W. Eaton (primo manutentore) e da
James B. Rawlings presso l'Università del Texas come strumento di calcolo
per l'ingegneria chimica.

Il suo sviluppo vero e proprio partì da John W. Eaton nel 1992. La prima
alpha pubblicata è datata 4 gennaio 1993 e il 17 febbraio 1994 fu
distribuita la versione 1.0. La versione 3.0 è stata distribuita il 21
dicembre 2007.

Dettagli tecnici

- Octave è scritto in conformità dello standard POSIX nel linguaggio C++
  usando le librerie Standard Template Library.
- Octave utilizza un interprete per il suo linguaggio di scripting.
- Octave è estendibile attraverso moduli o funzioni scritte dall'utente.
- Octave può lavorare assieme a gnuplot e Grace per disegnare funzioni,
  grafici, tabelle, consentendo di salvarli o stamparli.

Octave, il linguaggio

Il linguaggio di scripting di Octave supporta svariate librerie del C, e
supporta inoltre diverse system calls e funzioni UNIX.

I programmi scritti con Octave sono degli script o liste di chiamate a
funzioni. Il linguaggio dispone di diversi tipi di dati, oltre quello
numerico esistono anche un tipo logico (true, false), uno di tipo stringa e
strutture dati analoghe alle struct del linguaggio C. Esiste anche un altro
tipo di dato molto potente ed è la matrice che consente molte operazioni di
tipo matriciale. Il linguaggio di Octave non è un linguaggio orientato agli
oggetti ma supporta le strutture dati, inoltre mette a disposizione varie
strutture per il controllo del flusso, come i test logici if-else e switch
ed i cicli while e do-until.

La sintassi è molto simile a quella di MATLAB, ed è possibile scrivere
script che girano sia sotto Octave che su MATLAB.

Octave è distribuito sotto licenza GPL, e quindi può essere liberamente
copiato e usato. Il programma gira sotto sistemi Unix e Linux, oltre che su
Windows e macOS.

Funzionalità distintive

Completamento automatico dei comandi e dei nomi delle variabili

Digitare un carattere TAB nella riga di comando attiva in GNU Octave la
ricerca di possibili completamenti della parte di comando già parzialmente
digitata (in modo analogo al completamento automatico della shell Bash).

Command history

Quando avviato in modalità interattiva, GNU Octave salva i comandi già
eseguiti in un buffer interno così che essi possono essere richiamati ed
editati.

Strutture dati

GNU Octave include un limitato supporto per organizzare i dati in
strutture. Ad esempio:

octave:1> x.a = 1; x.b = [1, 2; 3, 4]; x.c = "stringa";
octave:2> x.a
ans =  1
octave:3> x.b
ans =

   1   2
   3   4

octave:4> x.c
ans = stringa
octave:5> x
x =
{
  a =  1
  b =

     1   2
     3   4

  c = stringa
}


Operatori booleani a corto circuito (short-circuit)

Gli operatori logici '&&' e '||' di GNU Octave sono valutati in modalità a
corto circuito (come i corrispondenti operatori in linguaggio C), a
differenza degli operatori '&' e '|', che agiscono elemento per elemento in
vettori, matrici e array multi-dimensionali.

Operatori incremento e decremento

GNU Octave include gli operatori C-like di incremento '++' e decremento
'--', sia nella loro forma prefissa che in quella suffissale.

Unwind-protect

GNU Octave supporta una forma basilare di gestione delle eccezioni,
modellata sul costrutto unwind-protect del Lisp. La forma generale di un
blocco unwind_protect ha questo aspetto:

unwind_protect
  body
unwind_protect_cleanup
  cleanup
end_unwind_protect


Come regola generale, GNU Octave riconosce come terminazione di un dato
blocco di codice 'block' sia la parola chiave 'end' (che è compatibile con
il linguaggio MATLAB) che l'altra più specifica 'end_block'. Di
conseguenza, un blocco 'unwind_protect' può essere terminato sia con la
parola chiave 'end_unwind_protect' - come nell'esempio - sia in modo più
portabile, con la parola chiave 'end'. Nell'esempio, la parte cleanup del
blocco è sempre eseguita. In caso la parte body sollevasse un'eccezione,
cleanup sarebbe eseguita immediatamente prima della propagazione
dell'eccezione al di fuori del blocco 'unwind_protect'.

GNU Octave supporta anche un'altra forma di gestione delle eccezioni
(compatibile con il linguaggio MATLAB):

try
   body
catch
   exception_handling
end


Quest'ultima forma differisce da un blocco 'unwind_protect' per due motivi.
Primo, la parte exception_handling viene eseguita soltanto nel caso in cui
la parte body sollevi un'eccezione. In secondo luogo, dopo l'esecuzione di
exception_handling, l'eccezione è considerata intercettata e gestita, e non
viene propagata all'esterno del blocco (a meno che un comando 'rethrow(
lasterror )' sia di proposito stato inserito all'interno del codice
exception_handling).

Liste di argomenti di lunghezza variabile

GNU Octave ha un meccanismo efficace per gestire funzioni che devono
ricevere un numero arbitrario (non noto a priori) di argomenti, senza un
limite superiore. Per indicare una lista di zero o più argomenti entranti
in una funzione, si usa lo speciale argomento varargin, posizionato come
ultimo (o solo) argomento nella lista:

function s = plus (varargin)
   if (nargin==0)
      s = 0;
   else
      s = varargin{1} + plus (varargin{2:nargin});
   end
end


Liste di ritorno di lunghezza variabile

Una funzione può essere implementata in modo che ritorni al codice chamante
un qualsiasi numero di valori, usando come argomento di uscita la variabile
speciale varargout. Ad esempio:

function varargout = multiassign (data)
   for k=1:nargout
      varargout{k} = data(:,k);
   end
end


Integrazione con il linguaggio C++

È anche possibile eseguire codice GNU Octave direttamente all'interno di un
programma C++. Per esempio, di seguito è riportato un frammento di codice
che chiama la funzione rand([10,1]) da C++, facendola interpretare da GNU
Octave:

   #include <octave/oct.h>
   ...
   ColumnVector NumRands(2);
   NumRands(0) = 10;
   NumRands(1) = 1;
   octave_value_list f_arg, f_ret;
   f_arg(0) = octave_value(NumRands);
   f_ret = feval("rand",f_arg,1);
   Matrix unis(f_ret(0).matrix_value());


Compatibilità con il linguaggio MATLAB

GNU Octave è stato progettato avendo tra gli obiettivi la compatibilità con
il linguaggio MATLAB, e infatti esso condivide con MATLAB molte
funzionalità:

- Le matrici come tipi di dato fondamentali.
- Il supporto nativo per i numeri complessi.
- Potenti funzioni matematiche native e ampie librerie di funzioni.
- Estensibilità, che assume la forma di funzioni definite dall'utente.

Rispetto al linguaggio MATLAB, esiste di proposito un insieme ristretto di
differenze :

- Le righe di commento possono essere prefisse sia con il carattere # che
  con il carattere % (quest'ultimo compatibile col linguaggio MATLAB).
- Sono supportati vari operatori basati sul linguaggio C: ++, --, +=, *=,
  /=.
- È possibile accedere agli elementi di variabili temporanee (vettori,
  matrici o array multi-dimensionali) senza dover creare nuove variabili,
  come ad esempio in [1:10](3).
- Le stringhe di testo possono essere definite sia con il carattere " che
  con il carattere ' (quest'ultimo compatibile col linguaggio MATLAB).

Note

[1] About Octave, gnu.org.

Voci correlate

- Analisi numerica
- FreeMat
- MATLAB
- Scilab
- JMathLib

Altri progetti

- Wikimedia Commons contiene immagini o altri file su GNU Octave

Collegamenti esterni

- (EN) Sito ufficiale, gnu.org.
-
- (EN) GNU Octave, su SourceForge.
- GNU Octave, su packages.debian.org.

Documentazione

- (EN) Octave-forge pagina della comunità di sviluppatori,
  octave.sourceforge.net.
- Introduzione a GNU Octave - Guida rapida in italiano con elementi di
  grafica, calcolo numerico, statistica, programmazione, matrici, funzioni
  (Download) (PDF), matematicamente.it.
- Un'introduzione a Octave (PDF), matematicamente.it.
- Un'introduzione (PDF), dm.unibo.it.
- (EN) Documentazione online, gnu.org.
- (EN) wiki di GNU Octave, wiki.octave.org.
- (EN) FAQ con i nuovi comandi di plotting, aims.ac.za.
- (EN) Archivi delle Mailing List su Nabble – Ricerca in tutte le mailing
  list di GNU Octave.
- (EN) Archivi delle Mailing List su Gmane – Ricerca in tutte le mailing
  list di GNU Octave.

Librerie e pacchetti numerici che si interfacciano con GNU Octave

GNU Octave è potenziato anche da numerosi strumenti e librerie di terze
parti, perlopiù in grado di fornire al calcolo scientifico astrazioni
generali o specifiche per particolari domini applicativi. Questi strumenti
possono essere classificati a seconda che il loro contributo sia più
orientato alla modellistica computazionale o al potenziamento dell'analisi
visiva dei dati.

Strumenti numerici

- Octave-forge pagina della comunità di sviluppatori – Collezione di tool
  software resi disponibili come software libero per numerose tipologie di
  problemi, da sviluppatori indipendenti. Octave-forge fornisce anche un
  installer per Windows capace di installare sia GNU Octave che i tool
  software aggiuntivi.
- Mastrave project – Libreria multi-linguaggio di software libero (coperta
  da licenza GNU GPLv3+) compatibile con GNU Octave and Matlab, per
  semplificare la modellistica ambientale con funzioni generali basate sul
  paradigma del semantic array programming.
- Neuroimaging Analysis Kit – Libreria (comperta da licenza MIT) per il
  processamento di dati di neuroimaging usando GNU Octave or Matlab, in
  particolare immagini di risonanza magnetica funzionale. La libreria
  include un sistema pipeline per gestire proccessamenti multi-stage.
- Parallel Matlab Toolbox fornisce un insieme di strutture dati e funzioni
  in linguaggio MATLAB che implementano array MATLAB distribuiti. È
  pubblicato con licenza MIT.
- MPI Toolbox per Octave (MPITB) – Calcolo parallelo per GNU Octave,
  tramite MPI.

Strumenti grafici

- PLplot – Un'alternativa all'uso del tradizionale gnuplot in GNU Octave,
  distribuito sotto la licenza GNU LGPL.
- OctPlot – Grafica 2D di alta qualità (su schermo e in postscript).
  Pubblicata sotto GNU GPL.
- Add-on grafico per GNU Octave – Sistema di visualizzazione 3D per GNU
  Octave.* Octaviz – Sistema di visualizzazione 3D per GNU Octave (wrapper
  che rende accessibili le classi VTK dall'interno di GNU Octave). Fornisce
  anche funzioni di alto livello per la visualizzazione 2D. (Nota: il sito
  di Octaviz riporta che "sfortunamente, Octaviz non è più attivamente
  sviluppato. L'ultima release (0.4.7) era usabile e stabile quando
  compilata con vtk-5.0.")

Interfacce utente

Dalla versione 3.8, GNU Octave integra una interfaccia grafica (GUI),
attivabile tramite l'opzione—force-gui. Verrà abilitata di default a
partire dalla versione 4.0.

Interfacce grafiche alternative

- GUIOctave - GUIOctave implementa una interfaccia grafica per semplificare
  l'uso di GNU Octave per gli utenti che non sono a loro agio con la
  versione originale di GNU Octave, basata sulla riga di comando.
- Kalculus - Interfaccia utente - simile all'ambiente di calcolo MATLAB -
  funzionante per GNU Octave e Yacas. Scritta in Qt4 con binding a Ruby.
- Xoctave – Xoctave incapsula GNU Octave usando pipeline e fornisce
  strumenti addizionali per semplificarne l'uso. L'interfaccia utente è
  molto simile a quella dell'ambiente di calcolo MATLAB.
- OctaveNB – Integrazione per GNU Octave in NetBeans IDE. Funzionalità
  principali: SVN, history locale, diff, progetti multi-lingiaggio.

Interfacce Web

- Editor online LaTeX e GNU Octave - Editor online GNU Octave/Matlab con
  funzionalità di plotting e storage.
- Online access to Octave – Consente di eseguire semplici computazioni
  online, sfruttando l'interprete di GNU Octave.
- MathCloud – Consente di condividere script GNU Octave/Matlab e di
  eseguire computazioni cloud-based.

Scilab

Scilab è un pacchetto di programmi gratuiti per la computazione numerica
sviluppati dallo INRIA e dallo ENPC in Francia, poi da Scilab Consortium in
seno alla Fondazione Digiteo. Oggi Scilab è sviluppato da Scilab
Enterprises.

Introduzione

Licenza

Scilab attualmente utilizza la licenza CeCILL v2, che è compatibile con la
licenza GNU GPL v2 della Free Software Foundation¹ . Versione precedenti di
Scilab erano rilasciate sotto la licenza CeCILL v1, che, nella sua variante
base, non era compatibile con le specifiche del Software Libero. Tuttavia
la versione 1 della licenza CeCILL prevedeva già la possibilità di essere
sostituita con versioni successive della stessa licenza, quindi la versione
2 della licenza può essere retroattivamente applicata a tutto il software
rilasciato con licenza CeCILL v1.

Sintassi informatica simile a quella usata in MATLAB

Scilab è stato ampiamente impiegato in alcuni progetti industriali e di
ricerca, e molti contributi (sotto forma di codice informatico) sono stati
fatti dagli utenti. La sintassi è simile a quella di MATLAB ma i due
programmi, i loro applicativi ed i plug-in non sono completamente
compatibili, anche se esiste un convertitore nel pacchetto di Scilab, che
opera le conversioni MATLAB → Scilab. Scilab ha un minor numero di file
d'aiuto (help files) rispetto a MATLAB.

Adatto per elaborazione dei segnali, fluidodinamica, statistica

È un linguaggio di programmazione di alto livello, liberamente basato sul
linguaggio di programmazione C, ed è simile nelle sue funzionalità a
MATLAB, inoltre è disponibile per il download gratuito. Il programma
consente di elaborare un'ampia gamma di operazioni matematiche da
operazioni relativamente semplici come le moltiplicazioni a quelle di
livello più alto, come correlazioni ed aritmetica dei numeri complessi. Il
software è particolarmente adatto per l'elaborazione dei segnali, analisi
statistica, elaborazione delle immagini, simulazioni di fluidodinamica,
ecc.

Include l'editore di diagrammi a blocchi Xcos

Scilab include anche un pacchetto chiamato Xcos, per la simulazione e la
costruzione di modelli di sistemi dinamici espliciti ed impliciti,
includendo sia sotto-sistemi continui che discreti.

Note

[1] http://www.scilab.org/changes_5/

Bibliografia

- Engineering and Scientific Computing with Scilab; libro del 1999 scritto
  da C. Gomez, C. Bunks, J.P. Chancelier, F. Delebecque, M. Goursat, R.
  Nikoukhah, S. Steer. Casa Editrice: Birkhäuser. ISBN 0-8176-4009-6

Voci correlate

- Analisi numerica
- FreeMat
- MATLAB
- GNU Octave

Altri progetti

- Wikimedia Commons contiene immagini o altri file su Scilab

Collegamenti esterni

- (EN, FR) Scilab site, scilab.org.
- (EN, FR) Scilab Enterprises site, scilab-enterprises.com.
- (EN, FR) Introduction to Scilab, scilab.org.
- (EN) Image processing toolkit for Scilab, siptoolbox.sourceforge.net.
- (EN, IT) Tutorial dallo Scilab Professional Partner italiano,
  openeering.com.
- Manuale Introduttivo di Scilab, in pdf da www.dia.uniroma3.it
- Pagina su Scilab da www.tecnoteca.it
- Alcune informazioni su Scilab, freeweb.supereva.com.
- Portale su Scilab, roboticboyer.wordpress.com.

Punto di equilibrio

Un punto di equilibrio di un sistema dinamico è un punto in corrispondenza
del quale l'evoluzione del sistema è stazionaria.

Dato un sistema autonomo \dot x(t) = f (x(t)), il vettore x₀ è un punto di
equilibrio se f(x_0)= 0. In tal caso la funzione x(t) = x₀ è una soluzione
(stazionaria) per ogni t. Le soluzioni stazionarie sono tutti e soli i
punti di equilibrio dell'equazione, la cui ricerca coincide quindi con il
trovare gli zeri del campo vettoriale f.

Definizione

Se il sistema dinamico è determinato da una equazione differenziale (o un
sistema di equazioni):

\frac{d}{dt} x(t)=F( x(t),t)

un punto di equilibrio è un punto x₀ tale che F(x₀,t)=0 per ogni t. Questa
condizione implica infatti che:

\frac{d}{dt} x(t)=0

da cui, integrando, si ottiene x(t)=cost indipendentemente dal tempo t,
ovvero il sistema tende a rimanere immutato alle condizioni descritte dal
punto x₀. Di particolare interesse è lo studio delle derivate (o la
jacobiana) di f in corrispondenza dei punti di equilibrio, poiché fornisce
diverse informazioni sul comportamento locale della soluzione.

Se il sistema dinamico è determinato da un'equazione di ricorrenza:

x_{n+1}=T(xₙ,n)

allora un punto di equilibrio è un punto x₀ che sia un punto fisso delle
mappe T(x_i,i), ovvero tale che T(x₀,n)=0 per ogni n.

Stabilità

I punti di equilibrio possono essere classificati linearizzando
l'equazione, e osservando il segno degli autovalori della matrice jacobiana
(relativa al sistema linearizzato) valutata nel punto di equilibrio.

Un punto di equilibrio è iperbolico se nessuno degli autovalori ha parte
reale nulla. Se tutti gli autovalori hanno parte reale negativa il punto di
equilibrio è stabile, mentre se almeno un autovalore ha parte reale
positiva l'equilibrio è instabile. Infine, se ci sono almeno un autovalore
che ha parte reale positiva e uno che ha parte reale negativa, il punto è
un punto di sella.

Voci correlate

- Criterio di Dirichlet-Lagrange
- Punto critico (matematica)
- Punto di equilibrio iperbolico
- Punto di sella
- Punto fisso
- Stabilità interna
- Varietà stabile

Collegamenti esterni

- Antonio Giorgilli - Equilibri e stabilità (PDF), mat.unimi.it.
- (EN) Jason Frank - Equilibrium Points and Fixed Points (PDF),
  staff.science.uu.nl.
- (EN) Norman Lebovitz - Equilibrium Points (PDF), people.cs.uchicago.edu.

Convertitore analogico-digitale

Analog to Digital Converter (ADC), in italiano convertitore
analogico-digitale, è un circuito elettronico in grado di convertire un
segnale analogico con andamento continuo (ad es. una tensione) in una serie
di valori discreti (vedi teoria sulla conversione analogico-digitale). Il
convertitore digitale-analogico o DAC compie l'operazione inversa.

Risoluzione

La risoluzione di un ADC indica il numero di valori discreti che può
produrre. È usualmente espressa in Bit. Per esempio, un ADC che codifica un
ingresso analogico in 256 livelli discreti ha una risoluzione di 8 bit,
essendo 2⁸ = 256. La risoluzione può anche essere definita elettricamente,
ed espressa in volt. La risoluzione in volt di un ADC è uguale alla minima
differenza di potenziale tra due segnali che vengono codificati con due
livelli distinti adiacenti. Alcuni esempi possono aiutare:

- Esempio 1:
  + Range compreso tra 0 e 10 volt
  + Risoluzione dell'ADC di 12 bit: 2¹² = 4096 livelli di quantizzazione
  + La differenza di potenziale tra due livelli adiacenti è 10 V / 4096 =
    0,00244 V = 2,44 mV
- Esempio 2:
  + Range compreso tra -10 e 10 volt
  + Risoluzione dell'ADC di 14 bit: 2¹⁴ = 16384 livelli di quantizzazione
  + La differenza di potenziale tra due livelli adiacenti è 20 V / 16384 =
    0,00122 V = 1,22 mV

Nella pratica, la risoluzione di un convertitore è limitata dal rapporto
segnale/rumore (S/N ratio) del segnale in questione. Se è presente troppo
rumore all'ingresso analogico, sarà impossibile convertire con accuratezza
oltre un certo numero di bit di risoluzione. Anche se l'ADC produrrà un
valore, questo non sarà accurato essendo i bit meno significativi funzione
del rumore e non del segnale. Il rapporto S/N dovrebbe essere di circa 6 dB
per bit.

Tipi di risposta

La maggior parte degli ADC sono lineari, il che significa che sono
progettati per produrre in uscita un valore che è funzione lineare del
segnale di ingresso. Un altro tipo comune di ADC è quello logaritmico, che
è usato in sistemi di comunicazioni vocali per aumentare l'entropia del
segnale digitalizzato.

L'istogramma di un segnale vocale ha la forma di due curve esponenziali
inverse, l'ADC non lineare cerca, quindi, di approssimare questo con una
funzione di densità di probabilità quadrata come a-law o μ-law, funzioni
logaritmiche. Il segnale distorto ha un range dinamico inferiore, e la sua
quantizzazione aggiunge meno rumore al segnale originale rispetto a quanto
farebbe un quantizzatore lineare con la stessa risoluzione in bit.

L'accuratezza dipende dall'errore della conversione. Questo errore è
formato da due componenti: un errore di quantizzazione e un errore di
non-linearità (o infedeltà alla curva desiderata nel caso di ADC
volutamente non-lineari). Questi errori sono misurati con un'unità chiamata
LSB (least significant bit = bit meno significativo) ed indica fino a che
punto i bit rappresentano segnale e quanti siano solo rumore. In un ADC a 8
bit, un errore di 1 LSB è pari ad un errore di 1/256 ossia circa del 0,4%;
è un modo per dire che l'ultimo bit è casuale. In un ADC a 16 bit con un
errore di 4 LSB significa che l'errore risulterà pari a 4/(2¹⁶) ossia
0,006%.

L'errore di quantizzazione è dovuto alla risoluzione finita dell'ADC ed è
una imperfezione intrinseca di tutti i tipi di ADC. La grandezza
dell'errore di quantizzazione su un campione è compresa tra zero e un LSB.

Tutti gli ADC soffrono di errori di non-linearità causati da imperfezioni
fisiche, facendo deviare la loro uscita da una funzione lineare (o da
un'altra funzione, in caso di ADC volutamente non-lineari). Questi errori
possono a volte essere attenuati con una calibrazione.

Parametri importanti per la linearità sono non-linearità integrale (INL) e
non linearità differenziale (DNL).

Sampling rate

Il segnale analogico è tempo-continuo ed è necessario convertirlo in un
flusso di valori discreti. È quindi necessario definire una frequenza alla
quale campionare i valori discreti del segnale analogico. Questa frequenza
è chiamata sampling rate (frequenza di campionamento) del convertitore.

L'idea chiave è che un segnale di banda limitata che varia con continuità
può essere campionato e poi riprodotto esattamente dai valori tempo
discreti con un algoritmo di interpolazione se la frequenza di
campionamento è almeno pari al doppio della frequenza massima del segnale
(Teorema di Nyquist-Shannon). L'accuratezza tuttavia è limitata dall'errore
di quantizzazione.

Poiché nella pratica un ADC non può effettuare una conversione istantanea,
il valore d'ingresso deve necessariamente rimanere costante durante il
tempo in cui il convertitore esegue la conversione (chiamato tempo di
conversione o conversion time). Un circuito d'ingresso chiamato sample/hold
svolge questo compito - spesso si usa un condensatore per immagazzinare la
tensione del segnale in input e un interruttore elettronico per
disconnettere il condensatore dall'ingresso. Molti ADC realizzati su
circuiti integrati realizzano il sottosistema di sample/hold internamente.

Aliasing

Tutti gli ADC lavorano campionando il proprio input ad intervalli discreti
di tempo. L'output di conseguenza è un'immagine incompleta dell'input e non
c'è modo di sapere, guardando soltanto l'output, che valori abbia assunto
l'input tra due istanti di campionamento adiacenti. Se è noto che
l'ingresso varia lentamente confrontato con la frequenza di campionamento,
allora si può presumere che esso sia sempre contenuto tra i due estremi in
quell'intervallo.

Il risultato diretto che si osserva riproducendo un segnale campionato ad
una frequenza inferiore della sua banda è che le componenti del segnale a
frequenze superiori verranno riprodotti a frequenza diverse, inferiori alla
frequenza di campionamento. Ad esempio, campionando a 1.5 kHz un'onda
sinusoidale a 2 kHz verrà trasformata in una onda a 500 Hz (ed in
opposizione di fase). Il problema dell'aliasing può essere osservato anche
visivamente, basta far caso che in televisione o al cinema (dove l'immagine
è campionata a 25 Hz), oggetti in rotazione a frequenza superiori, come
pale di elicottero o ruote di automobili, spesso ci appaiano girare
lentamente, o addirittura al contrario, rispetto a quanto ci si
aspetterebbe.

Per eliminare l'aliasing, l'ingresso di un ADC deve essere filtrato
(low-pass) per rimuovere le frequenze superiori a quelle di campionamento.
Questo filtro è chiamato anti-aliasing ed è essenziale in un sistema ADC.

Dither

Il dithering consiste nell'introdurre artificialmente del rumore nel
segnale di ingresso al fine di migliorare la qualità di conversione
superando la limitazione di una risoluzione finita. Anche se può sembrare
assurdo che del rumore possa migliorare la qualità si può mostrare come
questo sia vero con un semplice esempio numerico.

Supponiamo che il segnale di ingresso sia sempre pari e costante al valore
di 0,34 Volt e che il nostro convertitore abbia una risoluzione di 0,1
volt. In assenza di rumore il segnale sarà campionato e approssimato come
una sequenza di valori pari a 0,3 V, il livello più vicino del
quantizzatore. Se invece sommiamo del rumore bianco, cioè un segnale con
valore medio nullo, con una varianza pari a 0,1 V (pari alla risoluzione
del convertitore, 1LSB) avremo che il segnale oscillerà ora tra 0,24 V e
0,44 V con il risultato che i campioni avranno i valori di 0,2, 0,3 o 0,4
Volt. Per le proprietà statistiche del rumore, il valor medio dei campioni,
invece di 0,3 volt, sarà di 0,34 V: in pratica il rumore ha annullato
l'errore medio.

Osservando la figura, è chiaro come l'errore in assenza di dither si sommi
nel tempo essendo le due linee spesse parallele mentre la linea sottile,
oscillando attorno al valore esatto, lo approssima in valor medio sempre di
più al passare del tempo.

Strutture ADC

In elettronica ci sono cinque modi comuni di implementare un ADC:

- Un ADC a conversione diretta (Flash ADC) ha un comparatore per ognuno dei
  livelli di voltaggio riconosciuti dal quantizzatore. Un ADC flash ad
  8-bit avrà 2^8-1 (=256-1) comparatori. Il segnale di ingresso arriva a
  tutti i comparatori. Porteranno in uscita un valore di saturazione
  positivo tutti quelli in cui la tensione del segnale di ingresso è
  maggiore di quella di soglia per quel determinato bit. Attraverso un
  priority encoder solo il maggiore di essi attiverà la propria uscita,
  quello del livello corrispondente. I convertitori flash sono i più veloci
  in assoluto e sono usati per campionare segnali in alta frequenza, fino a
  diversi GHz. Poiché il numero di comparatori necessari cresce
  esponenzialmente con il numero dei bit richiesti, i convertitori flash
  raramente hanno più di 8 bit di risoluzione.
- Un ADC ad approssimazioni successive (SAR - Successive Approximation
  Register) usa un comparatore e un convertitore digitale-analogico, ad
  ogni passaggio l'ADC prova a impostare un bit, partendo dal MSB(Most
  Significant Bit, bit con peso maggiore) e usando il DAC confronta il
  segnale campionato con il segnale di ingresso in feedback. Questo
  convertitore individua un bit ad ogni iterazione in una sorta di ricerca
  binaria e la risoluzione è limitata solo dalle esigenze di sample-rate e
  dal rumore in ingresso.
- Un ADC ad inseguimento (a codifica-delta) ha un contatore up-down
  collegato ad un DAC. Un comparatore confronta il segnale di uscita del
  DAC con il segnale di ingresso e interrompe il conteggio quando i valori
  sono abbastanza vicini tra loro. Quando questo succede il contatore
  contiene il livello quantizzato del segnale. Questi convertitori sono
  usati spesso per leggere grandezze fisiche che non variano con elevata
  velocità ma che devono essere lette con molta precisione.
- Un ADC a doppia rampa (Dual Slope) (o ad integrazione) produce un segnale
  a dente di sega che sale, per poi cadere velocemente a zero. Il segnale
  di ingresso viene integrato facendo salire la rampa mentre un contatore
  segna il tempo. Quando la rampa raggiunge un livello noto il conteggio
  termina e indica il valore quantizzato del segnale. Questo tipo di ADC è
  sensibile alla temperatura poiché può alterare il clock usato per segnare
  il tempo o alterare il voltaggio di riferimento per la rampa e deve
  essere ricalibrato spesso.
- Un ADC a pipeline (noto anche come subranging quantizer) è simile al ADC
  ad approssimazioni successive ma invece di individuare un bit alla volta
  individua un blocco di bit; in un primo passo avviene una conversione
  grezza del segnale che viene poi riconvertito da un DAC; quindi si
  quantizza la differenza tra il segnale originario e quello campionato,
  eventualmente si può procedere a quantizzazioni sempre più fini con passi
  successivi. Se ad esempio supponiamo di avere un quantizzatore a 4-bit
  che operi con un range di [0÷2,56 V] (quindi con una risoluzione di 0,16
  V) e un altro quantizzatore a 4-bit che operi però tra [0 V ÷ 0,16 V] con
  una risoluzione di 0,01 V. Dopo aver quantizzato il segnale di ingresso
  con il primo quantizzatore la differenza tra il segnale quantizzato e
  quello di ingresso sarà al massimo quello della risoluzione, e può essere
  letto dal secondo quantizzatore. Se il segnale di ingresso era pari a
  2.50 V, il primo campionatore identificherà il livello 15 (1111 in
  binario), che corrisponde ad un valore di 2,40 V, la differenza di 0,1 V
  viene quantizzata dal secondo con il livello 10 (1010 in binario); unendo
  i codici si ottiene 1111 1010 ossia un valore a 8 bit.

Difetti del convertitore analogico-digitale

I convertitori AD presentano alcuni errori, il primo fra tutti è legato al
processo di campionamento e di quantizzazione. Esso infatti prevede la
discretizzazione ad un valore ben noto, di tutto i campioni che ricadono in
un intervallo di tensione detto quanto. Supponendo una dinamica di ingresso
di valore S su un convertitore ad n bit, il quanto ha valore:

Δs = \frac{s}{2ⁿ}

Per ridurre gli errori, la discretizzazione viene effettuata considerando
ogni campione come valore centrale avendo così un errore massimo del valore
del quanto. Si definisce quindi l'errore di quantizzazione pari alla metà
del quanto:

Δs = \frac{1}{2} ·\frac{s}{2ⁿ} =\frac{s}{2^{n+1}}

Altri errori classici nei convertitori AD sono:

- Errore di non linearità assoluta
- Errore di guadagno
- Errore differenziale
- Errore di offset

Sul datasheet di un convertitore viene generalmente indicato il cumulo di
tutti gli errori in un "Errore totale" rappresentato in frazione di LSB.

Tipi di convertitori analogico-digitali

I convertitori analogico-digitali si dividono in¹ :

- veloci
- lenti (ma più precisi)

Esistono, tra l'altro, vari tipi di convertitori analogico-digitali adatti
ciascuno per uno scopo² :

- ad 11 kHz per la registrazione della voce umana;
- a 22 kHz per la registrazione su nastro;
- a 44 kHz per la registrazione su cd.

Note

[1] Il convertitore analogico-digitale
[2] ADC (convertitore analogico digitale) TOP

Voci correlate

- Quantizzazione (elettronica)
- Convertitore digitale-analogico
- Modem
- DSP
- Adc0804

Altri progetti

- Wikimedia Commons contiene immagini o altri file su Convertitore
  analogico-digitale

Collegamenti esterni

- Nota applicativa sul miglioramento della conversione mediante dithering
  (PDF), atmel.com.
- Migliorare la risoluzione di un sistema di conversione AD tramite la
  tecnica di sovracampionamento e media (PDF), silabs.com.
- Descrizione dei principali parametri che quantificano la bontà di un
  sistema di conversione AD (SINAD, ENOB, SNR, THD, THD + N, SFDR) (PDF),
  analog.com.

Convertitore digitale-analogico

Il Digital (to) Analog Converter (DAC), in italiano Convertitore
digitale-analogico, è un componente elettronico in grado di produrre sul
suo terminale di uscita, un determinato livello di tensione o di corrente,
in funzione di un valore numerico che viene presentato al suo ingresso; ad
esempio, ad un valore pari ad 1 corrisponderà una tensione di uscita di 0,1
V, ad un valore di 2 avremo 0,2 V, e così via. La tabella di conversione
dal valore digitale a quello analogico prende il nome di LUT (Look-Up
Table) e può avere caratteristiche proporzionali (come nel precedente
esempio), o può seguire un andamento del tutto arbitrario, a seconda del
suo impiego.

Una larga diffusione ad uso domestico dei DAC si ha nei riproduttori
digitali di suoni, nel controllo dell'apertura del diaframma nelle macchine
fotografiche, nei controlli digitali (volume, luminosità) dei televisori e
in tutte quelle situazioni nelle quali un'informazione numerica deve
controllare una grandezza di tipo analogico.

Le caratteristiche del DAC hanno più o meno rilevanza a seconda
dell'impiego; ad esempio la risoluzione è estremamente importante per le
misure di precisione e la riproduzione di brani musicali ad alta fedeltà, e
la qualità sarà tanto più alta, quanto maggiore sarà la grandezza massima
riproducibile sul suo ingresso digitale. Si va dagli 8 bit (256 livelli di
tensione) dei DAC più semplici (telecomandi ecc.), ai 12 bit per i
controlli di precisione (strumenti di misura, multimetri, oscilloscopi), ai
16 bit per i riproduttori musicali ad alta fedeltà (16 bit permettono di
riprodurre una dinamica di 96 dB), fino ad arrivare al DVD che, con i suoi
24 bit di risoluzione, consente una dinamica teorica di ben 144 dB.

All'aumentare della risoluzione, però, corrisponde un maggior numero di
elaborazioni per ottenere la tensione d'uscita; in altre parole, più è
elevata la risoluzione del DAC e più la sua elaborazione ne risulterà
rallentata. Pertanto, la scelta della risoluzione dovrà obbligatoriamente
tenere conto della velocità del dispositivo impiegato, rispetto
all'utilizzo al quale è destinato.

Struttura circuitale

- DAC a resistenze di Emettitore potenza del 2

I convertitori DAC a commutazione di corrente hanno una coppia
differenziale per pilotare le linee di uscita (Io e -Io) e ricevono la
corrente da commutare dal collettore di un transistor tipicamente bipolare,
il cui emettitore ha una singola resistenza verso l'alimentazione negativa.
La base di tutti i transistor è pilotata dal servosistema di riferimento;
la loro uscita è tipicamente una corrente e, se il riferimento è un segnale
esterno, il DAC diventa DAC Moltiplicatore

- DAC a rete R-2R

La singola resistenza di Emettitore dà problemi costruttivi, a causa del
grande rapporto tra la resistenza dell'MSB e quella dell'LSB.

Una tecnica in grado di rendere facile la costruzione di reti con un ottimo
comportamento in un'ampia variazione termica è la R-2R, dove i valori della
rete sono solo due, e quindi mettendo 2N+1 resistenze nel circuito avremo
una rete ad N bit.

L'uscita di questo convertitore è quasi sempre una corrente.

- DAC flash

Questo convertitore è un convertitore a resistenza d'emettitore singola o a
rete R-2R, il cui dato d'ingresso passa attraverso un flip-flop D, aggiunto
per evitare il jitter e migliorare i percorsi dei segnali all'interno del
componente.

- DAC CMOS moltiplicante

Se le linee della rete R-2R sono commutate direttamente senza passare
attraverso un transistor, ed al nodo principale viene fornito un segnale,
questo circuito moltiplica il dato d'ingresso D per la tensione d'ingresso
ottenendo Vu = D / 2^N.

L'uscita di questo convertitore è una tensione.

- DAC ad 1 bit o convertitore Sigma-Delta

Usando una tecnica di sovracampionamento si può commutare la tensione di
pilotaggio di un integratore, la cui uscita sarà filtrata a frequenza molto
inferiore.

Questo convertitore è a basso costo e rende grandi risoluzioni senza
necessità di circuiti precisi, infatti la precisione avviene digitalmente
all'interno della logica di pilotaggio, e le sole parti precise saranno la
tensione di riferimento e la velocissima frequenza di clock.

L'uscita di questo convertitore è una tensione.

- DAC a capacità commutate

Questo convertitore è spesso usato nei microcontrollori, e la sua attività
si svolge nello scambio di carica tra un riferimento (destinato a caricare
un condensatore MOS) ed un punto di misura.

La tensione d'uscita è data dalla posizione dei commutatori CMOS.

Voci correlate

- Convertitore analogico-digitale
- Modulazione Sigma-Delta

Altri progetti

- Wikimedia Commons contiene immagini o altri file su Convertitore
  digitale-analogico

Pulse-code modulation

In elettronica e telecomunicazioni la pulse-code modulation (letteralmente
"modulazione a codice di impulsi"), sigla PCM, è un metodo di
rappresentazione digitale di un segnale analogico. Il metodo utilizza un
campionamento dell'ascissa del segnale a intervalli regolari; i valori
letti vengono poi quantizzati in ordinata ed infine digitalizzati (in
genere codificati in forma binaria). La PCM è ampiamente utilizzata nei
sistemi di telefonia, ma si basano su questo principio anche molti standard
video, come l'ITU-R BT.601. Poiché la PCM pura richiede un bitrate molto
elevato, gli standard video di consumo come DVD o DVR sono basati su sue
varianti che fanno uso di tecniche di compressione. Molto frequentemente,
la codifica PCM viene impiegata per facilitare le trasmissioni digitali in
forma seriale.

Modulazione

Nel diagramma un'onda sinusoidale (rossa) è campionata e quantizzata.
L'onda sinusoidale è campionata a intervalli regolari rappresentati dai
trattini sull'asse delle x. Per ogni campione, uno dei valori disponibili
sull'asse delle y è scelto da opportuni algoritmi, in genere viene
approssimato al più vicino. Questo produce una rappresentazione discreta
del segnale di ingresso che può essere facilmente codificata in digitale
per essere memorizzata e manipolata. Queste operazioni sono effettuate da
un unico circuito integrato chiamato ADC (analog-to-digital converter) a
cui va fornito solamente il clock e l'alimentazione, in uscita produce
direttamente la codifica digitale del segnale analogico in ingresso. Per
l'onda sinusoidale rappresentata sulla destra possiamo verificare che i
valori campionati sono quantizzati con i valori 9, 11, 12, 13, 14, 14, 15,
15, 15, 14, ecc. Codificando questi valori in binario avremo le seguenti
parole di 4 bit: 1001, 1011, 1100, 1101, 1110, 1110, 1111, 1111, 1111,
1110, ecc. Questi valori digitali possono essere processati o analizzati da
un analizzatore di segnali digitali o da una semplice CPU. Diversi canali
PCM possono anche essere multiplati, di solito per trasmettere una maggior
quantità di dati su un unico mezzo trasmissivo. Questa tecnica è chiamata
Time Division Multiplexing (TDM, o multiplazione a divisione di tempo), ed
è largamente usata nei moderni sistemi di telefonia pubblica.

Demodulazione

Per ricavare in ricezione il segnale campionato di ingresso si utilizza la
demodulazione, cioè il contrario della modulazione. Passato ogni periodo di
campionamento è letto il seguente valore e l'uscita si porta quasi
istantaneamente al nuovo valore. Come risultato di queste variazioni
istantanee si avrà un alto numero di armoniche indesiderate (maggiori di
\frac{1}{2} f_c ) che si possono eliminare attraverso un filtro analogico.
Teoricamente è impossibile rappresentare discretamente un segnale con banda
infinita ma secondo il teorema del campionamento se si utilizza una
frequenza di campionamento molto più alta di quella del segnale (pari a due
volte la sua banda di frequenza) il segnale ricostruito in ricezione non si
discosterà molto da quello originario. L'elettronica utilizzata per
riprodurre un accurato segnale analogico da dati discreti è simile a quella
usata per generare il segnale digitale. Questi dispositivi sono chiamati
DAC (digital-to-analog converters), e operano in modo simile agli ADC.
Producono in uscita una tensione o una corrente (dipende dal tipo) secondo
il valore presente in ingresso. Questo segnale di uscita viene generalmente
filtrato e amplificato prima di essere utilizzato.

Limitazioni

Ci sono due fonti di errore implicite nel PCM:

- scegliere un valore discreto "vicino" a quello del segnale analogico per
  ogni campione (errore di quantizzazione).
- nessuna misura è effettuata tra due campioni; secondo il teorema del
  campionamento ogni componente di frequenza superiore o uguale a
  \frac{1}{2} f_c sarà distorta o persa completamente (effetto di
  aliasing).

Poiché i campioni dipendono dal tempo è necessario un clock molto preciso
per un'accurata riproduzione. Se il clock di codifica o decodifica non è
preciso ne risentirà la qualità del segnale in uscita dal dispositivo. Un
piccolo errore tra i due clock non è motivo di preoccupazione anche se
costante, tuttavia se l'errore non è costante si va incontro ad una
distorsione considerevole, soprattutto nei segnali audio e video.

Digitalizzazione

Nel PCM convenzionale, il segnale analogico può essere modificato (ad
esempio mediante compressione del livello audio) prima di essere
digitalizzato. Una volta effettuato il passaggio alla forma digitale, il
segnale PCM è di solito soggetto ad ulteriori elaborazioni (per esempio
compressione dei dati).

Alcune forme particolari di PCM combinano insieme l'elaborazione e la
codifica dei segnali. Le vecchie versioni di questi sistemi applicavano
l'elaborazione nel dominio analogico come parte della conversione
analogico-digitale, mentre le implementazioni più recenti la svolgono nel
dominio digitale. Queste semplici tecniche sono state poi rese obsolete
dalle moderne tecniche di compressione audio digitale.

Differential pulse-code modulation

La differential pulse-code modulation (DPCM) codifica i valori della PCM
tramite le differenze tra il valore successivo e quello precedente. Per i
segnali audio questo tipo di codifica riduce il numero di bit richiesti per
campione di circa il 25% rispetto al PCM.

La DPCM è una tecnica di predizione dei campioni utilizzata per la
trasmissione di segnali analogici in formato numerico (digitale). La
tecnica prevede la quantizzazione e codifica binaria dell'errore tra la
predizione generata e il campione analogico in ingresso. Il valore di
predizione viene ottenuto mediante un predittore più complicato rispetto a
quelli utilizzati in tecniche più semplici ma meno preciso e tiene conto
della funzione di autocorrelazione di un segnale analogico. In particolare
il valore predetto è dipendente da N campioni precedenti ad ognuno dei
quali è assegnato un "peso" a cui corrisponde il proprio coefficiente Ci.

La DPCM viene calcolata mediante l'espressione:

Σ_{i=1}^{N}Ci*[x(k-i)Tc]

dove Tc esprime il tempo di campionamento 1/fc del segnale analogico in
ingresso al sistema.

Il valore dei coefficienti Ci è ottenuto attraverso un calcolo matriciale
che tiene conto appunto della autocorrelazione Rx(i). Il valore di
predizione sarà tanto più preciso quanto meglio è possibile stimare la
funzione di autocorrelazione stessa.

Adaptive differential pulse-code modulation

L'adaptive DPCM (ADPCM) è una variante del DPCM che rende arbitraria la
dimensione dei passi di campionamento, così da consentire ulteriori
riduzioni della larghezza di banda richiesta per un dato rapporto
segnale-rumore.

Modulazione delta

Esiste anche la modulazione delta, che può essere vista come una variante
della DPCM: con questo metodo di compressione si richiede che ogni valore
campionato differisca dal precedente di +1 o -1; sotto queste condizioni,
può essere trasmesso un singolo bit che dice se il nuovo campione è
maggiore o minore del precedente. L'occupazione di banda è di 1/4 rispetto
al PCM classico. La modulazione delta è adottata dai sistemi di
telecomunicazioni militari (NATO e non) sin dagli anni settanta.

Codifica per la trasmissione

La PCM può essere sia return-to-zero (RZ) sia non-return-to-zero (NRZ). Nei
sistemi NRZ è necessaria la sincronizzazione e quindi non ci possono essere
lunghe sequenze di 1 o di 0. Nei sistemi PCM binari la densità di 1 è
chiamata appunto "ones-density". La Ones-density è spesso controllata con
una tecnica di precodifica chiamata Run Length Limited, con cui il codice
PCM è leggermente allungato e viene garantito un limite di ones-density
prima della modulazione. In altri casi sono aggiunte occasionali variazioni
di livello nel flusso. Un'altra tecnica per il controllo della ones-density
è l'uso dello scrambler che fa sembrare il flusso dati pseudo-random,
l'originario segnale può essere estratto mediante un'operazione inversa.
Lunghe sequenze di 0 e di 1 sono ancora possibili ma altamente improbabili.

Storia della PCM

La PCM, come molte altre grandi invenzioni sembra essere semplice ed ovvia.
Il motivo principale che portò alla campionatura dei segnali era la
necessità di far passare su un unico cavo diversi campioni provenienti da
diverse fonti telegrafiche. La TDM (time-division multiplexing) fu
inventata nel 1853, dallo statunitense M.B. Farmer.

L'ingegnere elettrico W.M. Miner, nel 1903, usò un commutatore
elettro-meccanico per la multiplazione a divisione di tempo di diversi
segnali telegrafici, applicò in seguito questa tecnologia alla telefonia.
Ottenne flussi audio intelligibili per canali campionati a 3500–4300 Hz: al
di sotto la comunicazione era insoddisfacente. Questa TDM usava canali PAM
(pulse-amplitude modulation) e non PCM.

Paul M. Rainey della Western Electric nel 1926 brevettò un convertitore
analogico-digitale che però non andò mai in produzione. L'ingegnere inglese
Alec Reeves, ignaro del lavoro precedente, pensò alla PCM per le
comunicazioni vocali nel 1937 mentre lavorava per la International
Telephone and Telegraph in Francia. Descrisse la teoria e i vantaggi ma non
ne derivarono usi pratici. Reeves brevettò questi studi in Francia nel
1938, e nel 1943 negli Stati Uniti.

La prima trasmissione di un discorso mediante tecniche digitali fu
utilizzata per le comunicazioni di alto livello degli Alleati durante la
Seconda guerra mondiale nel 1943.

Non prima della metà del 1943 i tecnici dei Bell Labs che inventarono il
sistema SIGSALY (usato per le comunicazioni degli Alleati), vennero a
conoscenza che la codifica binaria PCM era già stata proposta da Alec
Reeves. La PCM negli anni cinquanta usava un tubo a raggi catodici con una
griglia perforata per la codifica. Come in un oscilloscopio il raggio si
muoveva orizzontalmente alla frequenza di campionamento e lo spostamento
verticale era controllato dal segnale analogico d'ingresso. La griglia era
progettata non per produrre codice binario semplice, bensì codice Gray.

Bibliografia

- Franklin S. Cooper, Ignatius Mattingly, Computer-controlled PCM system
  for investigation of dichotic speech perception, in Journal of the
  Acoustical Society of America, vol. 46, 1969, p. 115.
- Ken C. Pohlmann, Principles of Digital Audio, 2nd ed., Carmel, Indiana,
  Sams/Prentice-Hall Computer Publishing, 1985, ISBN 0-672-22634-0.
- D. H. Whalen, E. R. Wiley, Philip E. Rubin, and Franklin S. Cooper, The
  Haskins Laboratories pulse code modulation (PCM) system, in Behavior
  Research Methods, Instruments, and Computers, vol. 22, 1990, pp. 550-559.
- Bill Waggener, Pulse Code Modulation Techniques, 1st ed., New York, NY,
  Van Nostrand Reinhold, 1995, ISBN 0-442-01436-8.
- William N. Waggener, Pulse Code Modulation Systems Design, 1st ed.,
  Boston, MA, Artech House, 1999, ISBN 0-89006-776-7.

Altri progetti

- Wikimedia Commons contiene immagini o altri file su Pulse-code modulation

Collegamenti esterni

- Ralph Miller and Bob Badgley invented multi-level PCM independently in
  their work at Bell Labs on SIGSALY: (EN) United States Patent 3912868,
  United States Patent and Trademark Office.: N-ary Pulse Code Modulation.
- According to the Inventors Hall of Fame, B.M Oliver and Claude Shannon
  are the inventors of PCM as described in 'Communication System Employing
  Pulse Code Modulation,' (EN) United States Patent 2801281, United States
  Patent and Trademark Office. filed in 1946 and 1952, granted in 1956.
- Information about PCM: A description of PCM with links to information
  about subtypes of this format (for example Linear Pulse Code Modulation),
  and references to their specifications.

Sistema dinamico

In fisica e matematica, in particolare nella teoria dei sistemi dinamici,
un sistema dinamico è un modello matematico che rappresenta un oggetto
(sistema) con un numero finito di gradi di libertà che evolve nel tempo
secondo una legge deterministica. Un sistema dinamico viene identificato da
un vettore nello spazio delle fasi, lo spazio degli stati del sistema, dove
"stato" è un termine che indica l'insieme delle grandezze fisiche, dette
variabili di stato, che caratterizzano la dinamica del sistema.

Lo studio dei sistemi dinamici rappresenta uno dei più antichi e importanti
settori della matematica e della fisica; si tratta di un modello matematico
utilizzato per descrivere i sistemi meccanici nell'ambito della meccanica
classica e nella sua riformulazione sviluppata dalla meccanica lagrangiana
e dalla meccanica hamiltoniana, e che è presente in molti settori
dell'ingegneria, come l'automatica e l'ingegneria dei sistemi. Le
applicazioni sono molteplici, spaziando dai circuiti elettrici ai sistemi
termodinamici.

Alla fine del diciannovesimo secolo, poi, Henri Poincaré osserva la
possibilità di un comportamento fortemente irregolare di alcuni sistemi
dinamici studiando il problema dei tre corpi: negli anni '50 del secolo
successivo, in seguito agli esperimenti numerici del meteorologo Edward
Lorenz, che studiando l'atmosfera terrestre rivelò la dipendenza sensibile
dalle condizioni iniziali, i risultati di Poincaré vennero presi in grande
considerazione dalla comunità scientifica e posero le basi alla teoria del
caos. Il comportamento caotico dei sistemi dinamici, la cui controparte
matematica può raggiungere gradi di complessità che rendono vincolante
l'utilizzo del calcolatore, è stato riscontrato in molti e diversi ambiti
dello studio della natura della civiltà umana, tra cui la biologia e
l'economia.

Si possono identificare due tipologie di sistema dinamico:

- Se l'evoluzione avviene ad intervalli discreti di tempo il sistema viene
  chiamato sistema dinamico discreto ed è definito dall'iterazione di una
  funzione
- Se l'evoluzione è continua e definita da un'equazione differenziale, il
  sistema viene chiamato sistema dinamico continuo.

Di particolare importanza sono i sistemi dinamici lineari, i più semplici
da analizzare in quanto le equazioni non lineari non sono solitamente
risolvibili in modo esatto. Tra i sistemi lineari, i sistemi lineari
tempo-invarianti (sistemi LTI) vengono ampiamente utilizzati nella teoria
dei segnali e nella teoria del controllo.

Una delle caratteristiche dei sistemi dinamici che viene studiata più
spesso è la stabilità. Per esempio, è comune studiare la stabilità in
termini di limitatezza delle uscite nei confronti di un ingresso limitato
(stabilità esterna), oppure in termini di allontanamento da uno stato di
equilibrio (stabilità interna).

Per analizzare matematicamente il comportamento di un sistema dinamico si
utilizzano soprattutto due tipologie di descrizione, la rappresentazione in
spazio di stato e il formalismo del dominio della frequenza (si veda la
funzione di trasferimento nel caso di sistemi stazionari).

Introduzione

In meccanica classica un esempio elementare di sistema dinamico è fornito
da un punto che si muove nello spazio. Il punto viene completamente
caratterizzato dalla sua posizione r(t) (un vettore dipendente da t \in \R
) e dalla sua velocità v(t) = \dot r(t) = dr / dt. Lo stato di tale sistema
è il vettore (r(t),v(t)) \in \R ⁿ, dove \R ⁿ è lo spazio delle fasi
utilizzato. Lo spazio delle fasi viene anche detto spazio delle
configurazioni per il fatto che i suoi elementi rappresentano tutti gli
stati possibili che il sistema può assumere. L'evoluzione temporale del
punto è quindi data dalle due derivate:

\dot r(t) = v(t) \qquad \dot v(t) = a

dove a è l'accelerazione del punto (che dipende dalla somma delle forze a
cui è soggetto). Definendo:

x(t) =(r(t),v(t))

il moto del punto può essere scritto con l'equazione ordinaria autonoma:

\dot x(t) = f(x(t))

Scegliendo un punto e una velocità iniziali x₀ ₌ ₍r₀,v₀₎, ovvero ponendo
x(t=0) ≡x₀, si ottiene l'evoluzione del sistema a partire da x₀ (problema
di cauchy per l'equazione differenziale).

Tutti i sistemi dinamici a tempo continuo vengono scritti in modo analogo,
eventualmente con f che dipende esplicitamente dal tempo:

\dot x(t) = f(x(t),t) \qquad x \in \R ⁿ

dove f : \R ^n \times \R →\R ⁿ è una funzione almeno differenziabile. Tale
sistema può essere ricondotto a quello autonomo (f : \R ^n →\R ⁿ ) con un
cambio di variabili.

La soluzione (x₀,t) al variare di t è la traiettoria (orbita) seguita dal
sistema nello spazio delle fasi a partire da x₀. Nell'impostare formalmente
lo studio di un sistema dinamico si fa in modo che la funzione f sia
sufficientemente regolare da fornire una soluzione unica (teorema di
esistenza e unicità), in accordo con il fatto che l'evoluzione del sistema
a partire da un punto dato è unica.

Definizione

In generale, un sistema dinamico (T,M,Φ) è definito da un gruppo (o un
semigruppo) T, che è l'insieme dei valori del parametro tempo t, e un
insieme M, detto lo spazio delle fasi o spazio degli stati. La funzione di
evoluzione temporale (flusso) Φ\colon U \subset T \times M →M determina
l'azione di T su M. Nella teoria ergodica M è uno spazio misurabile con
misura di probabilità μ e Φ è una funzione misurabile che preserva μ,
mentre nella cosiddetta topologia dinamica M è uno spazio topologico
completo e Φ è una funzione continua (spesso anche invertibile).¹

Nello specifico, per ogni t si può definire Φ tale che:

Φ(0,x) = x
Φ(t_1,x) \circ Φ(t_2,x) = Φ(t_2,Φ(t_1,x)) = Φ(t_1 + t_2, x) \qquad t_1,
t_2, t_1 + t_2 \in I(x)

dove:

I(x) = {t \in T : (t,x) \in U }

Ciò rispecchia il fatto che la legge di evoluzione Φ del sistema non cambia
essa stessa nel tempo. Le funzioni Φ(t,x) parametrizzate da t, con la legge
di composizione Φ(t_1,x) \circ Φ(t₂,x), formano un gruppo commutativo ad un
parametro. Frequentemente nel caso discreto T coincide con \Z , mentre nel
caso continuo T coincide con \R .²

Il grafico di Φ è la traiettoria del sistema nel tempo e l'insieme:

γ_{x_0}:={Φ(t,x_0) : t \in I(x_0)}

è l'orbita passante per x₀ (ovvero l'immagine del flusso in x₀).

Un sottoinsieme S \subset M è detto Φ-invariante se:

Φ(t,x) \in S \qquad ∀x \in S ∀t \in T

In particolare, affinché S sia invariante si deve verificare I(x)=T per
tutti gli x \in S, ovvero il flusso lungo x deve essere definito per tutti
i punti di S ad ogni tempo.

Sistemi continui

Data una varietà S, sia v : S →S un campo vettoriale differenziabile, cioè
che associa ad ogni punto z \in S un vettore le cui coordinate sono legate
alle coordinate di z (definite in un suo intorno rispetto a qualche base)
tramite una funzione differenziabile. Un sistema dinamico è definito
dall'equazione autonoma (l'equazione del moto per sistemi meccanici):

v(z) = \frac{dz}{dt}

Trattandosi di un'equazione differenziale ordinaria, il relativo teorema di
esistenza e unicità della soluzione stabilisce che preso un punto iniziale
z₀ esiste un intervallo -a \le t \le b, con a,b > 0, in cui il sistema
dinamico ha una soluzione unica z(t)=ϕₜ₍z₀₎.

Se la soluzione (traiettoria) esiste per tutti i tempi e per qualsiasi
scelta del punto iniziale z₀ si ha che il tempo può scorrere nel verso
contrario, ovvero è possibile predire il passato conoscendo uno stato del
sistema nel futuro. In particolare, si verifica che ϕ^{-1}_t =ϕ_{-t} e
l'insieme delle ϕₜ forma un gruppo continuo ad un parametro di
diffeomorfismi su S.

La struttura matematica che viene assegnata allo spazio delle fasi M
dipende comunque dal contesto; solitamente è uno spazio topologico, in cui
ha senso parlare di continuità nell'evoluzione temporale dello stato. Uno
spazio topologico in cui è possibile l'utilizzo di strumenti metrici e
differenziali è ad esempio la varietà differenziabile, una delle strutture
più utilizzate in quanto risulta particolarmente adatta per modellare i
sistemi fisici. Per i sistemi nei quali allo stato viene associata una
nozione di misura, ad esempio una probabilità, si utilizza uno spazio
misurabile. Si richiede inoltre che il flusso Φ sia compatibile con la
struttura di M: nel caso in cui M sia rispettivamente uno spazio
topologico, uno spazio misurabile, una varietà differenziabile o una
varietà complessa, Φ è un omeomorfismo, una funzione misurabile, un
diffeomorfismo o una funzione olomorfa.

Sistemi discreti

I sistemi dinamici discreti sono definiti da un'iterazione del tipo:

X_{n+1} = f(X_n) \qquad n \ge 0

di una funzione f : S →S, con S \subset \R ⁿ. Può essere vista come
un'equazione alle differenze:

X_{n+1} - X_n = f(X_n) - X_n \qquad n \ge 0

che definendo F(Xₙ₎₌f(Xₙ₎ - Xₙ assume la stessa forma dell'equazione
differenziale ordinaria del caso continuo.

Le orbite di un sistema discreto sono una successione di stati {X_n
}_{n=1}^\infty . Il gruppo di trasformazioni è quindi dato dall'insieme:

G={Id, f, f^2, f^3, …f^n, …}

dove l'espressione f^k indica la composizione di funzioni f \circ …\circ f
di f con sé stessa iterata k volte.

Classificazione in base a ingressi e uscite

In ambito ingegneristico i sistemi dinamici vengono classificati in base al
numero di variabili d'ingresso e d'uscita, si hanno infatti:

- sistemi a singolo ingresso e singola uscita (SISO, dall'inglese single
  input-single output);
- sistemi a ingresso multiplo e uscita multipla (MIMO, dall'inglese
  multiple input-multiple output);

e meno frequentemente:

- sistemi a singolo ingresso e uscita multipla (SIMO, dall'inglese single
  input-multiple output);
- sistemi a ingresso multiplo e singola uscita (MISO, dall'inglese multiple
  input-single output).

Sistemi lineari

Una classe molto importante di sistemi dinamici è quella dei sistemi
lineari, in cui il legame tra variabili di ingresso e l'uscita è lineare.
Sono utilizzati ad esempio nella teoria dei segnali o nella teoria dei
circuiti, e spesso sono analizzati in frequenza tramite l'utilizzo di
trasformate integrali, come la trasformata di Fourier o la trasformata di
Laplace.

Un sistema lineare di n stati x \in \R ⁿ, m input u \in \R ^m e q uscite y
\in \R ^q viene descritto da un'equazione del tipo:³

\dot x(t) = A(t) x(t)+B(t) u(t)
y(t) = C(t) x(t)+D(t) u(t)

dove A \in \R ^{n \times n}, B \in \R ^{n \times m}, C \in \R ^{q \times n}
e D \in \R ^{q \times m} sono matrici (che nel caso stazionario non
dipendono dal tempo).

Sistemi lineari e stazionari

Un sistema dinamico lineare e stazionario è anche detto lineare
tempo-invariante, abbreviato spesso con la sigla LTI (dall'inglese Linear
Time-Invariant). Nel caso di un sistema continuo, è caratterizzato dal
fatto che l'uscita y(t) per un segnale in ingresso x(t) è descritta dalla
convoluzione:

y(t) = x(t) * h(t) = ∫_{-\infty }^{\infty } x(t-τ)·h(τ) \operatorname{d} τ=
∫_{-\infty }^{\infty } x(τ)·h(t-τ) \operatorname{d} τ

dove h(t) è la risposta impulsiva, ovvero la risposta del sistema quando
l'ingresso x(t) è una funzione a delta di Dirac. Se la funzione h(τ) è
nulla quando τ< 0 allora y(t) dipende soltanto dai valori assunti da x
precedentemente al tempo t, ed il sistema è detto causale.

Un sistema a tempo discreto trasforma la successione in ingresso {x} in
un'altra successione {y}, data dalla convoluzione discreta con la risposta
h alla delta di Kronecker:

y[n] = Σ_{k=-\infty }^{\infty } x[k]·h[n-k] = Σ_{k=-\infty }^{\infty }
x[n-k]·h[k]

Gli elementi di {y} possono dipendere da ogni elemento di {x}. Solitamente
y[n] dipende maggiormente dagli elementi in prossimità del tempo n.

I sistemi lineari stazionari sono spesso descritti nel dominio della
frequenza (risposta in frequenza) attraverso la funzione di trasferimento,
definita come la trasformata di Laplace della risposta all'impulso a Delta.

Sistemi strettamente propri

Un ulteriore classificazione per i sistemi lineari li divide in
strettamente propri (o puramente dinamici) quando l'uscita dipende
esclusivamente dagli stati del sistema, e in tal caso nella
rappresentazione matriciale ciò corrisponde a una matrice D(t) nulla,
mentre si parla di sistema proprio in tutti gli altri casi. Un caso
particolare di sistema proprio si ha quando è la matrice C(t) ad azzerarsi,
in tal caso il sistema è detto non dinamico e non è necessario ricorrere a
variabili di stato per rappresentarlo, poiché il legame fra ingresso e
uscita è istantaneo.⁴ È possibile dimostrare che un sistema puramente
dinamico ha funzione di trasferimento con grado del numeratore minore a
quello del denominatore mentre un sistema non dinamico ha, ovviamente,
funzione di trasferimento con grado zero.

Stabilità

Si possono definire diversi tipi di stabilità per un sistema dinamico, ad
esempio la stabilità esterna, anche detta stabilità BIBO (da Bounded Input,
Bounded Output), ovvero la proprietà di avere un'uscita limitata se
l'ingresso è limitato, oppure la stabilità interna, che si riferisce alla
capacità di tornare in una configurazione di equilibrio dopo una
perturbazione dello stato di equilibrio stesso. La stabilità esterna viene
generalmente utilizzata per analizzare il comportamento di sistemi lineari
stazionari (per i quali si valutano i poli della funzione di
trasferimento), mentre la stabilità interna sfrutta la rappresentazione in
spazio di stato del sistema ed è stata studiata in particolare da Aleksandr
Michajlovič Ljapunov.

L'analisi della stabilità di un sistema meccanico è collegata con il fatto
che il sistema, se lasciato libero di evolvere, tende spontaneamente a
portarsi in una configurazione dove la sua energia potenziale è minima:
tale configurazione che corrisponde ad uno stato di equilibrio stabile (si
veda il teorema di Lagrange-Dirichlet).

Stabilità esterna

Un sistema è stabile esternamente (BIBO stabile) se ad un ingresso limitato
corrisponde una uscita limitata. La limitatezza di una funzione scalare f è
generalmente definita in tale contesto dal fatto che esiste un M < \infty
tale che:

\sup _{t \ge 0} | f(t) | < M

Nel caso di sistemi dinamici lineari, un sistema lineare è BIBO stabile se
e solo se la risposta impulsiva h(t) è assolutamente integrabile, cioè
esiste un M' < \infty tale che:⁵

∫_{-\infty }^\infty |h (τ)| dτ< M'

Stabilità interna

Stabilità strutturale

Controllabilità e osservabilità

I concetti di controllabilità e osservabilità sono stati introdotti da
Kalman nel 1960 e sono alla base della teoria del controllo. Informalmente,
un sistema è controllabile se è possibile portarlo in qualsiasi
configurazione finale agendo opportunamente sull'ingresso in un tempo
finito; viceversa, è osservabile se dall'uscita è possibile risalire allo
stato del sistema. Nei sistemi lineari controllabilità e osservabilità sono
due proprietà duali.

Sistemi lineari

Dato un sistema dinamico lineare:

\dot x = Ax + b u
y = c^T x

dove c^T è un vettore costante, si consideri la matrice:

T = [c^T c^T A c^T A^2 … c^T A^{n-1} ]^T

Il sistema è completamente osservabile se il rango di T è massimo.

Considerando invece la matrice:

R = \begin{bmatrix} b & Ab & A^{2}b & ...& A^{n-1}b \end{bmatrix}

il sistema è completamente controllabile se la matrice ha rango massimo.

Definendo il sistema duale:⁶

\dot x = A^T x + c u
y = b^T x

si dimostra che il sistema di partenza è completamente osservabile se e
solo se il sistema duale è completamente controllabile, ed è completamente
controllabile se e solo se il sistema duale è completamente osservabile.

Sistemi non lineari

Dato un sistema dinamico definito su una varietà M \in C^\infty di
dimensione m:

\dot x = f(x,u) \qquad x \in M
y=g(x)

con u \in Ω\subset \R ^l l'ingresso, y \in \R ⁿ l'uscita e f,g \in C^\infty
, i problemi di controllabilità si traducono nel verificare se lo spazio
delle fasi M è sufficientemente grande da contenere tutti gli stati
possibili (altrimenti il sistema non è osservabile) o se, al contrario,
contiene stati che il sistema non può raggiungere (il sistema non è
controllabile).

Una descrizione matematica comunemente utilizzata considera l'algebra di
Lie F di campi vettoriali sullo spazio delle fasi M generata dal campo
vettoriale f(·, u), con u \in Ω un controllo costante: se la dimensione
dell'algebra è costante esiste un'unica sotto-varietà M' \subset M tangente
lo stato iniziale x₀ contenente tutte le orbite raggiungibili dal sistema
(andando avanti o all'indietro nel tempo) passanti per x₀. Se la dimensione
di F(x₀₎ è m allora M=M' e il sistema è in qualche modo controllabile; in
caso contrario, se la dimensione è minore di m si considera solo l'insieme
M' in cui il sistema è controllabile.⁷

Sistemi fisici

La dinamica dei sistemi fisici può essere caratterizzata dal fatto che il
loro moto tra due punti di coordinate generalizzate q(t₁₎ e q(t₂₎ segue un
cammino che rende stazionario, ovvero a variazione nulla, il funzionale
azione:⁸

δ\mathcal{S} = 0

in accordo con il principio di minima azione (principio variazionale di
Hamilton). L'azione è l'integrale nel tempo della lagrangiana L (q, \dot
q,t):⁹

\mathcal{S} = ∫_{t₁}^{t₂} L dt

dove L \in C²[t₁,t₂]. Si dimostra che L così definita soddisfa le equazioni
di Eulero-Lagrange:

{\partial L\over \partial q } - {d\over dt }{\partial L\over \partial \dot
q} = 0

Rendere stazionaria l'azione corrisponde a minimizzare l'energia del
sistema considerato, e solitamente si fa corrispondere all'energia totale
del sistema una funzione \mathcal{H} =\mathcal{H} (q,p,t), detta
hamiltoniana e introdotta nel 1835 da William Rowan Hamilton, che dipende
dalle coordinate generalizzate q e dai rispettivi momenti coniugati:

p_j = {\partial L (q, \dot q,t) \over \partial \dot{q} _j} \qquad p =
{\partial L (q, \dot q,t) \over \partial \dot{q} }

L'hamiltoniana è data dalla somma \mathcal{H} =T+V dell'energia cinetica T
e dell'energia potenziale V del sistema, ed è la trasformata di Legendre
della lagrangiana L:¹⁰ ¹¹

\mathcal{H} (q,p,t) = [ p ·\dot q - L (q,\dot q,t) ]_{\dot q = \dot q(
q,p,t)}

La formalizzazione di un problema dinamico tramite il principio di minima
azione (valido per sistemi olonomi e monogenici) è alla base della
riformulazione della meccanica classica sviluppata dalla meccanica
hamiltoniana e lagrangiana.

In particolare le equazioni di Hamilton:

\frac{\mathrm{d} p}{\mathrm{d} t} = -\frac{\partial \mathcal{H} }{\partial
q} \qquad \frac{\mathrm{d} q}{\mathrm{d} t} = +\frac{\partial \mathcal{H}
}{\partial p}

sono equivalenti alle equazioni del moto di Eulero-Lagrange, a loro volta
equivalenti alla legge di Newton.¹²

Il principio di conservazione dell'energia viene poi espresso, in tale
contesto, dicendo che \mathcal{H} è un integrale primo delle equazioni di
Hamilton, oppure con il fatto che la lagrangiana non dipende esplicitamente
dal tempo:

\frac{d \mathcal H}{ dt} = -\frac{\partial L}{ \partial t} = 0

Più in generale, per il teorema di Noether ad ogni simmetria della
lagrangiana, ovvero ad ogni trasformazione infinitesima continua delle
coordinate (q, \dot q,t) che lascia inalterata L (q, \dot q,t), corrisponde
una quantità conservata.

Sistemi ergodici

Teoria delle biforcazioni

Un punto fisso (in generale un punto periodico) è un punto nello spazio
delle fasi (cioè uno stato) che rimane invariato durante l'evoluzione del
sistema. Un insieme invariante è un insieme di stati che viene mandato in
sé stesso dall'evoluzione del sistema, eventualmente spostando i singoli
stati all'interno dell'insieme, e un attrattore è un insieme invariante a
cui le orbite si avvicinano per tempi che tendono all'infinito.

Caos

Rappresentazione grafica

Nell'ingegneria dei sistemi un sistema può essere modellizzato graficamente
tramite una scomposizione in un insieme di sottosistemi collegati tra loro
in vario modo (serie, parallelo, retroazione ecc...), ciascuno dei quali è
identificato da uno scatolotto il cui funzionamento o comportamento è
descritto da una funzione di sottoprocesso che esso svolge all'interno del
sistema generale. Lo schema risultante si darà schema a blocchi del sistema
(si veda Modello black box).

Esempi

Esempi di sistemi dinamici continui sono:

- Il sistema preda-predatore di Volterra Lotka per la dinamica delle
  popolazioni
- Il sistema di Lorenz per l'evoluzione delle condizioni meteorologiche

Esempi di sistemi dinamici discreti sono:

- la mappa logistica
- la mappa di Hénon
- la mappa standard

Note

[1] Treccani: Enciclopedia del Novecento II Supplemento (1998) - Sistemi
  dinamici
[2] (EN) Jinpeng An - Homogeneous Dynamics
[3] Giovanna Finzi - Classificazione dei sistemi dinamici
[4] Classificazione dei sistemi dinamici su unibs.it
[5] (EN) Mauricio de Oliveira - Stability
[6] (EN) William J. Terrel - Controllability, Observability, and Duality
[7] (EN) Robert Hermann, Arthur J. Krener - Nonlinear Controllability and
  Observability
[8] (EN) Analytical Mechanics, L.N. Hand, J.D. Finch, Cambridge University
  Press, 2008, ISBN 978-0-521-57572-0
[9] (EN) Simon J.A. Malham - An introduction to Lagrangian and Hamiltonian
  mechanics
[10] (EN) Britannica - Hamiltonian function
[11] (EN) L.N. Hand, J.D. Finch, Analytical Mechanics, Cambridge University
  Press, 2008, ISBN 978-0-521-57572-0
[12] (EN) Ernst Hairer - Lecture 1: Hamiltonian systems

Bibliografia

- (EN) V. I. Arnold, Mathematical methods of classical mechanics,
  Springer-Verlag, 1982, ISBN 0-387-96890-3.
- (EN) Jacob Palis and Wellington de Melo, Geometric theory of dynamical
  systems: an introduction, Springer-Verlag, 1982, ISBN 0-387-90668-1.
- (EN) David Ruelle, Elements of Differentiable Dynamics and Bifurcation
  Theory, Academic Press, 1989, ISBN 0-12-601710-7.
- (EN) Tim Bedford, Michael Keane and Caroline Series, eds., Ergodic
  theory, symbolic dynamics and hyperbolic spaces, Oxford University Press,
  1991, ISBN 0-19-853390-X.
- (EN) Ralph H. Abraham and Christopher D. Shaw, Dynamics—the geometry of
  behavior, 2nd edition, Addison-Wesley, 1992, ISBN 0-201-56716-4.
- (EN) Kathleen T. Alligood, Tim D. Sauer and James A. Yorke, Chaos. An
  introduction to dynamical systems, Springer Verlag, 2000, ISBN
  0-387-94677-2.
- (EN) Oded Galor, Discrete Dynamical Systems, Springer, 2011, ISBN
  978-3-642-07185-0.
- (EN) Anatole Katok and Boris Hasselblatt, Introduction to the modern
  theory of dynamical systems, Cambridge, 1996, ISBN 0-521-57557-5.
- (EN) James Meiss, Differential Dynamical Systems, SIAM, 2007, ISBN
  0-89871-635-7.
- (EN) Morris W. Hirsch, Stephen Smale and Robert Devaney, Differential
  Equations, dynamical systems, and an introduction to chaos, Academic
  Press, 2003, ISBN 0-12-349703-5.
- (EN) Julien Clinton Sprott, Chaos and time-series analysis, Oxford
  University Press, 2003, ISBN 0-19-850839-5.
- (EN) Steven H. Strogatz, Nonlinear dynamics and chaos: with applications
  to physics, biology chemistry and engineering, Addison Wesley, 1994, ISBN
  0-201-54344-3.
- (EN) Gerald Teschl, Ordinary Differential Equations and Dynamical
  Systems, Providence, American Mathematical Society, 2012, ISBN
  978-0-8218-8328-0.
- (EN) Stephen Wiggins, Introduction to Applied Dynamical Systems and
  Chaos, Springer, 2003, ISBN 0-387-00177-8.

Voci correlate

- Analisi dei sistemi dinamici
- Attrattore
- Controllabilità
- Controllo automatico
- Ergodicità
- Funzione di trasferimento
- Identificazione di sistemi dinamici
- Meccanica lagrangiana
- Meccanica hamiltoniana
- Orbita (matematica)
- Punto di equilibrio
- Sistema dinamico lineare stazionario
- Stabilità esterna
- Stabilità interna
- Teoria delle biforcazioni
- Teoria del caos
- Teoria della stabilità

Altri progetti

- Wikimedia Commons contiene immagini o altri file su sistema dinamico

Collegamenti esterni

- Sistema dinamico, in Thesaurus del Nuovo soggettario, BNCF, marzo 2013.
- (EN) D.V. Anosov, Dynamical system, in Encyclopaedia of Mathematics,
  Springer e European Mathematical Society, 2002.
- (EN) Michael Proctor - Dynamical Systems (PDF), damtp.cam.ac.uk.
- Carla Dionisi - Sistemi dinamici (PDF), web.math.unifi.it.
- (EN) Evans M. Harrell II - Dynamical Systems and Chaos, mathphysics.com.
- (EN) Eric W. Weisstein, Dynamical System, in MathWorld, Wolfram Research.

